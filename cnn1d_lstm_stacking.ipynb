{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 16808,
     "status": "ok",
     "timestamp": 1633575234019,
     "user": {
      "displayName": "꾸꾸",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "14922489440020274566"
     },
     "user_tz": -540
    },
    "id": "sm0xZ2uXk6Xg",
    "outputId": "eac1fb83-be3f-4529-e743-2d5df5ac1009"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "# 구글 드라이브 마운트\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 242,
     "status": "ok",
     "timestamp": 1633575238331,
     "user": {
      "displayName": "꾸꾸",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "14922489440020274566"
     },
     "user_tz": -540
    },
    "id": "jmIJ4F3Lk6Il"
   },
   "outputs": [],
   "source": [
    "# 기본 directory 설정\n",
    "import os\n",
    "os.chdir('/content/drive/MyDrive/Monthly_Workout')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 225,
     "status": "ok",
     "timestamp": 1633575240066,
     "user": {
      "displayName": "꾸꾸",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "14922489440020274566"
     },
     "user_tz": -540
    },
    "id": "c6d7M76Wl5Bx"
   },
   "outputs": [],
   "source": [
    "# 모듈 불러오기\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from math import pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "executionInfo": {
     "elapsed": 7740,
     "status": "ok",
     "timestamp": 1633575261246,
     "user": {
      "displayName": "꾸꾸",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "14922489440020274566"
     },
     "user_tz": -540
    },
    "id": "gFXySamQk5y-"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>time</th>\n",
       "      <th>acc_x</th>\n",
       "      <th>acc_y</th>\n",
       "      <th>acc_z</th>\n",
       "      <th>gy_x</th>\n",
       "      <th>gy_y</th>\n",
       "      <th>gy_z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.206087</td>\n",
       "      <td>-0.179371</td>\n",
       "      <td>-0.148447</td>\n",
       "      <td>-0.591608</td>\n",
       "      <td>-30.549010</td>\n",
       "      <td>-31.676112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.287696</td>\n",
       "      <td>-0.198974</td>\n",
       "      <td>-0.182444</td>\n",
       "      <td>0.303100</td>\n",
       "      <td>-39.139103</td>\n",
       "      <td>-24.927216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.304609</td>\n",
       "      <td>-0.195114</td>\n",
       "      <td>-0.253382</td>\n",
       "      <td>-3.617278</td>\n",
       "      <td>-44.122565</td>\n",
       "      <td>-25.019629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.293095</td>\n",
       "      <td>-0.230366</td>\n",
       "      <td>-0.215210</td>\n",
       "      <td>2.712986</td>\n",
       "      <td>-53.597843</td>\n",
       "      <td>-27.454013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1.300887</td>\n",
       "      <td>-0.187757</td>\n",
       "      <td>-0.222523</td>\n",
       "      <td>4.286707</td>\n",
       "      <td>-57.906561</td>\n",
       "      <td>-27.961234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1874995</th>\n",
       "      <td>3124</td>\n",
       "      <td>595</td>\n",
       "      <td>-0.712530</td>\n",
       "      <td>-0.658357</td>\n",
       "      <td>0.293707</td>\n",
       "      <td>-29.367857</td>\n",
       "      <td>-104.013664</td>\n",
       "      <td>-76.290437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1874996</th>\n",
       "      <td>3124</td>\n",
       "      <td>596</td>\n",
       "      <td>-0.683037</td>\n",
       "      <td>-0.658466</td>\n",
       "      <td>0.329223</td>\n",
       "      <td>-30.149089</td>\n",
       "      <td>-101.796809</td>\n",
       "      <td>-76.625087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1874997</th>\n",
       "      <td>3124</td>\n",
       "      <td>597</td>\n",
       "      <td>-0.664730</td>\n",
       "      <td>-0.666625</td>\n",
       "      <td>0.364114</td>\n",
       "      <td>-27.873095</td>\n",
       "      <td>-98.776072</td>\n",
       "      <td>-79.365125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1874998</th>\n",
       "      <td>3124</td>\n",
       "      <td>598</td>\n",
       "      <td>-0.630534</td>\n",
       "      <td>-0.682565</td>\n",
       "      <td>0.373696</td>\n",
       "      <td>-23.636550</td>\n",
       "      <td>-99.139495</td>\n",
       "      <td>-80.259478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1874999</th>\n",
       "      <td>3124</td>\n",
       "      <td>599</td>\n",
       "      <td>-0.578351</td>\n",
       "      <td>-0.700235</td>\n",
       "      <td>0.384390</td>\n",
       "      <td>-17.917626</td>\n",
       "      <td>-100.181873</td>\n",
       "      <td>-80.676229</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1875000 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id  time     acc_x     acc_y     acc_z       gy_x        gy_y  \\\n",
       "0           0     0  1.206087 -0.179371 -0.148447  -0.591608  -30.549010   \n",
       "1           0     1  1.287696 -0.198974 -0.182444   0.303100  -39.139103   \n",
       "2           0     2  1.304609 -0.195114 -0.253382  -3.617278  -44.122565   \n",
       "3           0     3  1.293095 -0.230366 -0.215210   2.712986  -53.597843   \n",
       "4           0     4  1.300887 -0.187757 -0.222523   4.286707  -57.906561   \n",
       "...       ...   ...       ...       ...       ...        ...         ...   \n",
       "1874995  3124   595 -0.712530 -0.658357  0.293707 -29.367857 -104.013664   \n",
       "1874996  3124   596 -0.683037 -0.658466  0.329223 -30.149089 -101.796809   \n",
       "1874997  3124   597 -0.664730 -0.666625  0.364114 -27.873095  -98.776072   \n",
       "1874998  3124   598 -0.630534 -0.682565  0.373696 -23.636550  -99.139495   \n",
       "1874999  3124   599 -0.578351 -0.700235  0.384390 -17.917626 -100.181873   \n",
       "\n",
       "              gy_z  \n",
       "0       -31.676112  \n",
       "1       -24.927216  \n",
       "2       -25.019629  \n",
       "3       -27.454013  \n",
       "4       -27.961234  \n",
       "...            ...  \n",
       "1874995 -76.290437  \n",
       "1874996 -76.625087  \n",
       "1874997 -79.365125  \n",
       "1874998 -80.259478  \n",
       "1874999 -80.676229  \n",
       "\n",
       "[1875000 rows x 8 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터 불러오기\n",
    "path = './' # 기본 directory 경로에 추가 할 경로\n",
    "\n",
    "train = pd.read_csv(path + 'train_features.csv')\n",
    "train_labels = pd.read_csv(path + 'train_labels.csv')\n",
    "test = pd.read_csv(path + 'test_features.csv')\n",
    "submission = pd.read_csv(path + 'sample_submission.csv')\n",
    "\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 237,
     "status": "ok",
     "timestamp": 1633575279669,
     "user": {
      "displayName": "꾸꾸",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "14922489440020274566"
     },
     "user_tz": -540
    },
    "id": "m7Ncehkzk22p",
    "outputId": "d60ed3dc-568c-46ce-bd0c-37e0bde93891"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['acc_x', 'acc_y', 'acc_z', 'gy_x', 'gy_y', 'gy_z'], dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "act_list=train.iloc[:,2:].columns\n",
    "acc_list=['acc_x','acc_y','acc_z']\n",
    "gy_list=['gy_x','gy_y','gy_z']\n",
    "act_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 220,
     "status": "ok",
     "timestamp": 1633575281644,
     "user": {
      "displayName": "꾸꾸",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "14922489440020274566"
     },
     "user_tz": -540
    },
    "id": "sK8gCKp3lp3D"
   },
   "outputs": [],
   "source": [
    "# acc 데이터와 gy 데이터로 분할\n",
    "def sensor_split(data):\n",
    "    X_acc = []\n",
    "    X_gy = []\n",
    "\n",
    "    for i in tqdm(data['id'].unique()):\n",
    "        temp_acc = np.array(data[data['id'] == i].loc[:,acc_list])\n",
    "        temp_gy = np.array(data[data['id'] == i].loc[:,gy_list])\n",
    "        X_acc.append(temp_acc)\n",
    "        X_gy.append(temp_gy)\n",
    "      \n",
    "    X_acc = np.array(X_acc).reshape(-1,600,3)\n",
    "    X_gy = np.array(X_gy).reshape(-1,600,3)\n",
    "\n",
    "    return X_acc, X_gy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 314,
     "status": "ok",
     "timestamp": 1633575283053,
     "user": {
      "displayName": "꾸꾸",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "14922489440020274566"
     },
     "user_tz": -540
    },
    "id": "6p-mjEZaltsK"
   },
   "outputs": [],
   "source": [
    "# 데이터 증강\n",
    "\n",
    "def permutation(X, nPerm=4, minSegLength=10):\n",
    "    X_new = np.zeros(X.shape)\n",
    "    idx = np.random.permutation(nPerm)\n",
    "    bWhile = True\n",
    "    while bWhile == True:\n",
    "        segs = np.zeros(nPerm+1, dtype=int)\n",
    "        segs[1:-1] = np.sort(np.random.randint(minSegLength, X.shape[0]-minSegLength, nPerm-1))\n",
    "        segs[-1] = X.shape[0]\n",
    "        if np.min(segs[1:]-segs[0:-1]) > minSegLength:\n",
    "            bWhile = False\n",
    "    pp = 0\n",
    "    for ii in range(nPerm):\n",
    "        x_temp = X[segs[idx[ii]]:segs[idx[ii]+1],:]\n",
    "        X_new[pp:pp+len(x_temp),:] = x_temp\n",
    "        pp += len(x_temp)\n",
    "    return (X_new)\n",
    "\n",
    "def aug(data, uid, shift):\n",
    "    shift_data = np.roll(data[uid], shift, axis=0)\n",
    "    return shift_data\n",
    "\n",
    "def rolling(data):\n",
    "    aug_data=[]\n",
    "    for i in range(data.shape[0]):\n",
    "        temp=list((aug(data,i,int(random.random()*600))))\n",
    "        aug_data.append(temp)\n",
    "    return np.array(aug_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 339,
     "status": "ok",
     "timestamp": 1633575284341,
     "user": {
      "displayName": "꾸꾸",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "14922489440020274566"
     },
     "user_tz": -540
    },
    "id": "HECv9WwUTQgZ"
   },
   "outputs": [],
   "source": [
    "# 데이터 증강 (반복하고 싶은 만큼 조정)\n",
    "def start_augmentation(train, train_labels):\n",
    "    # acc, gy 데이터 분할\n",
    "    X_train_mod=pd.merge(train,train_labels,how='left',on='id')\n",
    "    X_train_acc, X_train_gy= sensor_split(X_train_mod)\n",
    "\n",
    "    # 증강시키고 추가할 임시 데이터 복사본\n",
    "    X_train_acc_temp = X_train_acc.copy()\n",
    "    X_train_gy_temp = X_train_gy.copy()\n",
    "\n",
    "    # label 데이터 변환\n",
    "    y_train = train_labels['label']\n",
    "    y_train_total = np.append(y_train, y_train, axis=0)\n",
    "\n",
    "    rep = 3 # 5이상의 경우 reshape 과정에서 reset될 가능성 높음\n",
    "    for i in range(rep):\n",
    "        X_train_acc_roll = rolling(X_train_acc_temp)\n",
    "        #X_train_acc_rp = permutation(rolling(X_train_acc_temp)) # rolling + permutation\n",
    "\n",
    "        X_train_gy_roll = rolling(X_train_gy_temp)\n",
    "        #X_train_gy_rp = permutation(rolling(X_train_gy_temp)) # rolling + permutation\n",
    "\n",
    "        # 증강시킨 데이터 원래 데이터에 추가\n",
    "        X_train_acc = np.append(X_train_acc, X_train_acc_roll, axis=0)\n",
    "        #X_train_acc = np.append(X_train_acc, X_train_acc_rp, axis=0)\n",
    "\n",
    "        X_train_gy = np.append(X_train_gy, X_train_gy_roll, axis=0)\n",
    "        #X_train_gy = np.append(X_train_gy, X_train_gy_rp, axis=0)\n",
    "\n",
    "        y_train_total = np.append(y_train_total, y_train, axis=0)\n",
    "        if i != (rep-1): # 마지막 한 번 제외\n",
    "            y_train_total = np.append(y_train_total, y_train, axis=0)\n",
    "\n",
    "    return X_train_acc, X_train_gy, y_train_total "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 41308,
     "status": "ok",
     "timestamp": 1633575326653,
     "user": {
      "displayName": "꾸꾸",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "14922489440020274566"
     },
     "user_tz": -540
    },
    "id": "pwbF7XSAyy4l",
    "outputId": "abaaeb9b-d20e-40e9-eb60-d289c4200bfa"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 3125/3125 [00:37<00:00, 84.33it/s]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'rolling' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-37066a2e7419>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mX_train_acc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_train_gy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train_total\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstart_augmentation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mX_train_acc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_train_gy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train_total\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-5-2c305e7c0ae8>\u001b[0m in \u001b[0;36mstart_augmentation\u001b[1;34m(train, train_labels)\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[0mrep\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m3\u001b[0m \u001b[1;31m# 5이상의 경우 reshape 과정에서 reset될 가능성 높음\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m         \u001b[0mX_train_acc_roll\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrolling\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_acc_temp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m         \u001b[1;31m#X_train_acc_rp = permutation(rolling(X_train_acc_temp)) # rolling + permutation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'rolling' is not defined"
     ]
    }
   ],
   "source": [
    "X_train_acc, X_train_gy, y_train_total = start_augmentation(train, train_labels)\n",
    "\n",
    "X_train_acc.shape, X_train_gy.shape, y_train_total.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 234,
     "status": "ok",
     "timestamp": 1633575331272,
     "user": {
      "displayName": "꾸꾸",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "14922489440020274566"
     },
     "user_tz": -540
    },
    "id": "f_jVLRgKnGeU"
   },
   "outputs": [],
   "source": [
    "# np array 형태를 dataframe 으로 변환\n",
    "def np_to_df(X_train_acc, X_train_gy):\n",
    "    acc = [e for sl in X_train_acc for e in sl]\n",
    "    gy = [e for sl in X_train_gy for e in sl]\n",
    "\n",
    "    df_report_acc = np.stack(acc, axis = 0)\n",
    "    df_report_gy = np.stack(gy, axis = 0)\n",
    "\n",
    "    df_acc = pd.DataFrame(df_report_acc, columns= ['acc_x', 'acc_y', 'acc_z']) \n",
    "    df_gy = pd.DataFrame(df_report_gy, columns= ['gy_x', 'gy_y', 'gy_z']) \n",
    "\n",
    "    # acc, gy 데이터프레임 병합\n",
    "    df_aug_result = pd.concat([df_acc, df_gy], axis = 1)\n",
    "    \n",
    "    return df_aug_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "executionInfo": {
     "elapsed": 49182,
     "status": "ok",
     "timestamp": 1633575382293,
     "user": {
      "displayName": "꾸꾸",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "14922489440020274566"
     },
     "user_tz": -540
    },
    "id": "T0qgbFfRnO_g",
    "outputId": "c74d3319-c29c-462f-f7b8-a87a8872534e"
   },
   "outputs": [],
   "source": [
    "train = np_to_df(X_train_acc, X_train_gy)\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 3503,
     "status": "ok",
     "timestamp": 1633575439192,
     "user": {
      "displayName": "꾸꾸",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "14922489440020274566"
     },
     "user_tz": -540
    },
    "id": "r1o4zGQsqwk7"
   },
   "outputs": [],
   "source": [
    "# 가속도\n",
    "train['acc_t'] = (train['acc_x'] ** 2) + (train['acc_y'] ** 2) + (train['acc_z'] ** 2) ** (1/3)\n",
    "test['acc_t'] = (test['acc_x'] ** 2) + (test['acc_y'] ** 2) + (test['acc_z'] ** 2) ** (1/3)\n",
    "\n",
    "train['gy_t'] = (train['gy_x'] ** 2) + (train['gy_y'] ** 2) + (train['gy_z'] ** 2) ** (1/3)\n",
    "test['gy_t'] = (test['gy_x'] ** 2) + (test['gy_y'] ** 2) + (test['gy_z'] ** 2) ** (1/3)\n",
    "\n",
    "# Signal 극대화 (peak 캐치 유용)\n",
    "train['acc_mag'] = (train['acc_x'] ** 2) + (train['acc_y'] ** 2) + (train['acc_z'] ** 2)\n",
    "test['acc_mag'] = (test['acc_x'] ** 2) + (test['acc_y'] ** 2) + (test['acc_z'] ** 2)\n",
    "\n",
    "train['gy_mag'] = (train['gy_x'] ** 2) + (train['gy_y'] ** 2) + (train['gy_z'] ** 2)\n",
    "test['gy_mag'] = (test['gy_x'] ** 2) + (test['gy_y'] ** 2) + (test['gy_z'] ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1465,
     "status": "ok",
     "timestamp": 1633575442378,
     "user": {
      "displayName": "꾸꾸",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "14922489440020274566"
     },
     "user_tz": -540
    },
    "id": "KE_v-XPXBEwJ"
   },
   "outputs": [],
   "source": [
    "# vector\n",
    "train['acc_vec'] = np.sqrt((train['acc_x'] ** 2) +(train['acc_y'] ** 2)+(train['acc_z'] ** 2))\n",
    "test['acc_vec'] = np.sqrt((test['acc_x'] ** 2) +(test['acc_y'] ** 2)+(test['acc_z'] ** 2))\n",
    "\n",
    "train['gy_vec'] = np.sqrt((train['gy_x'] ** 2) +(train['gy_y'] ** 2)+(train['gy_z'] ** 2))\n",
    "test['gy_vec'] = np.sqrt((test['gy_x'] ** 2) +(test['gy_y'] ** 2)+(test['gy_z'] ** 2))\n",
    "\n",
    "# 자이로스코프 무게중심\n",
    "train['gy_gravity'] = (train['gy_x']+train['gy_y']+train['gy_z'])/3\n",
    "test['gy_gravity'] = (test['gy_x']+test['gy_y']+test['gy_z'])/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 463
    },
    "executionInfo": {
     "elapsed": 6778,
     "status": "ok",
     "timestamp": 1633575451181,
     "user": {
      "displayName": "꾸꾸",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "14922489440020274566"
     },
     "user_tz": -540
    },
    "id": "U_FgcUVljSip",
    "outputId": "46818f84-f768-4a20-ebb6-90ecfa690dc7"
   },
   "outputs": [],
   "source": [
    "# roll & pitch\n",
    "train['roll'] = np.arctan(train['acc_y']/np.sqrt(train['acc_x'] ** 2 + train['acc_z'] ** 2))\n",
    "test['roll'] = np.arctan(test['acc_y']/np.sqrt(test['acc_x'] ** 2 + test['acc_z'] ** 2))\n",
    "\n",
    "train['pitch'] = np.arctan(train['acc_x']/np.sqrt(train['acc_y'] ** 2 + train['acc_z'] ** 2))\n",
    "test['pitch'] = np.arctan(test['acc_x']/np.sqrt(test['acc_y'] ** 2 + test['acc_z'] ** 2))\n",
    "\n",
    "train['math_roll'] = np.arctan(- train['acc_x']/np.sqrt(train['acc_y'] ** 2 + train['acc_z'] ** 2)) * (180/pi)\n",
    "test['math_roll'] = np.arctan(- test['acc_x']/np.sqrt(test['acc_y'] ** 2 + test['acc_z'] ** 2)) * (180/pi)\n",
    "\n",
    "train['math_pitch'] = np.arctan(train['acc_y']/np.sqrt(train['acc_x'] ** 2 + train['acc_z'] ** 2)) * (180/pi)\n",
    "test['math_pitch'] = np.arctan(test['acc_y']/np.sqrt(test['acc_x'] ** 2 + test['acc_z'] ** 2)) * (180/pi)\n",
    "\n",
    "train['gy_roll'] = np.arctan(train['gy_y']/np.sqrt(train['gy_x'] ** 2 + train['gy_z'] ** 2))\n",
    "test['gy_roll'] = np.arctan(test['gy_y']/np.sqrt(test['gy_x'] ** 2 + test['gy_z'] ** 2))\n",
    "\n",
    "train['gy_pitch'] = np.arctan(train['gy_x']/np.sqrt(train['gy_y'] ** 2 + train['gy_z'] ** 2))\n",
    "test['gy_pitch'] = np.arctan(test['gy_x']/np.sqrt(test['gy_y'] ** 2 + test['gy_z'] ** 2))\n",
    "\n",
    "train['gy_math_roll'] = np.arctan(- train['gy_x']/np.sqrt(train['gy_y'] ** 2 + train['gy_z'] ** 2)) * (180/pi)\n",
    "test['gy_math_roll'] = np.arctan(- test['gy_x']/np.sqrt(test['gy_y'] ** 2 + test['gy_z'] ** 2)) * (180/pi)\n",
    "\n",
    "train['gy_math_pitch'] = np.arctan(train['gy_y']/np.sqrt(train['gy_x'] ** 2 + train['gy_z'] ** 2)) * (180/pi)\n",
    "test['gy_math_pitch'] = np.arctan(test['gy_y']/np.sqrt(test['gy_x'] ** 2 + test['gy_z'] ** 2)) * (180/pi)\n",
    "\n",
    "print(train.shape)\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10170,
     "status": "ok",
     "timestamp": 1633575496283,
     "user": {
      "displayName": "꾸꾸",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "14922489440020274566"
     },
     "user_tz": -540
    },
    "id": "KG0UxyQzqy38",
    "outputId": "0c4f5051-26f3-4d65-c806-a6615c4454df"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.93489817,  0.03657354, -0.31330862, ...,  0.05924213,\n",
       "        -0.05924213, -0.71658616],\n",
       "       [ 2.01969699,  0.00673528, -0.37289479, ...,  0.07768724,\n",
       "        -0.07768724, -0.94204715],\n",
       "       [ 2.0372705 ,  0.01260973, -0.49722803, ...,  0.0059123 ,\n",
       "        -0.0059123 , -0.98671563],\n",
       "       ...,\n",
       "       [-0.34391066,  0.25660796, -0.40865771, ..., -0.27397461,\n",
       "         0.27397461, -0.13581192],\n",
       "       [-0.25697945,  0.18887482, -0.38165898, ..., -0.23468183,\n",
       "         0.23468183,  0.85012356],\n",
       "       [-0.18474634,  0.13070128, -0.37485685, ..., -0.03601273,\n",
       "         0.03601273,  1.31550233]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scaling 원하는 걸로 사용\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import Normalizer\n",
    "\n",
    "scaler = RobustScaler()\n",
    "train = scaler.fit_transform(train)\n",
    "test.drop(['id', 'time'], axis=1, inplace=True)\n",
    "test = scaler.transform(test)\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "executionInfo": {
     "elapsed": 2372,
     "status": "ok",
     "timestamp": 1633575503209,
     "user": {
      "displayName": "꾸꾸",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "14922489440020274566"
     },
     "user_tz": -540
    },
    "id": "gqGdCWomjITD"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dropout, LSTM, Input\n",
    "import tensorflow_decision_forests as tfdf\n",
    "\n",
    "from keras.layers import TimeDistributed\n",
    "from keras.layers import Activation, GlobalAveragePooling1D\n",
    "from keras.layers import Dense, Flatten, BatchNormalization\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.models import Model\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras import regularizers\n",
    "from keras.models import load_model\n",
    "from keras.layers.merge import concatenate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 217,
     "status": "ok",
     "timestamp": 1633575505749,
     "user": {
      "displayName": "꾸꾸",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "14922489440020274566"
     },
     "user_tz": -540
    },
    "id": "3G_9MwV3lOCr",
    "outputId": "23a39e54-feb8-4150-bd8b-4c30fb5e989d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21875, 600, 21)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len_features = train.shape[1] # feature 갯수\n",
    "X = train.reshape(-1, 600, len_features)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 229,
     "status": "ok",
     "timestamp": 1633575508579,
     "user": {
      "displayName": "꾸꾸",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "14922489440020274566"
     },
     "user_tz": -540
    },
    "id": "L9BwD5mvnD21",
    "outputId": "4b8caf25-20fe-470e-98ad-65e55d5ad738"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21875, 61)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len_features = train.shape[1] # feature 갯수\n",
    "X = train.reshape(-1, 600, len_features)\n",
    "X.shapey = to_categorical(y_train_total) \n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "executionInfo": {
     "elapsed": 218,
     "status": "ok",
     "timestamp": 1633575510606,
     "user": {
      "displayName": "꾸꾸",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "14922489440020274566"
     },
     "user_tz": -540
    },
    "id": "Yd01SsFRoSc2"
   },
   "outputs": [],
   "source": [
    "epochs, batch_size = 100, 64 # Ram 24GB 기준 256 이상 reset될 가능성 높음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 215,
     "status": "ok",
     "timestamp": 1633575512283,
     "user": {
      "displayName": "꾸꾸",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "14922489440020274566"
     },
     "user_tz": -540
    },
    "id": "RMA0WAJ6q6_2",
    "outputId": "3704bd1c-030b-4878-ef40-6f925f0aad22"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(782, 600, 21)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_X = test.reshape(-1, 600, len_features)\n",
    "test_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "executionInfo": {
     "elapsed": 239,
     "status": "ok",
     "timestamp": 1633575551054,
     "user": {
      "displayName": "꾸꾸",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "14922489440020274566"
     },
     "user_tz": -540
    },
    "id": "WWxrKNusqy3-"
   },
   "outputs": [],
   "source": [
    "#epochs, batch_size = 30, 64\n",
    "n_features, n_outputs = X.shape[2], y.shape[1]\n",
    "# reshape data into time steps of sub-sequences\n",
    "n_steps, n_length = 6, 100\n",
    "X = X.reshape((X.shape[0], n_steps, n_length, n_features))\n",
    "test_X = test_X.reshape((test_X.shape[0], n_steps, n_length, n_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "executionInfo": {
     "elapsed": 647,
     "status": "ok",
     "timestamp": 1633576109381,
     "user": {
      "displayName": "꾸꾸",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "14922489440020274566"
     },
     "user_tz": -540
    },
    "id": "QsJbpKCIjBoc"
   },
   "outputs": [],
   "source": [
    "class Models:\n",
    "    # 각종 사이즈는 다양하게 적용하여 stacking 쌓아 올리기\n",
    "    def define_model_0():\n",
    "        model = Sequential()\n",
    "        model.add(TimeDistributed(Conv1D(filters=64, kernel_size=3, activation='relu'), input_shape=(None,n_length,n_features)))\n",
    "        model.add(TimeDistributed(Conv1D(filters=64, kernel_size=3, activation='relu')))\n",
    "        model.add(TimeDistributed(Dropout(0.5)))\n",
    "        model.add(TimeDistributed(MaxPooling1D(pool_size=2)))\n",
    "        model.add(TimeDistributed(Flatten()))\n",
    "        model.add(LSTM(32))\n",
    "        model.add(Dropout(0.5))\n",
    "        model.add(Dense(128, activation='relu'))\n",
    "        model.add(Dense(n_outputs, activation='softmax'))\n",
    "        model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "        return model\n",
    "\n",
    "    def define_model_1():\n",
    "        model = Sequential()\n",
    "        model.add(TimeDistributed(Conv1D(filters=32, kernel_size=3, activation='relu'), input_shape=(None,n_length,n_features)))\n",
    "        model.add(TimeDistributed(Dropout(0.5)))\n",
    "        model.add(TimeDistributed(Conv1D(filters=32, kernel_size=3, activation='relu')))\n",
    "        model.add(TimeDistributed(MaxPooling1D(pool_size=2)))\n",
    "        model.add(TimeDistributed(Flatten()))\n",
    "        model.add(LSTM(32))\n",
    "        model.add(Dropout(0.5))\n",
    "        model.add(Dense(128, activation='relu'))\n",
    "        model.add(Dense(n_outputs, activation='softmax'))\n",
    "        model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "        return model\n",
    "\n",
    "    def define_model_2():\n",
    "        model = Sequential()\n",
    "        model.add(TimeDistributed(Conv1D(filters=64, kernel_size=6, activation='relu'), input_shape=(None,n_length,n_features)))\n",
    "        model.add(TimeDistributed(Conv1D(filters=64, kernel_size=3, activation='relu')))\n",
    "        model.add(TimeDistributed(Dropout(0.5)))\n",
    "        model.add(TimeDistributed(MaxPooling1D(pool_size=2)))\n",
    "        model.add(TimeDistributed(Flatten()))\n",
    "        model.add(LSTM(32))\n",
    "        model.add(Dropout(0.5))\n",
    "        model.add(Dense(128, activation='relu'))\n",
    "        model.add(Dense(n_outputs, activation='softmax'))\n",
    "        model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "        return model\n",
    "\n",
    "    def define_model_3():\n",
    "        model = Sequential()\n",
    "        model.add(TimeDistributed(Conv1D(filters=32, kernel_size=3, activation='relu'), input_shape=(None,n_length,n_features)))\n",
    "        model.add(TimeDistributed(Conv1D(filters=64, kernel_size=6, activation='relu')))\n",
    "        model.add(TimeDistributed(Dropout(0.5)))\n",
    "        model.add(TimeDistributed(MaxPooling1D(pool_size=2)))\n",
    "        model.add(TimeDistributed(Flatten()))\n",
    "        model.add(LSTM(32))\n",
    "        model.add(Dropout(0.3))\n",
    "        model.add(Dense(128, activation='relu'))\n",
    "        model.add(Dense(n_outputs, activation='softmax'))\n",
    "        model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "        return model\n",
    "\n",
    "    def define_model_4():\n",
    "        model = Sequential()\n",
    "        model.add(TimeDistributed(Conv1D(filters=32, kernel_size=3, activation='relu'), input_shape=(None,n_length,n_features)))\n",
    "        model.add(TimeDistributed(Conv1D(filters=32, kernel_size=3, activation='relu')))\n",
    "        model.add(TimeDistributed(Dropout(0.5)))\n",
    "        model.add(TimeDistributed(GlobalAveragePooling1D()))\n",
    "        model.add(TimeDistributed(Flatten()))\n",
    "        model.add(LSTM(32))\n",
    "        model.add(Dropout(0.5))\n",
    "        model.add(Dense(128, activation='relu'))\n",
    "        model.add(Dense(n_outputs, activation='softmax'))\n",
    "        model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "pvJ-AalijBrV"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "274/274 [==============================] - 31s 105ms/step - loss: 2.7582 - accuracy: 0.4827 - val_loss: 2.6247 - val_accuracy: 0.4919\n",
      "\n",
      "Epoch 00001: loss improved from inf to 2.75816, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 2/100\n",
      "274/274 [==============================] - 28s 103ms/step - loss: 2.4614 - accuracy: 0.4981 - val_loss: 2.5446 - val_accuracy: 0.4917\n",
      "\n",
      "Epoch 00002: loss improved from 2.75816 to 2.46143, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 3/100\n",
      "274/274 [==============================] - 26s 96ms/step - loss: 2.3739 - accuracy: 0.4983 - val_loss: 2.5255 - val_accuracy: 0.4969\n",
      "\n",
      "Epoch 00003: loss improved from 2.46143 to 2.37394, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 4/100\n",
      "274/274 [==============================] - 27s 97ms/step - loss: 2.3066 - accuracy: 0.5007 - val_loss: 2.4943 - val_accuracy: 0.4910\n",
      "\n",
      "Epoch 00004: loss improved from 2.37394 to 2.30664, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 5/100\n",
      "274/274 [==============================] - 26s 95ms/step - loss: 2.2585 - accuracy: 0.5018 - val_loss: 2.4244 - val_accuracy: 0.5006\n",
      "\n",
      "Epoch 00005: loss improved from 2.30664 to 2.25848, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 6/100\n",
      "274/274 [==============================] - 30s 110ms/step - loss: 2.2201 - accuracy: 0.5047 - val_loss: 2.4223 - val_accuracy: 0.5015\n",
      "\n",
      "Epoch 00006: loss improved from 2.25848 to 2.22006, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 7/100\n",
      "274/274 [==============================] - 27s 98ms/step - loss: 2.1771 - accuracy: 0.5109 - val_loss: 2.4148 - val_accuracy: 0.4949\n",
      "\n",
      "Epoch 00007: loss improved from 2.22006 to 2.17714, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 8/100\n",
      "274/274 [==============================] - 28s 101ms/step - loss: 2.1342 - accuracy: 0.5169 - val_loss: 2.4093 - val_accuracy: 0.4983\n",
      "\n",
      "Epoch 00008: loss improved from 2.17714 to 2.13418, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 9/100\n",
      "274/274 [==============================] - 27s 100ms/step - loss: 2.0988 - accuracy: 0.5207 - val_loss: 2.3358 - val_accuracy: 0.5090\n",
      "\n",
      "Epoch 00009: loss improved from 2.13418 to 2.09878, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 10/100\n",
      "274/274 [==============================] - 27s 100ms/step - loss: 2.0702 - accuracy: 0.5241 - val_loss: 2.3172 - val_accuracy: 0.5163\n",
      "\n",
      "Epoch 00010: loss improved from 2.09878 to 2.07018, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 11/100\n",
      "274/274 [==============================] - 27s 99ms/step - loss: 2.0436 - accuracy: 0.5313 - val_loss: 2.3107 - val_accuracy: 0.5159\n",
      "\n",
      "Epoch 00011: loss improved from 2.07018 to 2.04356, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 12/100\n",
      "274/274 [==============================] - 27s 98ms/step - loss: 2.0181 - accuracy: 0.5331 - val_loss: 2.3042 - val_accuracy: 0.5111\n",
      "\n",
      "Epoch 00012: loss improved from 2.04356 to 2.01812, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 13/100\n",
      "274/274 [==============================] - 27s 97ms/step - loss: 1.9960 - accuracy: 0.5363 - val_loss: 2.2822 - val_accuracy: 0.5246\n",
      "\n",
      "Epoch 00013: loss improved from 2.01812 to 1.99599, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 14/100\n",
      "274/274 [==============================] - 27s 98ms/step - loss: 1.9766 - accuracy: 0.5425 - val_loss: 2.2602 - val_accuracy: 0.5312\n",
      "\n",
      "Epoch 00014: loss improved from 1.99599 to 1.97656, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 15/100\n",
      "274/274 [==============================] - 27s 98ms/step - loss: 1.9435 - accuracy: 0.5456 - val_loss: 2.2201 - val_accuracy: 0.5269\n",
      "\n",
      "Epoch 00015: loss improved from 1.97656 to 1.94346, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 16/100\n",
      "274/274 [==============================] - 31s 113ms/step - loss: 1.9387 - accuracy: 0.5455 - val_loss: 2.2336 - val_accuracy: 0.5351\n",
      "\n",
      "Epoch 00016: loss improved from 1.94346 to 1.93871, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 17/100\n",
      "274/274 [==============================] - 27s 100ms/step - loss: 1.9142 - accuracy: 0.5529 - val_loss: 2.2423 - val_accuracy: 0.5319\n",
      "\n",
      "Epoch 00017: loss improved from 1.93871 to 1.91418, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 18/100\n",
      "274/274 [==============================] - 28s 104ms/step - loss: 1.8913 - accuracy: 0.5580 - val_loss: 2.2280 - val_accuracy: 0.5362\n",
      "\n",
      "Epoch 00018: loss improved from 1.91418 to 1.89125, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 19/100\n",
      "274/274 [==============================] - 27s 98ms/step - loss: 1.8690 - accuracy: 0.5629 - val_loss: 2.2088 - val_accuracy: 0.5335\n",
      "\n",
      "Epoch 00019: loss improved from 1.89125 to 1.86899, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 20/100\n",
      "274/274 [==============================] - 28s 100ms/step - loss: 1.8491 - accuracy: 0.5632 - val_loss: 2.1982 - val_accuracy: 0.5433\n",
      "\n",
      "Epoch 00020: loss improved from 1.86899 to 1.84911, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 21/100\n",
      "274/274 [==============================] - 29s 104ms/step - loss: 1.8373 - accuracy: 0.5698 - val_loss: 2.1984 - val_accuracy: 0.5431\n",
      "\n",
      "Epoch 00021: loss improved from 1.84911 to 1.83731, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 22/100\n",
      "274/274 [==============================] - 28s 102ms/step - loss: 1.8295 - accuracy: 0.5691 - val_loss: 2.1776 - val_accuracy: 0.5383\n",
      "\n",
      "Epoch 00022: loss improved from 1.83731 to 1.82946, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 23/100\n",
      "274/274 [==============================] - 31s 112ms/step - loss: 1.8117 - accuracy: 0.5735 - val_loss: 2.2138 - val_accuracy: 0.5349\n",
      "\n",
      "Epoch 00023: loss improved from 1.82946 to 1.81174, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 24/100\n",
      "274/274 [==============================] - 28s 104ms/step - loss: 1.7983 - accuracy: 0.5745 - val_loss: 2.1809 - val_accuracy: 0.5417\n",
      "\n",
      "Epoch 00024: loss improved from 1.81174 to 1.79833, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 25/100\n",
      "274/274 [==============================] - 28s 101ms/step - loss: 1.7907 - accuracy: 0.5782 - val_loss: 2.1817 - val_accuracy: 0.5390\n",
      "\n",
      "Epoch 00025: loss improved from 1.79833 to 1.79074, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 26/100\n",
      "274/274 [==============================] - 27s 98ms/step - loss: 1.7658 - accuracy: 0.5840 - val_loss: 2.1963 - val_accuracy: 0.5381\n",
      "\n",
      "Epoch 00026: loss improved from 1.79074 to 1.76582, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 27/100\n",
      "274/274 [==============================] - 27s 98ms/step - loss: 1.7431 - accuracy: 0.5856 - val_loss: 2.2006 - val_accuracy: 0.5378\n",
      "\n",
      "Epoch 00027: loss improved from 1.76582 to 1.74309, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 28/100\n",
      "274/274 [==============================] - 27s 99ms/step - loss: 1.7353 - accuracy: 0.5878 - val_loss: 2.1829 - val_accuracy: 0.5417\n",
      "\n",
      "Epoch 00028: loss improved from 1.74309 to 1.73529, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 29/100\n",
      "274/274 [==============================] - 26s 96ms/step - loss: 1.7316 - accuracy: 0.5906 - val_loss: 2.1805 - val_accuracy: 0.5392\n",
      "\n",
      "Epoch 00029: loss improved from 1.73529 to 1.73163, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 30/100\n",
      "274/274 [==============================] - 27s 98ms/step - loss: 1.7104 - accuracy: 0.5893 - val_loss: 2.1971 - val_accuracy: 0.5477\n",
      "\n",
      "Epoch 00030: loss improved from 1.73163 to 1.71038, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 31/100\n",
      "274/274 [==============================] - 26s 96ms/step - loss: 1.6958 - accuracy: 0.5919 - val_loss: 2.1866 - val_accuracy: 0.5445\n",
      "\n",
      "Epoch 00031: loss improved from 1.71038 to 1.69575, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 32/100\n",
      "274/274 [==============================] - 27s 97ms/step - loss: 1.6912 - accuracy: 0.5942 - val_loss: 2.1754 - val_accuracy: 0.5483\n",
      "\n",
      "Epoch 00032: loss improved from 1.69575 to 1.69116, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 33/100\n",
      "274/274 [==============================] - 26s 96ms/step - loss: 1.6721 - accuracy: 0.6006 - val_loss: 2.1830 - val_accuracy: 0.5495\n",
      "\n",
      "Epoch 00033: loss improved from 1.69116 to 1.67210, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 34/100\n",
      "274/274 [==============================] - 26s 96ms/step - loss: 1.6657 - accuracy: 0.5986 - val_loss: 2.1846 - val_accuracy: 0.5477\n",
      "\n",
      "Epoch 00034: loss improved from 1.67210 to 1.66572, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 35/100\n",
      "274/274 [==============================] - 26s 96ms/step - loss: 1.6574 - accuracy: 0.6013 - val_loss: 2.2015 - val_accuracy: 0.5481\n",
      "\n",
      "Epoch 00035: loss improved from 1.66572 to 1.65737, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 36/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 26s 96ms/step - loss: 1.6604 - accuracy: 0.5971 - val_loss: 2.1844 - val_accuracy: 0.5422\n",
      "\n",
      "Epoch 00036: loss did not improve from 1.65737\n",
      "Epoch 37/100\n",
      "274/274 [==============================] - 26s 95ms/step - loss: 1.6389 - accuracy: 0.6032 - val_loss: 2.1790 - val_accuracy: 0.5483\n",
      "\n",
      "Epoch 00037: loss improved from 1.65737 to 1.63891, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 38/100\n",
      "274/274 [==============================] - 27s 98ms/step - loss: 1.6300 - accuracy: 0.6070 - val_loss: 2.1790 - val_accuracy: 0.5461\n",
      "\n",
      "Epoch 00038: loss improved from 1.63891 to 1.63001, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 39/100\n",
      "274/274 [==============================] - 30s 108ms/step - loss: 1.6286 - accuracy: 0.6058 - val_loss: 2.1719 - val_accuracy: 0.5481\n",
      "\n",
      "Epoch 00039: loss improved from 1.63001 to 1.62864, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 40/100\n",
      "274/274 [==============================] - 28s 102ms/step - loss: 1.6079 - accuracy: 0.6078 - val_loss: 2.1584 - val_accuracy: 0.5529\n",
      "\n",
      "Epoch 00040: loss improved from 1.62864 to 1.60790, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 41/100\n",
      "274/274 [==============================] - 27s 97ms/step - loss: 1.5996 - accuracy: 0.6105 - val_loss: 2.1730 - val_accuracy: 0.5529\n",
      "\n",
      "Epoch 00041: loss improved from 1.60790 to 1.59962, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 42/100\n",
      "274/274 [==============================] - 27s 98ms/step - loss: 1.5925 - accuracy: 0.6096 - val_loss: 2.1939 - val_accuracy: 0.5529\n",
      "\n",
      "Epoch 00042: loss improved from 1.59962 to 1.59255, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 43/100\n",
      "274/274 [==============================] - 27s 100ms/step - loss: 1.5715 - accuracy: 0.6144 - val_loss: 2.1931 - val_accuracy: 0.5403\n",
      "\n",
      "Epoch 00043: loss improved from 1.59255 to 1.57147, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 44/100\n",
      "274/274 [==============================] - 29s 106ms/step - loss: 1.5781 - accuracy: 0.6109 - val_loss: 2.2170 - val_accuracy: 0.5557\n",
      "\n",
      "Epoch 00044: loss did not improve from 1.57147\n",
      "Epoch 45/100\n",
      "274/274 [==============================] - 27s 99ms/step - loss: 1.5663 - accuracy: 0.6149 - val_loss: 2.2475 - val_accuracy: 0.5472\n",
      "\n",
      "Epoch 00045: loss improved from 1.57147 to 1.56633, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 46/100\n",
      "274/274 [==============================] - 28s 101ms/step - loss: 1.5665 - accuracy: 0.6140 - val_loss: 2.1973 - val_accuracy: 0.5520\n",
      "\n",
      "Epoch 00046: loss did not improve from 1.56633\n",
      "Epoch 47/100\n",
      "274/274 [==============================] - 29s 105ms/step - loss: 1.5621 - accuracy: 0.6158 - val_loss: 2.2170 - val_accuracy: 0.5488\n",
      "\n",
      "Epoch 00047: loss improved from 1.56633 to 1.56206, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 48/100\n",
      "274/274 [==============================] - 27s 99ms/step - loss: 1.5484 - accuracy: 0.6199 - val_loss: 2.2439 - val_accuracy: 0.5566\n",
      "\n",
      "Epoch 00048: loss improved from 1.56206 to 1.54837, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 49/100\n",
      "274/274 [==============================] - 27s 98ms/step - loss: 1.5362 - accuracy: 0.6220 - val_loss: 2.2177 - val_accuracy: 0.5561\n",
      "\n",
      "Epoch 00049: loss improved from 1.54837 to 1.53618, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 50/100\n",
      "274/274 [==============================] - 27s 100ms/step - loss: 1.5338 - accuracy: 0.6221 - val_loss: 2.2007 - val_accuracy: 0.5483\n",
      "\n",
      "Epoch 00050: loss improved from 1.53618 to 1.53385, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 51/100\n",
      "274/274 [==============================] - 28s 101ms/step - loss: 1.5300 - accuracy: 0.6213 - val_loss: 2.2314 - val_accuracy: 0.5527\n",
      "\n",
      "Epoch 00051: loss improved from 1.53385 to 1.53004, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 52/100\n",
      "274/274 [==============================] - 29s 105ms/step - loss: 1.5044 - accuracy: 0.6262 - val_loss: 2.2327 - val_accuracy: 0.5525\n",
      "\n",
      "Epoch 00052: loss improved from 1.53004 to 1.50442, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 53/100\n",
      "274/274 [==============================] - 26s 95ms/step - loss: 1.5046 - accuracy: 0.6263 - val_loss: 2.2570 - val_accuracy: 0.5566\n",
      "\n",
      "Epoch 00053: loss did not improve from 1.50442\n",
      "Epoch 54/100\n",
      "274/274 [==============================] - 27s 98ms/step - loss: 1.4993 - accuracy: 0.6263 - val_loss: 2.2420 - val_accuracy: 0.5568\n",
      "\n",
      "Epoch 00054: loss improved from 1.50442 to 1.49933, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 55/100\n",
      "274/274 [==============================] - 28s 101ms/step - loss: 1.5042 - accuracy: 0.6235 - val_loss: 2.2232 - val_accuracy: 0.5538\n",
      "\n",
      "Epoch 00055: loss did not improve from 1.49933\n",
      "Epoch 56/100\n",
      "274/274 [==============================] - 27s 97ms/step - loss: 1.4965 - accuracy: 0.6270 - val_loss: 2.2142 - val_accuracy: 0.5568\n",
      "\n",
      "Epoch 00056: loss improved from 1.49933 to 1.49649, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 57/100\n",
      "274/274 [==============================] - 26s 94ms/step - loss: 1.4882 - accuracy: 0.6270 - val_loss: 2.2336 - val_accuracy: 0.5506\n",
      "\n",
      "Epoch 00057: loss improved from 1.49649 to 1.48821, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 58/100\n",
      "274/274 [==============================] - 27s 99ms/step - loss: 1.4786 - accuracy: 0.6335 - val_loss: 2.2898 - val_accuracy: 0.5559\n",
      "\n",
      "Epoch 00058: loss improved from 1.48821 to 1.47861, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 59/100\n",
      "274/274 [==============================] - 26s 94ms/step - loss: 1.4749 - accuracy: 0.6330 - val_loss: 2.2391 - val_accuracy: 0.5479\n",
      "\n",
      "Epoch 00059: loss improved from 1.47861 to 1.47489, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 60/100\n",
      "274/274 [==============================] - 26s 95ms/step - loss: 1.4637 - accuracy: 0.6323 - val_loss: 2.2394 - val_accuracy: 0.5513\n",
      "\n",
      "Epoch 00060: loss improved from 1.47489 to 1.46370, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 61/100\n",
      "274/274 [==============================] - 26s 94ms/step - loss: 1.4606 - accuracy: 0.6367 - val_loss: 2.2446 - val_accuracy: 0.5461\n",
      "\n",
      "Epoch 00061: loss improved from 1.46370 to 1.46058, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 62/100\n",
      "274/274 [==============================] - 27s 97ms/step - loss: 1.4490 - accuracy: 0.6380 - val_loss: 2.2737 - val_accuracy: 0.5543\n",
      "\n",
      "Epoch 00062: loss improved from 1.46058 to 1.44903, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 63/100\n",
      "274/274 [==============================] - 27s 99ms/step - loss: 1.4402 - accuracy: 0.6407 - val_loss: 2.2550 - val_accuracy: 0.5525\n",
      "\n",
      "Epoch 00063: loss improved from 1.44903 to 1.44024, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 64/100\n",
      "274/274 [==============================] - 27s 97ms/step - loss: 1.4414 - accuracy: 0.6370 - val_loss: 2.2276 - val_accuracy: 0.5543\n",
      "\n",
      "Epoch 00064: loss did not improve from 1.44024\n",
      "Epoch 65/100\n",
      "274/274 [==============================] - 26s 97ms/step - loss: 1.4315 - accuracy: 0.6385 - val_loss: 2.2408 - val_accuracy: 0.5529\n",
      "\n",
      "Epoch 00065: loss improved from 1.44024 to 1.43150, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 66/100\n",
      "274/274 [==============================] - 26s 96ms/step - loss: 1.4472 - accuracy: 0.6352 - val_loss: 2.2948 - val_accuracy: 0.5557\n",
      "\n",
      "Epoch 00066: loss did not improve from 1.43150\n",
      "Epoch 67/100\n",
      "274/274 [==============================] - 27s 97ms/step - loss: 1.4375 - accuracy: 0.6393 - val_loss: 2.2625 - val_accuracy: 0.5547\n",
      "\n",
      "Epoch 00067: loss did not improve from 1.43150\n",
      "Epoch 68/100\n",
      "274/274 [==============================] - 26s 96ms/step - loss: 1.4294 - accuracy: 0.6374 - val_loss: 2.2869 - val_accuracy: 0.5483\n",
      "\n",
      "Epoch 00068: loss improved from 1.43150 to 1.42939, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 69/100\n",
      "274/274 [==============================] - 26s 96ms/step - loss: 1.4111 - accuracy: 0.6406 - val_loss: 2.2750 - val_accuracy: 0.5497\n",
      "\n",
      "Epoch 00069: loss improved from 1.42939 to 1.41110, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 70/100\n",
      "274/274 [==============================] - 26s 95ms/step - loss: 1.4047 - accuracy: 0.6409 - val_loss: 2.2911 - val_accuracy: 0.5534\n",
      "\n",
      "Epoch 00070: loss improved from 1.41110 to 1.40468, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 71/100\n",
      "274/274 [==============================] - 26s 95ms/step - loss: 1.4149 - accuracy: 0.6424 - val_loss: 2.2449 - val_accuracy: 0.5547\n",
      "\n",
      "Epoch 00071: loss did not improve from 1.40468\n",
      "Epoch 72/100\n",
      "274/274 [==============================] - 26s 95ms/step - loss: 1.4047 - accuracy: 0.6454 - val_loss: 2.3232 - val_accuracy: 0.5543\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00072: loss improved from 1.40468 to 1.40466, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 73/100\n",
      "274/274 [==============================] - 26s 95ms/step - loss: 1.4065 - accuracy: 0.6418 - val_loss: 2.3225 - val_accuracy: 0.5477\n",
      "\n",
      "Epoch 00073: loss did not improve from 1.40466\n",
      "Epoch 74/100\n",
      "274/274 [==============================] - 27s 97ms/step - loss: 1.4013 - accuracy: 0.6451 - val_loss: 2.3095 - val_accuracy: 0.5536\n",
      "\n",
      "Epoch 00074: loss improved from 1.40466 to 1.40134, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 75/100\n",
      "274/274 [==============================] - 26s 95ms/step - loss: 1.4063 - accuracy: 0.6428 - val_loss: 2.2627 - val_accuracy: 0.5474\n",
      "\n",
      "Epoch 00075: loss did not improve from 1.40134\n",
      "Epoch 76/100\n",
      "274/274 [==============================] - 26s 96ms/step - loss: 1.3969 - accuracy: 0.6425 - val_loss: 2.2713 - val_accuracy: 0.5543\n",
      "\n",
      "Epoch 00076: loss improved from 1.40134 to 1.39686, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 77/100\n",
      "274/274 [==============================] - 27s 98ms/step - loss: 1.3830 - accuracy: 0.6459 - val_loss: 2.2782 - val_accuracy: 0.5577\n",
      "\n",
      "Epoch 00077: loss improved from 1.39686 to 1.38297, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 78/100\n",
      "274/274 [==============================] - 27s 97ms/step - loss: 1.3849 - accuracy: 0.6494 - val_loss: 2.2738 - val_accuracy: 0.5497\n",
      "\n",
      "Epoch 00078: loss did not improve from 1.38297\n",
      "Epoch 79/100\n",
      "274/274 [==============================] - 27s 97ms/step - loss: 1.3801 - accuracy: 0.6455 - val_loss: 2.2966 - val_accuracy: 0.5557\n",
      "\n",
      "Epoch 00079: loss improved from 1.38297 to 1.38011, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 80/100\n",
      "274/274 [==============================] - 26s 96ms/step - loss: 1.3824 - accuracy: 0.6466 - val_loss: 2.3015 - val_accuracy: 0.5609\n",
      "\n",
      "Epoch 00080: loss did not improve from 1.38011\n",
      "Epoch 81/100\n",
      "274/274 [==============================] - 26s 96ms/step - loss: 1.3620 - accuracy: 0.6519 - val_loss: 2.2970 - val_accuracy: 0.5570\n",
      "\n",
      "Epoch 00081: loss improved from 1.38011 to 1.36202, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 82/100\n",
      "274/274 [==============================] - 26s 96ms/step - loss: 1.3694 - accuracy: 0.6506 - val_loss: 2.3200 - val_accuracy: 0.5593\n",
      "\n",
      "Epoch 00082: loss did not improve from 1.36202\n",
      "Epoch 83/100\n",
      "274/274 [==============================] - 26s 96ms/step - loss: 1.3510 - accuracy: 0.6513 - val_loss: 2.3506 - val_accuracy: 0.5575\n",
      "\n",
      "Epoch 00083: loss improved from 1.36202 to 1.35096, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 84/100\n",
      "274/274 [==============================] - 26s 96ms/step - loss: 1.3621 - accuracy: 0.6485 - val_loss: 2.3046 - val_accuracy: 0.5584\n",
      "\n",
      "Epoch 00084: loss did not improve from 1.35096\n",
      "Epoch 85/100\n",
      "274/274 [==============================] - 26s 96ms/step - loss: 1.3479 - accuracy: 0.6499 - val_loss: 2.3291 - val_accuracy: 0.5573\n",
      "\n",
      "Epoch 00085: loss improved from 1.35096 to 1.34795, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 86/100\n",
      "274/274 [==============================] - 27s 97ms/step - loss: 1.3473 - accuracy: 0.6534 - val_loss: 2.3432 - val_accuracy: 0.5552\n",
      "\n",
      "Epoch 00086: loss improved from 1.34795 to 1.34729, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 87/100\n",
      "274/274 [==============================] - 26s 95ms/step - loss: 1.3567 - accuracy: 0.6539 - val_loss: 2.3225 - val_accuracy: 0.5543\n",
      "\n",
      "Epoch 00087: loss did not improve from 1.34729\n",
      "Epoch 88/100\n",
      "274/274 [==============================] - 26s 96ms/step - loss: 1.3464 - accuracy: 0.6568 - val_loss: 2.3249 - val_accuracy: 0.5554\n",
      "\n",
      "Epoch 00088: loss improved from 1.34729 to 1.34643, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 89/100\n",
      "274/274 [==============================] - 26s 96ms/step - loss: 1.3354 - accuracy: 0.6553 - val_loss: 2.3303 - val_accuracy: 0.5614\n",
      "\n",
      "Epoch 00089: loss improved from 1.34643 to 1.33543, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 90/100\n",
      "274/274 [==============================] - 26s 97ms/step - loss: 1.3413 - accuracy: 0.6553 - val_loss: 2.3132 - val_accuracy: 0.5609\n",
      "\n",
      "Epoch 00090: loss did not improve from 1.33543\n",
      "Epoch 91/100\n",
      "274/274 [==============================] - 26s 96ms/step - loss: 1.3389 - accuracy: 0.6540 - val_loss: 2.3489 - val_accuracy: 0.5554\n",
      "\n",
      "Epoch 00091: loss did not improve from 1.33543\n",
      "Epoch 92/100\n",
      "274/274 [==============================] - 26s 96ms/step - loss: 1.3291 - accuracy: 0.6576 - val_loss: 2.3602 - val_accuracy: 0.5522\n",
      "\n",
      "Epoch 00092: loss improved from 1.33543 to 1.32913, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 93/100\n",
      "274/274 [==============================] - 26s 96ms/step - loss: 1.3329 - accuracy: 0.6557 - val_loss: 2.3918 - val_accuracy: 0.5529\n",
      "\n",
      "Epoch 00093: loss did not improve from 1.32913\n",
      "Epoch 94/100\n",
      "274/274 [==============================] - 26s 96ms/step - loss: 1.3334 - accuracy: 0.6550 - val_loss: 2.3273 - val_accuracy: 0.5541\n",
      "\n",
      "Epoch 00094: loss did not improve from 1.32913\n",
      "Epoch 95/100\n",
      "274/274 [==============================] - 26s 96ms/step - loss: 1.3280 - accuracy: 0.6565 - val_loss: 2.3221 - val_accuracy: 0.5557\n",
      "\n",
      "Epoch 00095: loss improved from 1.32913 to 1.32797, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 96/100\n",
      "274/274 [==============================] - 26s 96ms/step - loss: 1.3169 - accuracy: 0.6561 - val_loss: 2.3434 - val_accuracy: 0.5536\n",
      "\n",
      "Epoch 00096: loss improved from 1.32797 to 1.31690, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 97/100\n",
      "274/274 [==============================] - 27s 97ms/step - loss: 1.3108 - accuracy: 0.6601 - val_loss: 2.3800 - val_accuracy: 0.5561\n",
      "\n",
      "Epoch 00097: loss improved from 1.31690 to 1.31083, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 98/100\n",
      "274/274 [==============================] - 26s 96ms/step - loss: 1.3223 - accuracy: 0.6614 - val_loss: 2.3344 - val_accuracy: 0.5522\n",
      "\n",
      "Epoch 00098: loss did not improve from 1.31083\n",
      "Epoch 99/100\n",
      "274/274 [==============================] - 26s 96ms/step - loss: 1.3247 - accuracy: 0.6541 - val_loss: 2.4101 - val_accuracy: 0.5577\n",
      "\n",
      "Epoch 00099: loss did not improve from 1.31083\n",
      "Epoch 100/100\n",
      "274/274 [==============================] - 26s 96ms/step - loss: 1.3079 - accuracy: 0.6601 - val_loss: 2.4054 - val_accuracy: 0.5653\n",
      "\n",
      "Epoch 00100: loss improved from 1.31083 to 1.30786, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 1/100\n",
      "274/274 [==============================] - 16s 49ms/step - loss: 2.7995 - accuracy: 0.4831 - val_loss: 2.7452 - val_accuracy: 0.4862\n",
      "\n",
      "Epoch 00001: loss improved from inf to 2.79954, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 2/100\n",
      "274/274 [==============================] - 12s 45ms/step - loss: 2.5721 - accuracy: 0.4887 - val_loss: 2.6136 - val_accuracy: 0.4901\n",
      "\n",
      "Epoch 00002: loss improved from 2.79954 to 2.57210, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 3/100\n",
      "274/274 [==============================] - 12s 45ms/step - loss: 2.4075 - accuracy: 0.4952 - val_loss: 2.6123 - val_accuracy: 0.4699\n",
      "\n",
      "Epoch 00003: loss improved from 2.57210 to 2.40754, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 4/100\n",
      "274/274 [==============================] - 12s 45ms/step - loss: 2.3233 - accuracy: 0.4979 - val_loss: 2.5396 - val_accuracy: 0.4763\n",
      "\n",
      "Epoch 00004: loss improved from 2.40754 to 2.32332, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 5/100\n",
      "274/274 [==============================] - 12s 45ms/step - loss: 2.2391 - accuracy: 0.5055 - val_loss: 2.5390 - val_accuracy: 0.4768\n",
      "\n",
      "Epoch 00005: loss improved from 2.32332 to 2.23907, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 6/100\n",
      "274/274 [==============================] - 13s 46ms/step - loss: 2.1991 - accuracy: 0.5077 - val_loss: 2.4692 - val_accuracy: 0.4823\n",
      "\n",
      "Epoch 00006: loss improved from 2.23907 to 2.19906, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 7/100\n",
      "274/274 [==============================] - 13s 46ms/step - loss: 2.1450 - accuracy: 0.5135 - val_loss: 2.4274 - val_accuracy: 0.4846\n",
      "\n",
      "Epoch 00007: loss improved from 2.19906 to 2.14502, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 8/100\n",
      "274/274 [==============================] - 13s 46ms/step - loss: 2.0952 - accuracy: 0.5237 - val_loss: 2.4117 - val_accuracy: 0.4866\n",
      "\n",
      "Epoch 00008: loss improved from 2.14502 to 2.09515, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 9/100\n",
      "274/274 [==============================] - 13s 46ms/step - loss: 2.0473 - accuracy: 0.5303 - val_loss: 2.3699 - val_accuracy: 0.4955\n",
      "\n",
      "Epoch 00009: loss improved from 2.09515 to 2.04729, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 10/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 13s 46ms/step - loss: 2.0186 - accuracy: 0.5369 - val_loss: 2.3486 - val_accuracy: 0.4994\n",
      "\n",
      "Epoch 00010: loss improved from 2.04729 to 2.01864, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 11/100\n",
      "274/274 [==============================] - 13s 46ms/step - loss: 1.9672 - accuracy: 0.5463 - val_loss: 2.2819 - val_accuracy: 0.5086\n",
      "\n",
      "Epoch 00011: loss improved from 2.01864 to 1.96716, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 12/100\n",
      "274/274 [==============================] - 13s 46ms/step - loss: 1.9367 - accuracy: 0.5518 - val_loss: 2.3255 - val_accuracy: 0.5051\n",
      "\n",
      "Epoch 00012: loss improved from 1.96716 to 1.93672, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 13/100\n",
      "274/274 [==============================] - 13s 46ms/step - loss: 1.9093 - accuracy: 0.5549 - val_loss: 2.3376 - val_accuracy: 0.4985\n",
      "\n",
      "Epoch 00013: loss improved from 1.93672 to 1.90931, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 14/100\n",
      "274/274 [==============================] - 13s 46ms/step - loss: 1.8850 - accuracy: 0.5621 - val_loss: 2.2929 - val_accuracy: 0.5051\n",
      "\n",
      "Epoch 00014: loss improved from 1.90931 to 1.88498, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 15/100\n",
      "274/274 [==============================] - 13s 47ms/step - loss: 1.8558 - accuracy: 0.5665 - val_loss: 2.2681 - val_accuracy: 0.5054\n",
      "\n",
      "Epoch 00015: loss improved from 1.88498 to 1.85581, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 16/100\n",
      "274/274 [==============================] - 13s 47ms/step - loss: 1.8304 - accuracy: 0.5716 - val_loss: 2.2784 - val_accuracy: 0.5070\n",
      "\n",
      "Epoch 00016: loss improved from 1.85581 to 1.83041, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 17/100\n",
      "274/274 [==============================] - 13s 46ms/step - loss: 1.8151 - accuracy: 0.5766 - val_loss: 2.2370 - val_accuracy: 0.5179\n",
      "\n",
      "Epoch 00017: loss improved from 1.83041 to 1.81506, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 18/100\n",
      "274/274 [==============================] - 13s 46ms/step - loss: 1.7925 - accuracy: 0.5794 - val_loss: 2.2498 - val_accuracy: 0.5081\n",
      "\n",
      "Epoch 00018: loss improved from 1.81506 to 1.79253, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 19/100\n",
      "274/274 [==============================] - 13s 46ms/step - loss: 1.7764 - accuracy: 0.5823 - val_loss: 2.2659 - val_accuracy: 0.5120\n",
      "\n",
      "Epoch 00019: loss improved from 1.79253 to 1.77637, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 20/100\n",
      "274/274 [==============================] - 13s 46ms/step - loss: 1.7597 - accuracy: 0.5865 - val_loss: 2.2377 - val_accuracy: 0.5147\n",
      "\n",
      "Epoch 00020: loss improved from 1.77637 to 1.75970, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 21/100\n",
      "274/274 [==============================] - 13s 46ms/step - loss: 1.7354 - accuracy: 0.5934 - val_loss: 2.2326 - val_accuracy: 0.5159\n",
      "\n",
      "Epoch 00021: loss improved from 1.75970 to 1.73540, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 22/100\n",
      "274/274 [==============================] - 13s 46ms/step - loss: 1.7278 - accuracy: 0.5908 - val_loss: 2.2290 - val_accuracy: 0.5125\n",
      "\n",
      "Epoch 00022: loss improved from 1.73540 to 1.72785, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 23/100\n",
      "274/274 [==============================] - 13s 46ms/step - loss: 1.7039 - accuracy: 0.5975 - val_loss: 2.2171 - val_accuracy: 0.5214\n",
      "\n",
      "Epoch 00023: loss improved from 1.72785 to 1.70391, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 24/100\n",
      "274/274 [==============================] - 13s 46ms/step - loss: 1.6835 - accuracy: 0.5971 - val_loss: 2.2647 - val_accuracy: 0.5189\n",
      "\n",
      "Epoch 00024: loss improved from 1.70391 to 1.68354, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 25/100\n",
      "274/274 [==============================] - 13s 46ms/step - loss: 1.6854 - accuracy: 0.5979 - val_loss: 2.1958 - val_accuracy: 0.5246\n",
      "\n",
      "Epoch 00025: loss did not improve from 1.68354\n",
      "Epoch 26/100\n",
      "274/274 [==============================] - 13s 46ms/step - loss: 1.6693 - accuracy: 0.6031 - val_loss: 2.2012 - val_accuracy: 0.5291\n",
      "\n",
      "Epoch 00026: loss improved from 1.68354 to 1.66932, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 27/100\n",
      "274/274 [==============================] - 13s 46ms/step - loss: 1.6423 - accuracy: 0.6073 - val_loss: 2.1966 - val_accuracy: 0.5328\n",
      "\n",
      "Epoch 00027: loss improved from 1.66932 to 1.64227, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 28/100\n",
      "274/274 [==============================] - 13s 46ms/step - loss: 1.6410 - accuracy: 0.6086 - val_loss: 2.2054 - val_accuracy: 0.5280\n",
      "\n",
      "Epoch 00028: loss improved from 1.64227 to 1.64105, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 29/100\n",
      "274/274 [==============================] - 13s 46ms/step - loss: 1.6215 - accuracy: 0.6131 - val_loss: 2.2283 - val_accuracy: 0.5230\n",
      "\n",
      "Epoch 00029: loss improved from 1.64105 to 1.62152, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 30/100\n",
      "274/274 [==============================] - 13s 46ms/step - loss: 1.6052 - accuracy: 0.6154 - val_loss: 2.2189 - val_accuracy: 0.5230\n",
      "\n",
      "Epoch 00030: loss improved from 1.62152 to 1.60522, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 31/100\n",
      "274/274 [==============================] - 13s 46ms/step - loss: 1.5977 - accuracy: 0.6185 - val_loss: 2.2542 - val_accuracy: 0.5189\n",
      "\n",
      "Epoch 00031: loss improved from 1.60522 to 1.59773, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 32/100\n",
      "274/274 [==============================] - 13s 46ms/step - loss: 1.6047 - accuracy: 0.6143 - val_loss: 2.2300 - val_accuracy: 0.5173\n",
      "\n",
      "Epoch 00032: loss did not improve from 1.59773\n",
      "Epoch 33/100\n",
      "274/274 [==============================] - 13s 46ms/step - loss: 1.5824 - accuracy: 0.6206 - val_loss: 2.1943 - val_accuracy: 0.5273\n",
      "\n",
      "Epoch 00033: loss improved from 1.59773 to 1.58236, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 34/100\n",
      "274/274 [==============================] - 13s 46ms/step - loss: 1.5730 - accuracy: 0.6229 - val_loss: 2.2188 - val_accuracy: 0.5248\n",
      "\n",
      "Epoch 00034: loss improved from 1.58236 to 1.57301, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 35/100\n",
      "274/274 [==============================] - 13s 46ms/step - loss: 1.5561 - accuracy: 0.6224 - val_loss: 2.2266 - val_accuracy: 0.5273\n",
      "\n",
      "Epoch 00035: loss improved from 1.57301 to 1.55614, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 36/100\n",
      "274/274 [==============================] - 13s 46ms/step - loss: 1.5505 - accuracy: 0.6271 - val_loss: 2.2277 - val_accuracy: 0.5248\n",
      "\n",
      "Epoch 00036: loss improved from 1.55614 to 1.55053, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 37/100\n",
      "274/274 [==============================] - 13s 46ms/step - loss: 1.5373 - accuracy: 0.6249 - val_loss: 2.2481 - val_accuracy: 0.5200\n",
      "\n",
      "Epoch 00037: loss improved from 1.55053 to 1.53732, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 38/100\n",
      "274/274 [==============================] - 13s 46ms/step - loss: 1.5339 - accuracy: 0.6286 - val_loss: 2.2341 - val_accuracy: 0.5216\n",
      "\n",
      "Epoch 00038: loss improved from 1.53732 to 1.53390, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 39/100\n",
      "274/274 [==============================] - 13s 46ms/step - loss: 1.5203 - accuracy: 0.6316 - val_loss: 2.2315 - val_accuracy: 0.5221\n",
      "\n",
      "Epoch 00039: loss improved from 1.53390 to 1.52030, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 40/100\n",
      "274/274 [==============================] - 13s 46ms/step - loss: 1.4996 - accuracy: 0.6351 - val_loss: 2.2361 - val_accuracy: 0.5221\n",
      "\n",
      "Epoch 00040: loss improved from 1.52030 to 1.49957, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 41/100\n",
      "274/274 [==============================] - 13s 49ms/step - loss: 1.4946 - accuracy: 0.6349 - val_loss: 2.2389 - val_accuracy: 0.5211\n",
      "\n",
      "Epoch 00041: loss improved from 1.49957 to 1.49463, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 42/100\n",
      "274/274 [==============================] - 13s 47ms/step - loss: 1.5213 - accuracy: 0.6318 - val_loss: 2.2410 - val_accuracy: 0.5214\n",
      "\n",
      "Epoch 00042: loss did not improve from 1.49463\n",
      "Epoch 43/100\n",
      "274/274 [==============================] - 13s 48ms/step - loss: 1.4818 - accuracy: 0.6368 - val_loss: 2.2338 - val_accuracy: 0.5234\n",
      "\n",
      "Epoch 00043: loss improved from 1.49463 to 1.48177, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 44/100\n",
      "274/274 [==============================] - 14s 50ms/step - loss: 1.4693 - accuracy: 0.6398 - val_loss: 2.2446 - val_accuracy: 0.5264\n",
      "\n",
      "Epoch 00044: loss improved from 1.48177 to 1.46926, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 45/100\n",
      "274/274 [==============================] - 13s 48ms/step - loss: 1.4681 - accuracy: 0.6372 - val_loss: 2.2681 - val_accuracy: 0.5280\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00045: loss improved from 1.46926 to 1.46811, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 46/100\n",
      "274/274 [==============================] - 13s 47ms/step - loss: 1.4540 - accuracy: 0.6464 - val_loss: 2.2499 - val_accuracy: 0.5291\n",
      "\n",
      "Epoch 00046: loss improved from 1.46811 to 1.45404, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 47/100\n",
      "274/274 [==============================] - 13s 48ms/step - loss: 1.4483 - accuracy: 0.6438 - val_loss: 2.2749 - val_accuracy: 0.5237\n",
      "\n",
      "Epoch 00047: loss improved from 1.45404 to 1.44832, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 48/100\n",
      "274/274 [==============================] - 13s 48ms/step - loss: 1.4398 - accuracy: 0.6434 - val_loss: 2.2576 - val_accuracy: 0.5248\n",
      "\n",
      "Epoch 00048: loss improved from 1.44832 to 1.43983, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 49/100\n",
      "274/274 [==============================] - 13s 48ms/step - loss: 1.4350 - accuracy: 0.6461 - val_loss: 2.2788 - val_accuracy: 0.5225\n",
      "\n",
      "Epoch 00049: loss improved from 1.43983 to 1.43498, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 50/100\n",
      "274/274 [==============================] - 13s 48ms/step - loss: 1.4233 - accuracy: 0.6509 - val_loss: 2.2434 - val_accuracy: 0.5221\n",
      "\n",
      "Epoch 00050: loss improved from 1.43498 to 1.42330, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 51/100\n",
      "274/274 [==============================] - 13s 48ms/step - loss: 1.4171 - accuracy: 0.6490 - val_loss: 2.2862 - val_accuracy: 0.5138\n",
      "\n",
      "Epoch 00051: loss improved from 1.42330 to 1.41709, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 52/100\n",
      "274/274 [==============================] - 13s 46ms/step - loss: 1.4147 - accuracy: 0.6467 - val_loss: 2.2470 - val_accuracy: 0.5259\n",
      "\n",
      "Epoch 00052: loss improved from 1.41709 to 1.41472, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 53/100\n",
      "274/274 [==============================] - 13s 46ms/step - loss: 1.3959 - accuracy: 0.6539 - val_loss: 2.2724 - val_accuracy: 0.5234\n",
      "\n",
      "Epoch 00053: loss improved from 1.41472 to 1.39587, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 54/100\n",
      "274/274 [==============================] - 13s 48ms/step - loss: 1.4030 - accuracy: 0.6521 - val_loss: 2.2797 - val_accuracy: 0.5195\n",
      "\n",
      "Epoch 00054: loss did not improve from 1.39587\n",
      "Epoch 55/100\n",
      "274/274 [==============================] - 13s 46ms/step - loss: 1.3966 - accuracy: 0.6505 - val_loss: 2.2848 - val_accuracy: 0.5223\n",
      "\n",
      "Epoch 00055: loss did not improve from 1.39587\n",
      "Epoch 56/100\n",
      "274/274 [==============================] - 13s 47ms/step - loss: 1.3767 - accuracy: 0.6542 - val_loss: 2.2892 - val_accuracy: 0.5211\n",
      "\n",
      "Epoch 00056: loss improved from 1.39587 to 1.37671, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 57/100\n",
      "274/274 [==============================] - 13s 48ms/step - loss: 1.3742 - accuracy: 0.6585 - val_loss: 2.2861 - val_accuracy: 0.5259\n",
      "\n",
      "Epoch 00057: loss improved from 1.37671 to 1.37417, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 58/100\n",
      "274/274 [==============================] - 13s 47ms/step - loss: 1.3729 - accuracy: 0.6549 - val_loss: 2.3489 - val_accuracy: 0.5079\n",
      "\n",
      "Epoch 00058: loss improved from 1.37417 to 1.37291, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 59/100\n",
      "274/274 [==============================] - 13s 47ms/step - loss: 1.3567 - accuracy: 0.6584 - val_loss: 2.3269 - val_accuracy: 0.5211\n",
      "\n",
      "Epoch 00059: loss improved from 1.37291 to 1.35672, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 60/100\n",
      "274/274 [==============================] - 13s 48ms/step - loss: 1.3524 - accuracy: 0.6613 - val_loss: 2.2918 - val_accuracy: 0.5221\n",
      "\n",
      "Epoch 00060: loss improved from 1.35672 to 1.35237, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 61/100\n",
      "274/274 [==============================] - 13s 48ms/step - loss: 1.3413 - accuracy: 0.6637 - val_loss: 2.2889 - val_accuracy: 0.5246\n",
      "\n",
      "Epoch 00061: loss improved from 1.35237 to 1.34134, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 62/100\n",
      "274/274 [==============================] - 13s 48ms/step - loss: 1.3352 - accuracy: 0.6649 - val_loss: 2.3152 - val_accuracy: 0.5216\n",
      "\n",
      "Epoch 00062: loss improved from 1.34134 to 1.33523, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 63/100\n",
      "274/274 [==============================] - 13s 48ms/step - loss: 1.3367 - accuracy: 0.6618 - val_loss: 2.3281 - val_accuracy: 0.5189\n",
      "\n",
      "Epoch 00063: loss did not improve from 1.33523\n",
      "Epoch 64/100\n",
      "274/274 [==============================] - 13s 48ms/step - loss: 1.3351 - accuracy: 0.6617 - val_loss: 2.3159 - val_accuracy: 0.5278\n",
      "\n",
      "Epoch 00064: loss improved from 1.33523 to 1.33511, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 65/100\n",
      "274/274 [==============================] - 13s 48ms/step - loss: 1.3254 - accuracy: 0.6645 - val_loss: 2.3278 - val_accuracy: 0.5257\n",
      "\n",
      "Epoch 00065: loss improved from 1.33511 to 1.32539, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 66/100\n",
      "274/274 [==============================] - 13s 48ms/step - loss: 1.3012 - accuracy: 0.6705 - val_loss: 2.3478 - val_accuracy: 0.5182\n",
      "\n",
      "Epoch 00066: loss improved from 1.32539 to 1.30123, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 67/100\n",
      "274/274 [==============================] - 13s 47ms/step - loss: 1.3126 - accuracy: 0.6652 - val_loss: 2.3448 - val_accuracy: 0.5211\n",
      "\n",
      "Epoch 00067: loss did not improve from 1.30123\n",
      "Epoch 68/100\n",
      "274/274 [==============================] - 13s 48ms/step - loss: 1.3167 - accuracy: 0.6659 - val_loss: 2.3295 - val_accuracy: 0.5275\n",
      "\n",
      "Epoch 00068: loss did not improve from 1.30123\n",
      "Epoch 69/100\n",
      "274/274 [==============================] - 13s 48ms/step - loss: 1.3040 - accuracy: 0.6700 - val_loss: 2.3370 - val_accuracy: 0.5259\n",
      "\n",
      "Epoch 00069: loss did not improve from 1.30123\n",
      "Epoch 70/100\n",
      "274/274 [==============================] - 13s 48ms/step - loss: 1.2965 - accuracy: 0.6659 - val_loss: 2.3445 - val_accuracy: 0.5211\n",
      "\n",
      "Epoch 00070: loss improved from 1.30123 to 1.29647, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 71/100\n",
      "274/274 [==============================] - 13s 49ms/step - loss: 1.2778 - accuracy: 0.6730 - val_loss: 2.3821 - val_accuracy: 0.5143\n",
      "\n",
      "Epoch 00071: loss improved from 1.29647 to 1.27784, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 72/100\n",
      "274/274 [==============================] - 13s 48ms/step - loss: 1.2838 - accuracy: 0.6700 - val_loss: 2.3657 - val_accuracy: 0.5193\n",
      "\n",
      "Epoch 00072: loss did not improve from 1.27784\n",
      "Epoch 73/100\n",
      "274/274 [==============================] - 13s 48ms/step - loss: 1.2735 - accuracy: 0.6719 - val_loss: 2.3640 - val_accuracy: 0.5246\n",
      "\n",
      "Epoch 00073: loss improved from 1.27784 to 1.27348, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 74/100\n",
      "274/274 [==============================] - 13s 48ms/step - loss: 1.2787 - accuracy: 0.6695 - val_loss: 2.3780 - val_accuracy: 0.5264\n",
      "\n",
      "Epoch 00074: loss did not improve from 1.27348\n",
      "Epoch 75/100\n",
      "274/274 [==============================] - 13s 49ms/step - loss: 1.2644 - accuracy: 0.6755 - val_loss: 2.3358 - val_accuracy: 0.5301\n",
      "\n",
      "Epoch 00075: loss improved from 1.27348 to 1.26439, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 76/100\n",
      "274/274 [==============================] - 13s 48ms/step - loss: 1.2580 - accuracy: 0.6741 - val_loss: 2.3625 - val_accuracy: 0.5168\n",
      "\n",
      "Epoch 00076: loss improved from 1.26439 to 1.25800, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 77/100\n",
      "274/274 [==============================] - 13s 48ms/step - loss: 1.2782 - accuracy: 0.6695 - val_loss: 2.3648 - val_accuracy: 0.5193\n",
      "\n",
      "Epoch 00077: loss did not improve from 1.25800\n",
      "Epoch 78/100\n",
      "274/274 [==============================] - 13s 48ms/step - loss: 1.2541 - accuracy: 0.6758 - val_loss: 2.3882 - val_accuracy: 0.5225\n",
      "\n",
      "Epoch 00078: loss improved from 1.25800 to 1.25406, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 79/100\n",
      "274/274 [==============================] - 13s 48ms/step - loss: 1.2559 - accuracy: 0.6763 - val_loss: 2.3999 - val_accuracy: 0.5173\n",
      "\n",
      "Epoch 00079: loss did not improve from 1.25406\n",
      "Epoch 80/100\n",
      "274/274 [==============================] - 13s 49ms/step - loss: 1.2469 - accuracy: 0.6735 - val_loss: 2.3954 - val_accuracy: 0.5205\n",
      "\n",
      "Epoch 00080: loss improved from 1.25406 to 1.24685, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 81/100\n",
      "274/274 [==============================] - 13s 49ms/step - loss: 1.2421 - accuracy: 0.6779 - val_loss: 2.4519 - val_accuracy: 0.5131\n",
      "\n",
      "Epoch 00081: loss improved from 1.24685 to 1.24214, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 82/100\n",
      "274/274 [==============================] - 13s 49ms/step - loss: 1.2309 - accuracy: 0.6790 - val_loss: 2.4287 - val_accuracy: 0.5193\n",
      "\n",
      "Epoch 00082: loss improved from 1.24214 to 1.23091, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 83/100\n",
      "274/274 [==============================] - 13s 49ms/step - loss: 1.2343 - accuracy: 0.6802 - val_loss: 2.4257 - val_accuracy: 0.5118\n",
      "\n",
      "Epoch 00083: loss did not improve from 1.23091\n",
      "Epoch 84/100\n",
      "274/274 [==============================] - 13s 49ms/step - loss: 1.2216 - accuracy: 0.6803 - val_loss: 2.3585 - val_accuracy: 0.5351\n",
      "\n",
      "Epoch 00084: loss improved from 1.23091 to 1.22161, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 85/100\n",
      "274/274 [==============================] - 13s 49ms/step - loss: 1.2312 - accuracy: 0.6813 - val_loss: 2.4006 - val_accuracy: 0.5239\n",
      "\n",
      "Epoch 00085: loss did not improve from 1.22161\n",
      "Epoch 86/100\n",
      "274/274 [==============================] - 13s 49ms/step - loss: 1.2330 - accuracy: 0.6757 - val_loss: 2.4132 - val_accuracy: 0.5173\n",
      "\n",
      "Epoch 00086: loss did not improve from 1.22161\n",
      "Epoch 87/100\n",
      "274/274 [==============================] - 13s 49ms/step - loss: 1.2260 - accuracy: 0.6763 - val_loss: 2.4515 - val_accuracy: 0.5065\n",
      "\n",
      "Epoch 00087: loss did not improve from 1.22161\n",
      "Epoch 88/100\n",
      "274/274 [==============================] - 13s 49ms/step - loss: 1.2122 - accuracy: 0.6829 - val_loss: 2.4447 - val_accuracy: 0.5141\n",
      "\n",
      "Epoch 00088: loss improved from 1.22161 to 1.21215, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 89/100\n",
      "274/274 [==============================] - 14s 49ms/step - loss: 1.2118 - accuracy: 0.6826 - val_loss: 2.4252 - val_accuracy: 0.5154\n",
      "\n",
      "Epoch 00089: loss improved from 1.21215 to 1.21184, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 90/100\n",
      "274/274 [==============================] - 13s 48ms/step - loss: 1.2162 - accuracy: 0.6815 - val_loss: 2.4322 - val_accuracy: 0.5129\n",
      "\n",
      "Epoch 00090: loss did not improve from 1.21184\n",
      "Epoch 91/100\n",
      "274/274 [==============================] - 13s 49ms/step - loss: 1.2069 - accuracy: 0.6836 - val_loss: 2.4123 - val_accuracy: 0.5131\n",
      "\n",
      "Epoch 00091: loss improved from 1.21184 to 1.20686, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 92/100\n",
      "274/274 [==============================] - 13s 49ms/step - loss: 1.2042 - accuracy: 0.6829 - val_loss: 2.4279 - val_accuracy: 0.5189\n",
      "\n",
      "Epoch 00092: loss improved from 1.20686 to 1.20423, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 93/100\n",
      "274/274 [==============================] - 13s 49ms/step - loss: 1.1971 - accuracy: 0.6822 - val_loss: 2.4344 - val_accuracy: 0.5275\n",
      "\n",
      "Epoch 00093: loss improved from 1.20423 to 1.19714, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 94/100\n",
      "274/274 [==============================] - 13s 49ms/step - loss: 1.1971 - accuracy: 0.6828 - val_loss: 2.4375 - val_accuracy: 0.5218\n",
      "\n",
      "Epoch 00094: loss improved from 1.19714 to 1.19711, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 95/100\n",
      "274/274 [==============================] - 13s 49ms/step - loss: 1.1918 - accuracy: 0.6859 - val_loss: 2.4966 - val_accuracy: 0.5013\n",
      "\n",
      "Epoch 00095: loss improved from 1.19711 to 1.19177, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 96/100\n",
      "274/274 [==============================] - 13s 47ms/step - loss: 1.1845 - accuracy: 0.6864 - val_loss: 2.4894 - val_accuracy: 0.5067\n",
      "\n",
      "Epoch 00096: loss improved from 1.19177 to 1.18447, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 97/100\n",
      "274/274 [==============================] - 13s 46ms/step - loss: 1.1807 - accuracy: 0.6905 - val_loss: 2.4790 - val_accuracy: 0.5182\n",
      "\n",
      "Epoch 00097: loss improved from 1.18447 to 1.18067, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 98/100\n",
      "274/274 [==============================] - 13s 46ms/step - loss: 1.1705 - accuracy: 0.6900 - val_loss: 2.5139 - val_accuracy: 0.5081\n",
      "\n",
      "Epoch 00098: loss improved from 1.18067 to 1.17054, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 99/100\n",
      "274/274 [==============================] - 13s 46ms/step - loss: 1.1773 - accuracy: 0.6898 - val_loss: 2.5148 - val_accuracy: 0.5026\n",
      "\n",
      "Epoch 00099: loss did not improve from 1.17054\n",
      "Epoch 100/100\n",
      "274/274 [==============================] - 13s 46ms/step - loss: 1.1785 - accuracy: 0.6869 - val_loss: 2.5242 - val_accuracy: 0.5026\n",
      "\n",
      "Epoch 00100: loss did not improve from 1.17054\n",
      "Epoch 1/100\n",
      "274/274 [==============================] - 27s 92ms/step - loss: 2.7844 - accuracy: 0.4810 - val_loss: 2.6853 - val_accuracy: 0.4862\n",
      "\n",
      "Epoch 00001: loss improved from inf to 2.78439, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 2/100\n",
      "274/274 [==============================] - 26s 94ms/step - loss: 2.5854 - accuracy: 0.4889 - val_loss: 2.6317 - val_accuracy: 0.4923\n",
      "\n",
      "Epoch 00002: loss improved from 2.78439 to 2.58537, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 3/100\n",
      "274/274 [==============================] - 26s 93ms/step - loss: 2.4912 - accuracy: 0.4906 - val_loss: 2.5712 - val_accuracy: 0.4939\n",
      "\n",
      "Epoch 00003: loss improved from 2.58537 to 2.49116, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 4/100\n",
      "274/274 [==============================] - 26s 94ms/step - loss: 2.4296 - accuracy: 0.4940 - val_loss: 2.5234 - val_accuracy: 0.4935\n",
      "\n",
      "Epoch 00004: loss improved from 2.49116 to 2.42959, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 5/100\n",
      "274/274 [==============================] - 26s 94ms/step - loss: 2.3859 - accuracy: 0.4928 - val_loss: 2.5093 - val_accuracy: 0.4944\n",
      "\n",
      "Epoch 00005: loss improved from 2.42959 to 2.38585, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 6/100\n",
      "274/274 [==============================] - 26s 95ms/step - loss: 2.3590 - accuracy: 0.4922 - val_loss: 2.5139 - val_accuracy: 0.4926\n",
      "\n",
      "Epoch 00006: loss improved from 2.38585 to 2.35895, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 7/100\n",
      "274/274 [==============================] - 26s 95ms/step - loss: 2.3244 - accuracy: 0.4958 - val_loss: 2.5253 - val_accuracy: 0.4976\n",
      "\n",
      "Epoch 00007: loss improved from 2.35895 to 2.32444, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 8/100\n",
      "274/274 [==============================] - 26s 95ms/step - loss: 2.2992 - accuracy: 0.4973 - val_loss: 2.4808 - val_accuracy: 0.4967\n",
      "\n",
      "Epoch 00008: loss improved from 2.32444 to 2.29920, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 9/100\n",
      "274/274 [==============================] - 26s 95ms/step - loss: 2.2717 - accuracy: 0.4973 - val_loss: 2.4586 - val_accuracy: 0.4969\n",
      "\n",
      "Epoch 00009: loss improved from 2.29920 to 2.27169, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 10/100\n",
      "274/274 [==============================] - 27s 100ms/step - loss: 2.2496 - accuracy: 0.4993 - val_loss: 2.4526 - val_accuracy: 0.5008\n",
      "\n",
      "Epoch 00010: loss improved from 2.27169 to 2.24955, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 11/100\n",
      "274/274 [==============================] - 28s 102ms/step - loss: 2.2328 - accuracy: 0.5030 - val_loss: 2.4187 - val_accuracy: 0.5015\n",
      "\n",
      "Epoch 00011: loss improved from 2.24955 to 2.23278, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 12/100\n",
      "274/274 [==============================] - 26s 94ms/step - loss: 2.2248 - accuracy: 0.5025 - val_loss: 2.4629 - val_accuracy: 0.5019\n",
      "\n",
      "Epoch 00012: loss improved from 2.23278 to 2.22477, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 13/100\n",
      "274/274 [==============================] - 26s 94ms/step - loss: 2.2102 - accuracy: 0.5048 - val_loss: 2.4054 - val_accuracy: 0.4981\n",
      "\n",
      "Epoch 00013: loss improved from 2.22477 to 2.21016, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 14/100\n",
      "274/274 [==============================] - 26s 96ms/step - loss: 2.1990 - accuracy: 0.5042 - val_loss: 2.3851 - val_accuracy: 0.4978\n",
      "\n",
      "Epoch 00014: loss improved from 2.21016 to 2.19899, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 15/100\n",
      "274/274 [==============================] - 26s 95ms/step - loss: 2.1902 - accuracy: 0.5041 - val_loss: 2.3877 - val_accuracy: 0.5045\n",
      "\n",
      "Epoch 00015: loss improved from 2.19899 to 2.19022, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 16/100\n",
      "274/274 [==============================] - 26s 94ms/step - loss: 2.1743 - accuracy: 0.5086 - val_loss: 2.3934 - val_accuracy: 0.5033\n",
      "\n",
      "Epoch 00016: loss improved from 2.19022 to 2.17433, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 17/100\n",
      "274/274 [==============================] - 26s 93ms/step - loss: 2.1668 - accuracy: 0.5042 - val_loss: 2.3700 - val_accuracy: 0.5022\n",
      "\n",
      "Epoch 00017: loss improved from 2.17433 to 2.16680, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 18/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 26s 95ms/step - loss: 2.1656 - accuracy: 0.5063 - val_loss: 2.3570 - val_accuracy: 0.5049\n",
      "\n",
      "Epoch 00018: loss improved from 2.16680 to 2.16558, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 19/100\n",
      "274/274 [==============================] - 26s 94ms/step - loss: 2.1559 - accuracy: 0.5063 - val_loss: 2.3807 - val_accuracy: 0.5086\n",
      "\n",
      "Epoch 00019: loss improved from 2.16558 to 2.15588, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 20/100\n",
      "274/274 [==============================] - 26s 94ms/step - loss: 2.1351 - accuracy: 0.5114 - val_loss: 2.3372 - val_accuracy: 0.5095\n",
      "\n",
      "Epoch 00020: loss improved from 2.15588 to 2.13511, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 21/100\n",
      "274/274 [==============================] - 26s 94ms/step - loss: 2.1363 - accuracy: 0.5095 - val_loss: 2.3736 - val_accuracy: 0.5136\n",
      "\n",
      "Epoch 00021: loss did not improve from 2.13511\n",
      "Epoch 22/100\n",
      "274/274 [==============================] - 26s 94ms/step - loss: 2.1118 - accuracy: 0.5157 - val_loss: 2.3318 - val_accuracy: 0.5019\n",
      "\n",
      "Epoch 00022: loss improved from 2.13511 to 2.11180, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 23/100\n",
      "274/274 [==============================] - 26s 94ms/step - loss: 2.1292 - accuracy: 0.5123 - val_loss: 2.3243 - val_accuracy: 0.5090\n",
      "\n",
      "Epoch 00023: loss did not improve from 2.11180\n",
      "Epoch 24/100\n",
      "274/274 [==============================] - 26s 93ms/step - loss: 2.1097 - accuracy: 0.5137 - val_loss: 2.3479 - val_accuracy: 0.5143\n",
      "\n",
      "Epoch 00024: loss improved from 2.11180 to 2.10974, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 25/100\n",
      "274/274 [==============================] - 26s 94ms/step - loss: 2.0964 - accuracy: 0.5162 - val_loss: 2.3235 - val_accuracy: 0.5150\n",
      "\n",
      "Epoch 00025: loss improved from 2.10974 to 2.09639, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 26/100\n",
      "274/274 [==============================] - 26s 95ms/step - loss: 2.1049 - accuracy: 0.5135 - val_loss: 2.2899 - val_accuracy: 0.5152\n",
      "\n",
      "Epoch 00026: loss did not improve from 2.09639\n",
      "Epoch 27/100\n",
      "274/274 [==============================] - 26s 94ms/step - loss: 2.1167 - accuracy: 0.5154 - val_loss: 2.3206 - val_accuracy: 0.5067\n",
      "\n",
      "Epoch 00027: loss did not improve from 2.09639\n",
      "Epoch 28/100\n",
      "274/274 [==============================] - 26s 94ms/step - loss: 2.0908 - accuracy: 0.5140 - val_loss: 2.2862 - val_accuracy: 0.5191\n",
      "\n",
      "Epoch 00028: loss improved from 2.09639 to 2.09076, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 29/100\n",
      "274/274 [==============================] - 26s 95ms/step - loss: 2.1029 - accuracy: 0.5144 - val_loss: 2.3268 - val_accuracy: 0.5138\n",
      "\n",
      "Epoch 00029: loss did not improve from 2.09076\n",
      "Epoch 30/100\n",
      "274/274 [==============================] - 26s 94ms/step - loss: 2.1035 - accuracy: 0.5181 - val_loss: 2.3164 - val_accuracy: 0.5198\n",
      "\n",
      "Epoch 00030: loss did not improve from 2.09076\n",
      "Epoch 31/100\n",
      "274/274 [==============================] - 26s 94ms/step - loss: 2.1023 - accuracy: 0.5167 - val_loss: 2.3228 - val_accuracy: 0.5161\n",
      "\n",
      "Epoch 00031: loss did not improve from 2.09076\n",
      "Epoch 32/100\n",
      "274/274 [==============================] - 26s 94ms/step - loss: 2.0857 - accuracy: 0.5191 - val_loss: 2.3059 - val_accuracy: 0.5131\n",
      "\n",
      "Epoch 00032: loss improved from 2.09076 to 2.08565, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 33/100\n",
      "274/274 [==============================] - 26s 95ms/step - loss: 2.1049 - accuracy: 0.5136 - val_loss: 2.3036 - val_accuracy: 0.5173\n",
      "\n",
      "Epoch 00033: loss did not improve from 2.08565\n",
      "Epoch 34/100\n",
      "274/274 [==============================] - 26s 95ms/step - loss: 2.0748 - accuracy: 0.5200 - val_loss: 2.3040 - val_accuracy: 0.5163\n",
      "\n",
      "Epoch 00034: loss improved from 2.08565 to 2.07476, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 35/100\n",
      "274/274 [==============================] - 26s 94ms/step - loss: 2.0799 - accuracy: 0.5185 - val_loss: 2.2926 - val_accuracy: 0.5138\n",
      "\n",
      "Epoch 00035: loss did not improve from 2.07476\n",
      "Epoch 36/100\n",
      "274/274 [==============================] - 26s 94ms/step - loss: 2.0742 - accuracy: 0.5221 - val_loss: 2.3197 - val_accuracy: 0.5120\n",
      "\n",
      "Epoch 00036: loss improved from 2.07476 to 2.07422, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 37/100\n",
      "274/274 [==============================] - 26s 94ms/step - loss: 2.0744 - accuracy: 0.5214 - val_loss: 2.3148 - val_accuracy: 0.5122\n",
      "\n",
      "Epoch 00037: loss did not improve from 2.07422\n",
      "Epoch 38/100\n",
      "274/274 [==============================] - 26s 95ms/step - loss: 2.0831 - accuracy: 0.5231 - val_loss: 2.2692 - val_accuracy: 0.5189\n",
      "\n",
      "Epoch 00038: loss did not improve from 2.07422\n",
      "Epoch 39/100\n",
      "274/274 [==============================] - 26s 94ms/step - loss: 2.0680 - accuracy: 0.5234 - val_loss: 2.2887 - val_accuracy: 0.5191\n",
      "\n",
      "Epoch 00039: loss improved from 2.07422 to 2.06797, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 40/100\n",
      "274/274 [==============================] - 26s 94ms/step - loss: 2.0640 - accuracy: 0.5221 - val_loss: 2.2612 - val_accuracy: 0.5125\n",
      "\n",
      "Epoch 00040: loss improved from 2.06797 to 2.06404, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 41/100\n",
      "274/274 [==============================] - 26s 94ms/step - loss: 2.0597 - accuracy: 0.5221 - val_loss: 2.2707 - val_accuracy: 0.5241\n",
      "\n",
      "Epoch 00041: loss improved from 2.06404 to 2.05972, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 42/100\n",
      "274/274 [==============================] - 26s 93ms/step - loss: 2.0459 - accuracy: 0.5259 - val_loss: 2.2949 - val_accuracy: 0.5184\n",
      "\n",
      "Epoch 00042: loss improved from 2.05972 to 2.04593, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 43/100\n",
      "274/274 [==============================] - 26s 94ms/step - loss: 2.0535 - accuracy: 0.5238 - val_loss: 2.2795 - val_accuracy: 0.5182\n",
      "\n",
      "Epoch 00043: loss did not improve from 2.04593\n",
      "Epoch 44/100\n",
      "274/274 [==============================] - 26s 94ms/step - loss: 2.0588 - accuracy: 0.5251 - val_loss: 2.2834 - val_accuracy: 0.5273\n",
      "\n",
      "Epoch 00044: loss did not improve from 2.04593\n",
      "Epoch 45/100\n",
      "274/274 [==============================] - 26s 94ms/step - loss: 2.0489 - accuracy: 0.5269 - val_loss: 2.2626 - val_accuracy: 0.5257\n",
      "\n",
      "Epoch 00045: loss did not improve from 2.04593\n",
      "Epoch 46/100\n",
      "274/274 [==============================] - 26s 94ms/step - loss: 2.0361 - accuracy: 0.5288 - val_loss: 2.2806 - val_accuracy: 0.5198\n",
      "\n",
      "Epoch 00046: loss improved from 2.04593 to 2.03607, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 47/100\n",
      "274/274 [==============================] - 26s 94ms/step - loss: 2.0379 - accuracy: 0.5246 - val_loss: 2.2828 - val_accuracy: 0.5275\n",
      "\n",
      "Epoch 00047: loss did not improve from 2.03607\n",
      "Epoch 48/100\n",
      "274/274 [==============================] - 26s 95ms/step - loss: 2.0305 - accuracy: 0.5295 - val_loss: 2.2402 - val_accuracy: 0.5248\n",
      "\n",
      "Epoch 00048: loss improved from 2.03607 to 2.03046, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 49/100\n",
      "274/274 [==============================] - 26s 95ms/step - loss: 2.0377 - accuracy: 0.5274 - val_loss: 2.2813 - val_accuracy: 0.5255\n",
      "\n",
      "Epoch 00049: loss did not improve from 2.03046\n",
      "Epoch 50/100\n",
      "274/274 [==============================] - 26s 95ms/step - loss: 2.0334 - accuracy: 0.5273 - val_loss: 2.2963 - val_accuracy: 0.5298\n",
      "\n",
      "Epoch 00050: loss did not improve from 2.03046\n",
      "Epoch 51/100\n",
      "274/274 [==============================] - 26s 94ms/step - loss: 2.0242 - accuracy: 0.5341 - val_loss: 2.2407 - val_accuracy: 0.5230\n",
      "\n",
      "Epoch 00051: loss improved from 2.03046 to 2.02422, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 52/100\n",
      "274/274 [==============================] - 26s 94ms/step - loss: 2.0337 - accuracy: 0.5293 - val_loss: 2.2389 - val_accuracy: 0.5259\n",
      "\n",
      "Epoch 00052: loss did not improve from 2.02422\n",
      "Epoch 53/100\n",
      "274/274 [==============================] - 27s 100ms/step - loss: 2.0319 - accuracy: 0.5301 - val_loss: 2.2483 - val_accuracy: 0.5275\n",
      "\n",
      "Epoch 00053: loss did not improve from 2.02422\n",
      "Epoch 54/100\n",
      "274/274 [==============================] - 27s 98ms/step - loss: 2.0242 - accuracy: 0.5294 - val_loss: 2.2729 - val_accuracy: 0.5266\n",
      "\n",
      "Epoch 00054: loss improved from 2.02422 to 2.02419, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 55/100\n",
      "274/274 [==============================] - 26s 96ms/step - loss: 2.0328 - accuracy: 0.5296 - val_loss: 2.2468 - val_accuracy: 0.5291\n",
      "\n",
      "Epoch 00055: loss did not improve from 2.02419\n",
      "Epoch 56/100\n",
      "274/274 [==============================] - 26s 97ms/step - loss: 2.0308 - accuracy: 0.5320 - val_loss: 2.2713 - val_accuracy: 0.5259\n",
      "\n",
      "Epoch 00056: loss did not improve from 2.02419\n",
      "Epoch 57/100\n",
      "274/274 [==============================] - 26s 96ms/step - loss: 2.0303 - accuracy: 0.5313 - val_loss: 2.2616 - val_accuracy: 0.5294\n",
      "\n",
      "Epoch 00057: loss did not improve from 2.02419\n",
      "Epoch 58/100\n",
      "274/274 [==============================] - 26s 96ms/step - loss: 2.0360 - accuracy: 0.5256 - val_loss: 2.2857 - val_accuracy: 0.5269\n",
      "\n",
      "Epoch 00058: loss did not improve from 2.02419\n",
      "Epoch 59/100\n",
      "274/274 [==============================] - 26s 96ms/step - loss: 2.0368 - accuracy: 0.5322 - val_loss: 2.2786 - val_accuracy: 0.5205\n",
      "\n",
      "Epoch 00059: loss did not improve from 2.02419\n",
      "Epoch 60/100\n",
      "274/274 [==============================] - 26s 97ms/step - loss: 2.0227 - accuracy: 0.5316 - val_loss: 2.2959 - val_accuracy: 0.5179\n",
      "\n",
      "Epoch 00060: loss improved from 2.02419 to 2.02268, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 61/100\n",
      "274/274 [==============================] - 27s 97ms/step - loss: 2.0088 - accuracy: 0.5309 - val_loss: 2.2517 - val_accuracy: 0.5243\n",
      "\n",
      "Epoch 00061: loss improved from 2.02268 to 2.00876, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 62/100\n",
      "274/274 [==============================] - 26s 96ms/step - loss: 2.0100 - accuracy: 0.5326 - val_loss: 2.2927 - val_accuracy: 0.5234\n",
      "\n",
      "Epoch 00062: loss did not improve from 2.00876\n",
      "Epoch 63/100\n",
      "274/274 [==============================] - 27s 97ms/step - loss: 2.0093 - accuracy: 0.5313 - val_loss: 2.2390 - val_accuracy: 0.5262\n",
      "\n",
      "Epoch 00063: loss did not improve from 2.00876\n",
      "Epoch 64/100\n",
      "274/274 [==============================] - 26s 96ms/step - loss: 2.0215 - accuracy: 0.5303 - val_loss: 2.2703 - val_accuracy: 0.5177\n",
      "\n",
      "Epoch 00064: loss did not improve from 2.00876\n",
      "Epoch 65/100\n",
      "274/274 [==============================] - 26s 97ms/step - loss: 2.0204 - accuracy: 0.5251 - val_loss: 2.2731 - val_accuracy: 0.5189\n",
      "\n",
      "Epoch 00065: loss did not improve from 2.00876\n",
      "Epoch 66/100\n",
      "274/274 [==============================] - 27s 98ms/step - loss: 2.0114 - accuracy: 0.5306 - val_loss: 2.2624 - val_accuracy: 0.5253\n",
      "\n",
      "Epoch 00066: loss did not improve from 2.00876\n",
      "Epoch 67/100\n",
      "274/274 [==============================] - 26s 96ms/step - loss: 2.0117 - accuracy: 0.5338 - val_loss: 2.2548 - val_accuracy: 0.5191\n",
      "\n",
      "Epoch 00067: loss did not improve from 2.00876\n",
      "Epoch 68/100\n",
      "274/274 [==============================] - 26s 96ms/step - loss: 1.9986 - accuracy: 0.5315 - val_loss: 2.2138 - val_accuracy: 0.5291\n",
      "\n",
      "Epoch 00068: loss improved from 2.00876 to 1.99862, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 69/100\n",
      "274/274 [==============================] - 26s 96ms/step - loss: 2.0132 - accuracy: 0.5275 - val_loss: 2.2459 - val_accuracy: 0.5237\n",
      "\n",
      "Epoch 00069: loss did not improve from 1.99862\n",
      "Epoch 70/100\n",
      "274/274 [==============================] - 26s 96ms/step - loss: 2.0184 - accuracy: 0.5269 - val_loss: 2.2786 - val_accuracy: 0.5186\n",
      "\n",
      "Epoch 00070: loss did not improve from 1.99862\n",
      "Epoch 71/100\n",
      "274/274 [==============================] - 26s 96ms/step - loss: 2.0089 - accuracy: 0.5331 - val_loss: 2.2382 - val_accuracy: 0.5289\n",
      "\n",
      "Epoch 00071: loss did not improve from 1.99862\n",
      "Epoch 72/100\n",
      "274/274 [==============================] - 26s 96ms/step - loss: 2.0028 - accuracy: 0.5346 - val_loss: 2.2758 - val_accuracy: 0.5225\n",
      "\n",
      "Epoch 00072: loss did not improve from 1.99862\n",
      "Epoch 73/100\n",
      "274/274 [==============================] - 26s 96ms/step - loss: 2.0187 - accuracy: 0.5363 - val_loss: 2.2640 - val_accuracy: 0.5246\n",
      "\n",
      "Epoch 00073: loss did not improve from 1.99862\n",
      "Epoch 74/100\n",
      "274/274 [==============================] - 26s 96ms/step - loss: 2.0123 - accuracy: 0.5364 - val_loss: 2.2580 - val_accuracy: 0.5200\n",
      "\n",
      "Epoch 00074: loss did not improve from 1.99862\n",
      "Epoch 75/100\n",
      "274/274 [==============================] - 26s 96ms/step - loss: 1.9985 - accuracy: 0.5348 - val_loss: 2.2160 - val_accuracy: 0.5330\n",
      "\n",
      "Epoch 00075: loss improved from 1.99862 to 1.99847, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 76/100\n",
      "274/274 [==============================] - 26s 96ms/step - loss: 2.0092 - accuracy: 0.5334 - val_loss: 2.2495 - val_accuracy: 0.5271\n",
      "\n",
      "Epoch 00076: loss did not improve from 1.99847\n",
      "Epoch 77/100\n",
      "274/274 [==============================] - 26s 96ms/step - loss: 2.0006 - accuracy: 0.5342 - val_loss: 2.2254 - val_accuracy: 0.5294\n",
      "\n",
      "Epoch 00077: loss did not improve from 1.99847\n",
      "Epoch 78/100\n",
      "274/274 [==============================] - 26s 96ms/step - loss: 1.9829 - accuracy: 0.5393 - val_loss: 2.2337 - val_accuracy: 0.5310\n",
      "\n",
      "Epoch 00078: loss improved from 1.99847 to 1.98292, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 79/100\n",
      "274/274 [==============================] - 27s 97ms/step - loss: 1.9865 - accuracy: 0.5365 - val_loss: 2.2264 - val_accuracy: 0.5323\n",
      "\n",
      "Epoch 00079: loss did not improve from 1.98292\n",
      "Epoch 80/100\n",
      "274/274 [==============================] - 26s 96ms/step - loss: 1.9952 - accuracy: 0.5369 - val_loss: 2.2330 - val_accuracy: 0.5289\n",
      "\n",
      "Epoch 00080: loss did not improve from 1.98292\n",
      "Epoch 81/100\n",
      "274/274 [==============================] - 26s 96ms/step - loss: 1.9844 - accuracy: 0.5378 - val_loss: 2.2189 - val_accuracy: 0.5259\n",
      "\n",
      "Epoch 00081: loss did not improve from 1.98292\n",
      "Epoch 82/100\n",
      "274/274 [==============================] - 26s 96ms/step - loss: 1.9740 - accuracy: 0.5402 - val_loss: 2.2032 - val_accuracy: 0.5285\n",
      "\n",
      "Epoch 00082: loss improved from 1.98292 to 1.97402, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 83/100\n",
      "274/274 [==============================] - 26s 96ms/step - loss: 1.9936 - accuracy: 0.5345 - val_loss: 2.2258 - val_accuracy: 0.5264\n",
      "\n",
      "Epoch 00083: loss did not improve from 1.97402\n",
      "Epoch 84/100\n",
      "274/274 [==============================] - 26s 96ms/step - loss: 2.0072 - accuracy: 0.5355 - val_loss: 2.2464 - val_accuracy: 0.5287\n",
      "\n",
      "Epoch 00084: loss did not improve from 1.97402\n",
      "Epoch 85/100\n",
      "274/274 [==============================] - 26s 96ms/step - loss: 1.9979 - accuracy: 0.5390 - val_loss: 2.2250 - val_accuracy: 0.5298\n",
      "\n",
      "Epoch 00085: loss did not improve from 1.97402\n",
      "Epoch 86/100\n",
      "274/274 [==============================] - 26s 96ms/step - loss: 1.9861 - accuracy: 0.5385 - val_loss: 2.2431 - val_accuracy: 0.5241\n",
      "\n",
      "Epoch 00086: loss did not improve from 1.97402\n",
      "Epoch 87/100\n",
      "274/274 [==============================] - 26s 96ms/step - loss: 2.0162 - accuracy: 0.5290 - val_loss: 2.2357 - val_accuracy: 0.5301\n",
      "\n",
      "Epoch 00087: loss did not improve from 1.97402\n",
      "Epoch 88/100\n",
      "274/274 [==============================] - 26s 96ms/step - loss: 1.9880 - accuracy: 0.5342 - val_loss: 2.2073 - val_accuracy: 0.5323\n",
      "\n",
      "Epoch 00088: loss did not improve from 1.97402\n",
      "Epoch 89/100\n",
      "274/274 [==============================] - 26s 96ms/step - loss: 1.9866 - accuracy: 0.5385 - val_loss: 2.2287 - val_accuracy: 0.5307\n",
      "\n",
      "Epoch 00089: loss did not improve from 1.97402\n",
      "Epoch 90/100\n",
      "274/274 [==============================] - 26s 96ms/step - loss: 1.9933 - accuracy: 0.5352 - val_loss: 2.2455 - val_accuracy: 0.5301\n",
      "\n",
      "Epoch 00090: loss did not improve from 1.97402\n",
      "Epoch 91/100\n",
      "274/274 [==============================] - 26s 96ms/step - loss: 2.0106 - accuracy: 0.5302 - val_loss: 2.1937 - val_accuracy: 0.5294\n",
      "\n",
      "Epoch 00091: loss did not improve from 1.97402\n",
      "Epoch 92/100\n",
      "274/274 [==============================] - 26s 96ms/step - loss: 1.9951 - accuracy: 0.5369 - val_loss: 2.2039 - val_accuracy: 0.5342\n",
      "\n",
      "Epoch 00092: loss did not improve from 1.97402\n",
      "Epoch 93/100\n",
      "274/274 [==============================] - 26s 96ms/step - loss: 1.9997 - accuracy: 0.5326 - val_loss: 2.2449 - val_accuracy: 0.5291\n",
      "\n",
      "Epoch 00093: loss did not improve from 1.97402\n",
      "Epoch 94/100\n",
      "274/274 [==============================] - 26s 96ms/step - loss: 1.9902 - accuracy: 0.5382 - val_loss: 2.2116 - val_accuracy: 0.5271\n",
      "\n",
      "Epoch 00094: loss did not improve from 1.97402\n",
      "Epoch 95/100\n",
      "274/274 [==============================] - 26s 96ms/step - loss: 1.9832 - accuracy: 0.5390 - val_loss: 2.2309 - val_accuracy: 0.5266\n",
      "\n",
      "Epoch 00095: loss did not improve from 1.97402\n",
      "Epoch 96/100\n",
      "274/274 [==============================] - 26s 96ms/step - loss: 1.9907 - accuracy: 0.5384 - val_loss: 2.2077 - val_accuracy: 0.5216\n",
      "\n",
      "Epoch 00096: loss did not improve from 1.97402\n",
      "Epoch 97/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 26s 95ms/step - loss: 1.9806 - accuracy: 0.5374 - val_loss: 2.2394 - val_accuracy: 0.5227\n",
      "\n",
      "Epoch 00097: loss did not improve from 1.97402\n",
      "Epoch 98/100\n",
      "274/274 [==============================] - 26s 96ms/step - loss: 1.9863 - accuracy: 0.5385 - val_loss: 2.2168 - val_accuracy: 0.5250\n",
      "\n",
      "Epoch 00098: loss did not improve from 1.97402\n",
      "Epoch 99/100\n",
      "274/274 [==============================] - 26s 96ms/step - loss: 1.9839 - accuracy: 0.5388 - val_loss: 2.2270 - val_accuracy: 0.5246\n",
      "\n",
      "Epoch 00099: loss did not improve from 1.97402\n",
      "Epoch 100/100\n",
      "274/274 [==============================] - 26s 95ms/step - loss: 1.9982 - accuracy: 0.5341 - val_loss: 2.2250 - val_accuracy: 0.5305\n",
      "\n",
      "Epoch 00100: loss did not improve from 1.97402\n",
      "Epoch 1/100\n",
      "274/274 [==============================] - 25s 85ms/step - loss: 2.7462 - accuracy: 0.4837 - val_loss: 2.6014 - val_accuracy: 0.4862\n",
      "\n",
      "Epoch 00001: loss improved from inf to 2.74624, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 2/100\n",
      "274/274 [==============================] - 24s 88ms/step - loss: 2.5369 - accuracy: 0.4874 - val_loss: 2.5670 - val_accuracy: 0.4953\n",
      "\n",
      "Epoch 00002: loss improved from 2.74624 to 2.53688, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 3/100\n",
      "274/274 [==============================] - 24s 87ms/step - loss: 2.3786 - accuracy: 0.4962 - val_loss: 2.4498 - val_accuracy: 0.4951\n",
      "\n",
      "Epoch 00003: loss improved from 2.53688 to 2.37859, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 4/100\n",
      "274/274 [==============================] - 24s 88ms/step - loss: 2.2666 - accuracy: 0.5027 - val_loss: 2.3641 - val_accuracy: 0.4987\n",
      "\n",
      "Epoch 00004: loss improved from 2.37859 to 2.26663, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 5/100\n",
      "274/274 [==============================] - 24s 88ms/step - loss: 2.1823 - accuracy: 0.5105 - val_loss: 2.3154 - val_accuracy: 0.5086\n",
      "\n",
      "Epoch 00005: loss improved from 2.26663 to 2.18232, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 6/100\n",
      "274/274 [==============================] - 24s 88ms/step - loss: 2.1298 - accuracy: 0.5177 - val_loss: 2.2996 - val_accuracy: 0.5113\n",
      "\n",
      "Epoch 00006: loss improved from 2.18232 to 2.12985, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 7/100\n",
      "274/274 [==============================] - 24s 88ms/step - loss: 2.0579 - accuracy: 0.5274 - val_loss: 2.2822 - val_accuracy: 0.5182\n",
      "\n",
      "Epoch 00007: loss improved from 2.12985 to 2.05791, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 8/100\n",
      "274/274 [==============================] - 24s 87ms/step - loss: 2.0076 - accuracy: 0.5354 - val_loss: 2.2247 - val_accuracy: 0.5246\n",
      "\n",
      "Epoch 00008: loss improved from 2.05791 to 2.00760, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 9/100\n",
      "274/274 [==============================] - 24s 88ms/step - loss: 1.9612 - accuracy: 0.5445 - val_loss: 2.1892 - val_accuracy: 0.5278\n",
      "\n",
      "Epoch 00009: loss improved from 2.00760 to 1.96117, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 10/100\n",
      "274/274 [==============================] - 24s 88ms/step - loss: 1.9208 - accuracy: 0.5557 - val_loss: 2.1749 - val_accuracy: 0.5349\n",
      "\n",
      "Epoch 00010: loss improved from 1.96117 to 1.92076, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 11/100\n",
      "274/274 [==============================] - 24s 88ms/step - loss: 1.8700 - accuracy: 0.5618 - val_loss: 2.1536 - val_accuracy: 0.5346\n",
      "\n",
      "Epoch 00011: loss improved from 1.92076 to 1.87002, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 12/100\n",
      "274/274 [==============================] - 24s 88ms/step - loss: 1.8357 - accuracy: 0.5709 - val_loss: 2.1623 - val_accuracy: 0.5435\n",
      "\n",
      "Epoch 00012: loss improved from 1.87002 to 1.83568, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 13/100\n",
      "274/274 [==============================] - 24s 87ms/step - loss: 1.8066 - accuracy: 0.5794 - val_loss: 2.1403 - val_accuracy: 0.5445\n",
      "\n",
      "Epoch 00013: loss improved from 1.83568 to 1.80663, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 14/100\n",
      "274/274 [==============================] - 24s 87ms/step - loss: 1.7729 - accuracy: 0.5845 - val_loss: 2.1556 - val_accuracy: 0.5415\n",
      "\n",
      "Epoch 00014: loss improved from 1.80663 to 1.77288, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 15/100\n",
      "274/274 [==============================] - 24s 87ms/step - loss: 1.7407 - accuracy: 0.5901 - val_loss: 2.1323 - val_accuracy: 0.5479\n",
      "\n",
      "Epoch 00015: loss improved from 1.77288 to 1.74073, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 16/100\n",
      "274/274 [==============================] - 24s 88ms/step - loss: 1.7142 - accuracy: 0.5971 - val_loss: 2.1207 - val_accuracy: 0.5538\n",
      "\n",
      "Epoch 00016: loss improved from 1.74073 to 1.71422, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 17/100\n",
      "274/274 [==============================] - 24s 88ms/step - loss: 1.6776 - accuracy: 0.6051 - val_loss: 2.1408 - val_accuracy: 0.5486\n",
      "\n",
      "Epoch 00017: loss improved from 1.71422 to 1.67757, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 18/100\n",
      "274/274 [==============================] - 24s 87ms/step - loss: 1.6486 - accuracy: 0.6080 - val_loss: 2.1549 - val_accuracy: 0.5463\n",
      "\n",
      "Epoch 00018: loss improved from 1.67757 to 1.64856, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 19/100\n",
      "274/274 [==============================] - 24s 88ms/step - loss: 1.6325 - accuracy: 0.6126 - val_loss: 2.1304 - val_accuracy: 0.5456\n",
      "\n",
      "Epoch 00019: loss improved from 1.64856 to 1.63245, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 20/100\n",
      "274/274 [==============================] - 24s 88ms/step - loss: 1.5993 - accuracy: 0.6200 - val_loss: 2.1299 - val_accuracy: 0.5497\n",
      "\n",
      "Epoch 00020: loss improved from 1.63245 to 1.59930, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 21/100\n",
      "274/274 [==============================] - 24s 87ms/step - loss: 1.5722 - accuracy: 0.6254 - val_loss: 2.1355 - val_accuracy: 0.5488\n",
      "\n",
      "Epoch 00021: loss improved from 1.59930 to 1.57218, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 22/100\n",
      "274/274 [==============================] - 24s 88ms/step - loss: 1.5542 - accuracy: 0.6269 - val_loss: 2.1479 - val_accuracy: 0.5582\n",
      "\n",
      "Epoch 00022: loss improved from 1.57218 to 1.55415, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 23/100\n",
      "274/274 [==============================] - 25s 89ms/step - loss: 1.5341 - accuracy: 0.6289 - val_loss: 2.1582 - val_accuracy: 0.5522\n",
      "\n",
      "Epoch 00023: loss improved from 1.55415 to 1.53414, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 24/100\n",
      "274/274 [==============================] - 24s 88ms/step - loss: 1.5108 - accuracy: 0.6347 - val_loss: 2.1653 - val_accuracy: 0.5543\n",
      "\n",
      "Epoch 00024: loss improved from 1.53414 to 1.51079, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 25/100\n",
      "274/274 [==============================] - 24s 89ms/step - loss: 1.4907 - accuracy: 0.6394 - val_loss: 2.1631 - val_accuracy: 0.5481\n",
      "\n",
      "Epoch 00025: loss improved from 1.51079 to 1.49072, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 26/100\n",
      "274/274 [==============================] - 24s 88ms/step - loss: 1.4670 - accuracy: 0.6410 - val_loss: 2.1742 - val_accuracy: 0.5593\n",
      "\n",
      "Epoch 00026: loss improved from 1.49072 to 1.46696, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 27/100\n",
      "274/274 [==============================] - 24s 88ms/step - loss: 1.4521 - accuracy: 0.6470 - val_loss: 2.1461 - val_accuracy: 0.5559\n",
      "\n",
      "Epoch 00027: loss improved from 1.46696 to 1.45206, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 28/100\n",
      "274/274 [==============================] - 24s 88ms/step - loss: 1.4307 - accuracy: 0.6513 - val_loss: 2.1799 - val_accuracy: 0.5566\n",
      "\n",
      "Epoch 00028: loss improved from 1.45206 to 1.43070, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 29/100\n",
      "274/274 [==============================] - 24s 88ms/step - loss: 1.4156 - accuracy: 0.6514 - val_loss: 2.2208 - val_accuracy: 0.5557\n",
      "\n",
      "Epoch 00029: loss improved from 1.43070 to 1.41564, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 30/100\n",
      "274/274 [==============================] - 24s 87ms/step - loss: 1.4020 - accuracy: 0.6547 - val_loss: 2.2409 - val_accuracy: 0.5470\n",
      "\n",
      "Epoch 00030: loss improved from 1.41564 to 1.40203, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 31/100\n",
      "274/274 [==============================] - 24s 88ms/step - loss: 1.3932 - accuracy: 0.6572 - val_loss: 2.1938 - val_accuracy: 0.5545\n",
      "\n",
      "Epoch 00031: loss improved from 1.40203 to 1.39323, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 32/100\n",
      "274/274 [==============================] - 24s 88ms/step - loss: 1.3779 - accuracy: 0.6630 - val_loss: 2.2116 - val_accuracy: 0.5568\n",
      "\n",
      "Epoch 00032: loss improved from 1.39323 to 1.37786, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 33/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 24s 87ms/step - loss: 1.3584 - accuracy: 0.6637 - val_loss: 2.2286 - val_accuracy: 0.5520\n",
      "\n",
      "Epoch 00033: loss improved from 1.37786 to 1.35838, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 34/100\n",
      "274/274 [==============================] - 24s 87ms/step - loss: 1.3455 - accuracy: 0.6631 - val_loss: 2.2132 - val_accuracy: 0.5506\n",
      "\n",
      "Epoch 00034: loss improved from 1.35838 to 1.34550, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 35/100\n",
      "274/274 [==============================] - 24s 87ms/step - loss: 1.3174 - accuracy: 0.6698 - val_loss: 2.2539 - val_accuracy: 0.5495\n",
      "\n",
      "Epoch 00035: loss improved from 1.34550 to 1.31738, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 36/100\n",
      "274/274 [==============================] - 24s 89ms/step - loss: 1.3114 - accuracy: 0.6717 - val_loss: 2.2704 - val_accuracy: 0.5463\n",
      "\n",
      "Epoch 00036: loss improved from 1.31738 to 1.31141, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 37/100\n",
      "274/274 [==============================] - 25s 89ms/step - loss: 1.3123 - accuracy: 0.6674 - val_loss: 2.2908 - val_accuracy: 0.5513\n",
      "\n",
      "Epoch 00037: loss did not improve from 1.31141\n",
      "Epoch 38/100\n",
      "274/274 [==============================] - 24s 88ms/step - loss: 1.3000 - accuracy: 0.6709 - val_loss: 2.2819 - val_accuracy: 0.5538\n",
      "\n",
      "Epoch 00038: loss improved from 1.31141 to 1.30003, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 39/100\n",
      "274/274 [==============================] - 24s 89ms/step - loss: 1.2960 - accuracy: 0.6692 - val_loss: 2.2535 - val_accuracy: 0.5577\n",
      "\n",
      "Epoch 00039: loss improved from 1.30003 to 1.29604, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 40/100\n",
      "274/274 [==============================] - 25s 91ms/step - loss: 1.2792 - accuracy: 0.6727 - val_loss: 2.2798 - val_accuracy: 0.5618\n",
      "\n",
      "Epoch 00040: loss improved from 1.29604 to 1.27917, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 41/100\n",
      "274/274 [==============================] - 25s 90ms/step - loss: 1.2707 - accuracy: 0.6779 - val_loss: 2.3139 - val_accuracy: 0.5543\n",
      "\n",
      "Epoch 00041: loss improved from 1.27917 to 1.27068, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 42/100\n",
      "274/274 [==============================] - 24s 89ms/step - loss: 1.2467 - accuracy: 0.6830 - val_loss: 2.2824 - val_accuracy: 0.5504\n",
      "\n",
      "Epoch 00042: loss improved from 1.27068 to 1.24667, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 43/100\n",
      "274/274 [==============================] - 24s 89ms/step - loss: 1.2397 - accuracy: 0.6841 - val_loss: 2.3505 - val_accuracy: 0.5529\n",
      "\n",
      "Epoch 00043: loss improved from 1.24667 to 1.23972, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 44/100\n",
      "274/274 [==============================] - 25s 90ms/step - loss: 1.2214 - accuracy: 0.6851 - val_loss: 2.3373 - val_accuracy: 0.5513\n",
      "\n",
      "Epoch 00044: loss improved from 1.23972 to 1.22141, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 45/100\n",
      "274/274 [==============================] - 25s 90ms/step - loss: 1.2212 - accuracy: 0.6834 - val_loss: 2.3916 - val_accuracy: 0.5472\n",
      "\n",
      "Epoch 00045: loss improved from 1.22141 to 1.22119, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 46/100\n",
      "274/274 [==============================] - 25s 90ms/step - loss: 1.2030 - accuracy: 0.6873 - val_loss: 2.3554 - val_accuracy: 0.5488\n",
      "\n",
      "Epoch 00046: loss improved from 1.22119 to 1.20304, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 47/100\n",
      "274/274 [==============================] - 24s 88ms/step - loss: 1.1991 - accuracy: 0.6915 - val_loss: 2.3236 - val_accuracy: 0.5568\n",
      "\n",
      "Epoch 00047: loss improved from 1.20304 to 1.19907, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 48/100\n",
      "274/274 [==============================] - 24s 88ms/step - loss: 1.1938 - accuracy: 0.6922 - val_loss: 2.3667 - val_accuracy: 0.5495\n",
      "\n",
      "Epoch 00048: loss improved from 1.19907 to 1.19381, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 49/100\n",
      "274/274 [==============================] - 24s 89ms/step - loss: 1.1878 - accuracy: 0.6893 - val_loss: 2.3766 - val_accuracy: 0.5607\n",
      "\n",
      "Epoch 00049: loss improved from 1.19381 to 1.18783, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 50/100\n",
      "274/274 [==============================] - 25s 90ms/step - loss: 1.1839 - accuracy: 0.6911 - val_loss: 2.3791 - val_accuracy: 0.5550\n",
      "\n",
      "Epoch 00050: loss improved from 1.18783 to 1.18388, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 51/100\n",
      "274/274 [==============================] - 25s 92ms/step - loss: 1.1825 - accuracy: 0.6926 - val_loss: 2.4235 - val_accuracy: 0.5474\n",
      "\n",
      "Epoch 00051: loss improved from 1.18388 to 1.18250, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 52/100\n",
      "274/274 [==============================] - 24s 88ms/step - loss: 1.1714 - accuracy: 0.6967 - val_loss: 2.3575 - val_accuracy: 0.5497\n",
      "\n",
      "Epoch 00052: loss improved from 1.18250 to 1.17140, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 53/100\n",
      "274/274 [==============================] - 25s 90ms/step - loss: 1.1462 - accuracy: 0.6983 - val_loss: 2.4064 - val_accuracy: 0.5486\n",
      "\n",
      "Epoch 00053: loss improved from 1.17140 to 1.14623, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 54/100\n",
      "274/274 [==============================] - 24s 88ms/step - loss: 1.1442 - accuracy: 0.6993 - val_loss: 2.4163 - val_accuracy: 0.5557\n",
      "\n",
      "Epoch 00054: loss improved from 1.14623 to 1.14420, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 55/100\n",
      "274/274 [==============================] - 24s 88ms/step - loss: 1.1418 - accuracy: 0.7036 - val_loss: 2.4264 - val_accuracy: 0.5561\n",
      "\n",
      "Epoch 00055: loss improved from 1.14420 to 1.14177, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 56/100\n",
      "274/274 [==============================] - 24s 89ms/step - loss: 1.1344 - accuracy: 0.7006 - val_loss: 2.4723 - val_accuracy: 0.5520\n",
      "\n",
      "Epoch 00056: loss improved from 1.14177 to 1.13440, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 57/100\n",
      "274/274 [==============================] - 24s 89ms/step - loss: 1.1277 - accuracy: 0.7034 - val_loss: 2.4305 - val_accuracy: 0.5513\n",
      "\n",
      "Epoch 00057: loss improved from 1.13440 to 1.12767, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 58/100\n",
      "274/274 [==============================] - 24s 89ms/step - loss: 1.1323 - accuracy: 0.7016 - val_loss: 2.4557 - val_accuracy: 0.5518\n",
      "\n",
      "Epoch 00058: loss did not improve from 1.12767\n",
      "Epoch 59/100\n",
      "274/274 [==============================] - 24s 89ms/step - loss: 1.1227 - accuracy: 0.7032 - val_loss: 2.4363 - val_accuracy: 0.5504\n",
      "\n",
      "Epoch 00059: loss improved from 1.12767 to 1.12272, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 60/100\n",
      "274/274 [==============================] - 24s 89ms/step - loss: 1.1250 - accuracy: 0.7031 - val_loss: 2.4898 - val_accuracy: 0.5511\n",
      "\n",
      "Epoch 00060: loss did not improve from 1.12272\n",
      "Epoch 61/100\n",
      "274/274 [==============================] - 26s 94ms/step - loss: 1.1022 - accuracy: 0.7066 - val_loss: 2.4707 - val_accuracy: 0.5511\n",
      "\n",
      "Epoch 00061: loss improved from 1.12272 to 1.10222, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 62/100\n",
      "274/274 [==============================] - 28s 101ms/step - loss: 1.0889 - accuracy: 0.7103 - val_loss: 2.4393 - val_accuracy: 0.5506\n",
      "\n",
      "Epoch 00062: loss improved from 1.10222 to 1.08892, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 63/100\n",
      "274/274 [==============================] - 32s 117ms/step - loss: 1.0898 - accuracy: 0.7119 - val_loss: 2.5033 - val_accuracy: 0.5559\n",
      "\n",
      "Epoch 00063: loss did not improve from 1.08892\n",
      "Epoch 64/100\n",
      "274/274 [==============================] - 28s 103ms/step - loss: 1.0701 - accuracy: 0.7142 - val_loss: 2.4791 - val_accuracy: 0.5477\n",
      "\n",
      "Epoch 00064: loss improved from 1.08892 to 1.07009, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 65/100\n",
      "274/274 [==============================] - 33s 120ms/step - loss: 1.0851 - accuracy: 0.7115 - val_loss: 2.5018 - val_accuracy: 0.5499\n",
      "\n",
      "Epoch 00065: loss did not improve from 1.07009\n",
      "Epoch 66/100\n",
      "274/274 [==============================] - 29s 106ms/step - loss: 1.0681 - accuracy: 0.7132 - val_loss: 2.5161 - val_accuracy: 0.5579\n",
      "\n",
      "Epoch 00066: loss improved from 1.07009 to 1.06811, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 67/100\n",
      "274/274 [==============================] - 29s 108ms/step - loss: 1.0766 - accuracy: 0.7112 - val_loss: 2.5217 - val_accuracy: 0.5550\n",
      "\n",
      "Epoch 00067: loss did not improve from 1.06811\n",
      "Epoch 68/100\n",
      "274/274 [==============================] - 31s 114ms/step - loss: 1.0579 - accuracy: 0.7170 - val_loss: 2.4617 - val_accuracy: 0.5499\n",
      "\n",
      "Epoch 00068: loss improved from 1.06811 to 1.05787, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 69/100\n",
      "274/274 [==============================] - 33s 121ms/step - loss: 1.0658 - accuracy: 0.7153 - val_loss: 2.5162 - val_accuracy: 0.5595\n",
      "\n",
      "Epoch 00069: loss did not improve from 1.05787\n",
      "Epoch 70/100\n",
      "274/274 [==============================] - 32s 117ms/step - loss: 1.0662 - accuracy: 0.7088 - val_loss: 2.5700 - val_accuracy: 0.5481\n",
      "\n",
      "Epoch 00070: loss did not improve from 1.05787\n",
      "Epoch 71/100\n",
      "274/274 [==============================] - 28s 103ms/step - loss: 1.0647 - accuracy: 0.7142 - val_loss: 2.5246 - val_accuracy: 0.5522\n",
      "\n",
      "Epoch 00071: loss did not improve from 1.05787\n",
      "Epoch 72/100\n",
      "274/274 [==============================] - 31s 112ms/step - loss: 1.0480 - accuracy: 0.7175 - val_loss: 2.5449 - val_accuracy: 0.5520\n",
      "\n",
      "Epoch 00072: loss improved from 1.05787 to 1.04804, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 73/100\n",
      "274/274 [==============================] - 42s 152ms/step - loss: 1.0398 - accuracy: 0.7191 - val_loss: 2.5935 - val_accuracy: 0.5506\n",
      "\n",
      "Epoch 00073: loss improved from 1.04804 to 1.03984, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 74/100\n",
      "274/274 [==============================] - 41s 148ms/step - loss: 1.0317 - accuracy: 0.7174 - val_loss: 2.5778 - val_accuracy: 0.5586\n",
      "\n",
      "Epoch 00074: loss improved from 1.03984 to 1.03166, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 75/100\n",
      "274/274 [==============================] - 38s 138ms/step - loss: 1.0339 - accuracy: 0.7214 - val_loss: 2.5905 - val_accuracy: 0.5502\n",
      "\n",
      "Epoch 00075: loss did not improve from 1.03166\n",
      "Epoch 76/100\n",
      "274/274 [==============================] - 38s 138ms/step - loss: 1.0151 - accuracy: 0.7258 - val_loss: 2.5634 - val_accuracy: 0.5573\n",
      "\n",
      "Epoch 00076: loss improved from 1.03166 to 1.01512, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 77/100\n",
      "274/274 [==============================] - 38s 137ms/step - loss: 1.0242 - accuracy: 0.7208 - val_loss: 2.5353 - val_accuracy: 0.5513\n",
      "\n",
      "Epoch 00077: loss did not improve from 1.01512\n",
      "Epoch 78/100\n",
      "274/274 [==============================] - 37s 134ms/step - loss: 1.0289 - accuracy: 0.7233 - val_loss: 2.5580 - val_accuracy: 0.5552\n",
      "\n",
      "Epoch 00078: loss did not improve from 1.01512\n",
      "Epoch 79/100\n",
      "274/274 [==============================] - 38s 140ms/step - loss: 1.0080 - accuracy: 0.7240 - val_loss: 2.6283 - val_accuracy: 0.5529\n",
      "\n",
      "Epoch 00079: loss improved from 1.01512 to 1.00801, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 80/100\n",
      "274/274 [==============================] - 37s 135ms/step - loss: 1.0123 - accuracy: 0.7275 - val_loss: 2.5557 - val_accuracy: 0.5493\n",
      "\n",
      "Epoch 00080: loss did not improve from 1.00801\n",
      "Epoch 81/100\n",
      "274/274 [==============================] - 38s 138ms/step - loss: 1.0105 - accuracy: 0.7234 - val_loss: 2.5719 - val_accuracy: 0.5504\n",
      "\n",
      "Epoch 00081: loss did not improve from 1.00801\n",
      "Epoch 82/100\n",
      "274/274 [==============================] - 38s 139ms/step - loss: 1.0070 - accuracy: 0.7227 - val_loss: 2.5840 - val_accuracy: 0.5474\n",
      "\n",
      "Epoch 00082: loss improved from 1.00801 to 1.00700, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 83/100\n",
      "274/274 [==============================] - 38s 137ms/step - loss: 1.0065 - accuracy: 0.7281 - val_loss: 2.5161 - val_accuracy: 0.5477\n",
      "\n",
      "Epoch 00083: loss improved from 1.00700 to 1.00649, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 84/100\n",
      "274/274 [==============================] - 37s 136ms/step - loss: 1.0070 - accuracy: 0.7270 - val_loss: 2.5596 - val_accuracy: 0.5527\n",
      "\n",
      "Epoch 00084: loss did not improve from 1.00649\n",
      "Epoch 85/100\n",
      "274/274 [==============================] - 38s 139ms/step - loss: 0.9973 - accuracy: 0.7255 - val_loss: 2.6351 - val_accuracy: 0.5515\n",
      "\n",
      "Epoch 00085: loss improved from 1.00649 to 0.99732, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 86/100\n",
      "274/274 [==============================] - 38s 138ms/step - loss: 1.0170 - accuracy: 0.7196 - val_loss: 2.6527 - val_accuracy: 0.5563\n",
      "\n",
      "Epoch 00086: loss did not improve from 0.99732\n",
      "Epoch 87/100\n",
      "274/274 [==============================] - 37s 136ms/step - loss: 0.9906 - accuracy: 0.7300 - val_loss: 2.6308 - val_accuracy: 0.5518\n",
      "\n",
      "Epoch 00087: loss improved from 0.99732 to 0.99064, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 88/100\n",
      "274/274 [==============================] - 38s 139ms/step - loss: 0.9922 - accuracy: 0.7277 - val_loss: 2.6429 - val_accuracy: 0.5518\n",
      "\n",
      "Epoch 00088: loss did not improve from 0.99064\n",
      "Epoch 89/100\n",
      "274/274 [==============================] - 37s 137ms/step - loss: 1.0044 - accuracy: 0.7293 - val_loss: 2.5975 - val_accuracy: 0.5536\n",
      "\n",
      "Epoch 00089: loss did not improve from 0.99064\n",
      "Epoch 90/100\n",
      "274/274 [==============================] - 38s 138ms/step - loss: 0.9858 - accuracy: 0.7298 - val_loss: 2.6401 - val_accuracy: 0.5490\n",
      "\n",
      "Epoch 00090: loss improved from 0.99064 to 0.98578, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 91/100\n",
      "274/274 [==============================] - 37s 136ms/step - loss: 0.9730 - accuracy: 0.7332 - val_loss: 2.6344 - val_accuracy: 0.5479\n",
      "\n",
      "Epoch 00091: loss improved from 0.98578 to 0.97301, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 92/100\n",
      "274/274 [==============================] - 39s 142ms/step - loss: 0.9639 - accuracy: 0.7345 - val_loss: 2.6345 - val_accuracy: 0.5470\n",
      "\n",
      "Epoch 00092: loss improved from 0.97301 to 0.96391, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 93/100\n",
      "274/274 [==============================] - 39s 143ms/step - loss: 0.9635 - accuracy: 0.7335 - val_loss: 2.6299 - val_accuracy: 0.5554\n",
      "\n",
      "Epoch 00093: loss improved from 0.96391 to 0.96348, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 94/100\n",
      "274/274 [==============================] - 38s 138ms/step - loss: 0.9609 - accuracy: 0.7375 - val_loss: 2.6403 - val_accuracy: 0.5502\n",
      "\n",
      "Epoch 00094: loss improved from 0.96348 to 0.96090, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 95/100\n",
      "274/274 [==============================] - 38s 140ms/step - loss: 0.9711 - accuracy: 0.7349 - val_loss: 2.6577 - val_accuracy: 0.5570\n",
      "\n",
      "Epoch 00095: loss did not improve from 0.96090\n",
      "Epoch 96/100\n",
      "274/274 [==============================] - 38s 139ms/step - loss: 0.9479 - accuracy: 0.7406 - val_loss: 2.6714 - val_accuracy: 0.5502\n",
      "\n",
      "Epoch 00096: loss improved from 0.96090 to 0.94789, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 97/100\n",
      "274/274 [==============================] - 37s 134ms/step - loss: 0.9596 - accuracy: 0.7318 - val_loss: 2.7113 - val_accuracy: 0.5483\n",
      "\n",
      "Epoch 00097: loss did not improve from 0.94789\n",
      "Epoch 98/100\n",
      "274/274 [==============================] - 38s 140ms/step - loss: 0.9399 - accuracy: 0.7381 - val_loss: 2.6541 - val_accuracy: 0.5502\n",
      "\n",
      "Epoch 00098: loss improved from 0.94789 to 0.93991, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 99/100\n",
      "274/274 [==============================] - 38s 138ms/step - loss: 0.9512 - accuracy: 0.7371 - val_loss: 2.6961 - val_accuracy: 0.5531\n",
      "\n",
      "Epoch 00099: loss did not improve from 0.93991\n",
      "Epoch 100/100\n",
      "274/274 [==============================] - 37s 136ms/step - loss: 0.9490 - accuracy: 0.7339 - val_loss: 2.6801 - val_accuracy: 0.5499\n",
      "\n",
      "Epoch 00100: loss did not improve from 0.93991\n",
      "Epoch 1/100\n",
      "274/274 [==============================] - 23s 73ms/step - loss: 2.7127 - accuracy: 0.4801 - val_loss: 2.5736 - val_accuracy: 0.4976\n",
      "\n",
      "Epoch 00001: loss improved from inf to 2.71271, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 2/100\n",
      "274/274 [==============================] - 16s 59ms/step - loss: 2.3374 - accuracy: 0.5035 - val_loss: 2.5501 - val_accuracy: 0.4855\n",
      "\n",
      "Epoch 00002: loss improved from 2.71271 to 2.33736, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 3/100\n",
      "274/274 [==============================] - 18s 64ms/step - loss: 2.2172 - accuracy: 0.5135 - val_loss: 2.4512 - val_accuracy: 0.5047\n",
      "\n",
      "Epoch 00003: loss improved from 2.33736 to 2.21720, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 4/100\n",
      "274/274 [==============================] - 19s 70ms/step - loss: 2.1351 - accuracy: 0.5247 - val_loss: 2.3945 - val_accuracy: 0.50561 -  - ETA: 1s - loss: 2.1373 - accura -\n",
      "\n",
      "Epoch 00004: loss improved from 2.21720 to 2.13511, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 5/100\n",
      "274/274 [==============================] - 18s 64ms/step - loss: 2.0484 - accuracy: 0.5401 - val_loss: 2.3354 - val_accuracy: 0.5131\n",
      "\n",
      "Epoch 00005: loss improved from 2.13511 to 2.04844, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 6/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 19s 69ms/step - loss: 1.9919 - accuracy: 0.5515 - val_loss: 2.3008 - val_accuracy: 0.5173\n",
      "\n",
      "Epoch 00006: loss improved from 2.04844 to 1.99187, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 7/100\n",
      "274/274 [==============================] - 18s 67ms/step - loss: 1.9508 - accuracy: 0.5617 - val_loss: 2.2538 - val_accuracy: 0.5321\n",
      "\n",
      "Epoch 00007: loss improved from 1.99187 to 1.95083, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 8/100\n",
      "274/274 [==============================] - 18s 64ms/step - loss: 1.9112 - accuracy: 0.5663 - val_loss: 2.2422 - val_accuracy: 0.5234\n",
      "\n",
      "Epoch 00008: loss improved from 1.95083 to 1.91118, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 9/100\n",
      "274/274 [==============================] - 18s 64ms/step - loss: 1.8725 - accuracy: 0.5754 - val_loss: 2.2070 - val_accuracy: 0.5369\n",
      "\n",
      "Epoch 00009: loss improved from 1.91118 to 1.87254, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 10/100\n",
      "274/274 [==============================] - 12s 44ms/step - loss: 1.8509 - accuracy: 0.5826 - val_loss: 2.1795 - val_accuracy: 0.5406\n",
      "\n",
      "Epoch 00010: loss improved from 1.87254 to 1.85089, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 11/100\n",
      "274/274 [==============================] - 12s 44ms/step - loss: 1.8205 - accuracy: 0.5877 - val_loss: 2.1390 - val_accuracy: 0.5518\n",
      "\n",
      "Epoch 00011: loss improved from 1.85089 to 1.82050, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 12/100\n",
      "274/274 [==============================] - 13s 47ms/step - loss: 1.7957 - accuracy: 0.5950 - val_loss: 2.1413 - val_accuracy: 0.5515\n",
      "\n",
      "Epoch 00012: loss improved from 1.82050 to 1.79575, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 13/100\n",
      "274/274 [==============================] - 11s 40ms/step - loss: 1.7721 - accuracy: 0.6003 - val_loss: 2.1425 - val_accuracy: 0.5463\n",
      "\n",
      "Epoch 00013: loss improved from 1.79575 to 1.77205, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 14/100\n",
      "274/274 [==============================] - 11s 38ms/step - loss: 1.7558 - accuracy: 0.6007 - val_loss: 2.1650 - val_accuracy: 0.5429\n",
      "\n",
      "Epoch 00014: loss improved from 1.77205 to 1.75579, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 15/100\n",
      "274/274 [==============================] - 10s 37ms/step - loss: 1.7485 - accuracy: 0.6064 - val_loss: 2.1097 - val_accuracy: 0.5559\n",
      "\n",
      "Epoch 00015: loss improved from 1.75579 to 1.74850, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 16/100\n",
      "274/274 [==============================] - 10s 37ms/step - loss: 1.7316 - accuracy: 0.6087 - val_loss: 2.0999 - val_accuracy: 0.5561\n",
      "\n",
      "Epoch 00016: loss improved from 1.74850 to 1.73156, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 17/100\n",
      "274/274 [==============================] - 10s 37ms/step - loss: 1.7067 - accuracy: 0.6141 - val_loss: 2.0849 - val_accuracy: 0.5609\n",
      "\n",
      "Epoch 00017: loss improved from 1.73156 to 1.70675, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 18/100\n",
      "274/274 [==============================] - 10s 38ms/step - loss: 1.6898 - accuracy: 0.6195 - val_loss: 2.0907 - val_accuracy: 0.5584\n",
      "\n",
      "Epoch 00018: loss improved from 1.70675 to 1.68979, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 19/100\n",
      "274/274 [==============================] - 10s 37ms/step - loss: 1.6955 - accuracy: 0.6179 - val_loss: 2.0860 - val_accuracy: 0.5632\n",
      "\n",
      "Epoch 00019: loss did not improve from 1.68979\n",
      "Epoch 20/100\n",
      "274/274 [==============================] - 10s 37ms/step - loss: 1.6770 - accuracy: 0.6209 - val_loss: 2.1064 - val_accuracy: 0.5534\n",
      "\n",
      "Epoch 00020: loss improved from 1.68979 to 1.67704, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 21/100\n",
      "274/274 [==============================] - 10s 37ms/step - loss: 1.6649 - accuracy: 0.6245 - val_loss: 2.0764 - val_accuracy: 0.5611\n",
      "\n",
      "Epoch 00021: loss improved from 1.67704 to 1.66490, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 22/100\n",
      "274/274 [==============================] - 10s 37ms/step - loss: 1.6541 - accuracy: 0.6279 - val_loss: 2.0700 - val_accuracy: 0.5609\n",
      "\n",
      "Epoch 00022: loss improved from 1.66490 to 1.65413, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 23/100\n",
      "274/274 [==============================] - 10s 37ms/step - loss: 1.6507 - accuracy: 0.6285 - val_loss: 2.0568 - val_accuracy: 0.5723\n",
      "\n",
      "Epoch 00023: loss improved from 1.65413 to 1.65070, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 24/100\n",
      "274/274 [==============================] - 10s 37ms/step - loss: 1.6335 - accuracy: 0.6336 - val_loss: 2.0540 - val_accuracy: 0.5666\n",
      "\n",
      "Epoch 00024: loss improved from 1.65070 to 1.63354, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 25/100\n",
      "274/274 [==============================] - 10s 37ms/step - loss: 1.6316 - accuracy: 0.6378 - val_loss: 2.0634 - val_accuracy: 0.5641\n",
      "\n",
      "Epoch 00025: loss improved from 1.63354 to 1.63157, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 26/100\n",
      "274/274 [==============================] - 10s 37ms/step - loss: 1.6170 - accuracy: 0.6369 - val_loss: 2.0448 - val_accuracy: 0.5733\n",
      "\n",
      "Epoch 00026: loss improved from 1.63157 to 1.61697, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 27/100\n",
      "274/274 [==============================] - 10s 37ms/step - loss: 1.6125 - accuracy: 0.6363 - val_loss: 2.0436 - val_accuracy: 0.5641\n",
      "\n",
      "Epoch 00027: loss improved from 1.61697 to 1.61246, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 28/100\n",
      "274/274 [==============================] - 10s 37ms/step - loss: 1.5948 - accuracy: 0.6429 - val_loss: 2.0342 - val_accuracy: 0.5710\n",
      "\n",
      "Epoch 00028: loss improved from 1.61246 to 1.59477, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 29/100\n",
      "274/274 [==============================] - 10s 37ms/step - loss: 1.5875 - accuracy: 0.6421 - val_loss: 2.0356 - val_accuracy: 0.5730\n",
      "\n",
      "Epoch 00029: loss improved from 1.59477 to 1.58755, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 30/100\n",
      "274/274 [==============================] - 10s 38ms/step - loss: 1.5868 - accuracy: 0.6425 - val_loss: 2.0323 - val_accuracy: 0.5746\n",
      "\n",
      "Epoch 00030: loss improved from 1.58755 to 1.58680, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 31/100\n",
      "274/274 [==============================] - 10s 37ms/step - loss: 1.5770 - accuracy: 0.6460 - val_loss: 2.0433 - val_accuracy: 0.5749\n",
      "\n",
      "Epoch 00031: loss improved from 1.58680 to 1.57704, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 32/100\n",
      "274/274 [==============================] - 11s 39ms/step - loss: 1.5724 - accuracy: 0.6470 - val_loss: 2.0237 - val_accuracy: 0.5746\n",
      "\n",
      "Epoch 00032: loss improved from 1.57704 to 1.57241, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 33/100\n",
      "274/274 [==============================] - 11s 39ms/step - loss: 1.5647 - accuracy: 0.6494 - val_loss: 2.0202 - val_accuracy: 0.5714\n",
      "\n",
      "Epoch 00033: loss improved from 1.57241 to 1.56466, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 34/100\n",
      "274/274 [==============================] - 11s 39ms/step - loss: 1.5514 - accuracy: 0.6523 - val_loss: 2.0265 - val_accuracy: 0.5760\n",
      "\n",
      "Epoch 00034: loss improved from 1.56466 to 1.55136, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 35/100\n",
      "274/274 [==============================] - 11s 39ms/step - loss: 1.5456 - accuracy: 0.6557 - val_loss: 2.0311 - val_accuracy: 0.5755\n",
      "\n",
      "Epoch 00035: loss improved from 1.55136 to 1.54557, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 36/100\n",
      "274/274 [==============================] - 11s 39ms/step - loss: 1.5376 - accuracy: 0.6561 - val_loss: 2.0293 - val_accuracy: 0.5790\n",
      "\n",
      "Epoch 00036: loss improved from 1.54557 to 1.53765, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 37/100\n",
      "274/274 [==============================] - 11s 40ms/step - loss: 1.5318 - accuracy: 0.6542 - val_loss: 2.0134 - val_accuracy: 0.5776\n",
      "\n",
      "Epoch 00037: loss improved from 1.53765 to 1.53179, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 38/100\n",
      "274/274 [==============================] - 11s 39ms/step - loss: 1.5303 - accuracy: 0.6549 - val_loss: 2.0047 - val_accuracy: 0.5794\n",
      "\n",
      "Epoch 00038: loss improved from 1.53179 to 1.53029, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 39/100\n",
      "274/274 [==============================] - 11s 39ms/step - loss: 1.5317 - accuracy: 0.6564 - val_loss: 1.9922 - val_accuracy: 0.5822\n",
      "\n",
      "Epoch 00039: loss did not improve from 1.53029\n",
      "Epoch 40/100\n",
      "274/274 [==============================] - 11s 39ms/step - loss: 1.5182 - accuracy: 0.6577 - val_loss: 2.0116 - val_accuracy: 0.5797\n",
      "\n",
      "Epoch 00040: loss improved from 1.53029 to 1.51820, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 41/100\n",
      "274/274 [==============================] - 11s 40ms/step - loss: 1.5112 - accuracy: 0.6609 - val_loss: 2.0131 - val_accuracy: 0.5717\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00041: loss improved from 1.51820 to 1.51120, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 42/100\n",
      "274/274 [==============================] - 11s 39ms/step - loss: 1.4995 - accuracy: 0.6626 - val_loss: 2.0058 - val_accuracy: 0.5790\n",
      "\n",
      "Epoch 00042: loss improved from 1.51120 to 1.49949, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 43/100\n",
      "274/274 [==============================] - 11s 39ms/step - loss: 1.4988 - accuracy: 0.6645 - val_loss: 2.0115 - val_accuracy: 0.5819\n",
      "\n",
      "Epoch 00043: loss improved from 1.49949 to 1.49879, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 44/100\n",
      "274/274 [==============================] - 11s 39ms/step - loss: 1.4937 - accuracy: 0.6665 - val_loss: 2.0031 - val_accuracy: 0.5787\n",
      "\n",
      "Epoch 00044: loss improved from 1.49879 to 1.49374, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 45/100\n",
      "274/274 [==============================] - 11s 39ms/step - loss: 1.4891 - accuracy: 0.6672 - val_loss: 1.9933 - val_accuracy: 0.5801\n",
      "\n",
      "Epoch 00045: loss improved from 1.49374 to 1.48909, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 46/100\n",
      "274/274 [==============================] - 11s 39ms/step - loss: 1.4849 - accuracy: 0.6686 - val_loss: 1.9902 - val_accuracy: 0.5829\n",
      "\n",
      "Epoch 00046: loss improved from 1.48909 to 1.48493, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 47/100\n",
      "274/274 [==============================] - 11s 39ms/step - loss: 1.4758 - accuracy: 0.6702 - val_loss: 2.0057 - val_accuracy: 0.5769\n",
      "\n",
      "Epoch 00047: loss improved from 1.48493 to 1.47584, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 48/100\n",
      "274/274 [==============================] - 11s 39ms/step - loss: 1.4852 - accuracy: 0.6689 - val_loss: 2.0306 - val_accuracy: 0.5737\n",
      "\n",
      "Epoch 00048: loss did not improve from 1.47584\n",
      "Epoch 49/100\n",
      "274/274 [==============================] - 11s 39ms/step - loss: 1.4700 - accuracy: 0.6729 - val_loss: 2.0027 - val_accuracy: 0.5792\n",
      "\n",
      "Epoch 00049: loss improved from 1.47584 to 1.47001, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 50/100\n",
      "274/274 [==============================] - 11s 39ms/step - loss: 1.4664 - accuracy: 0.6729 - val_loss: 2.0103 - val_accuracy: 0.5776\n",
      "\n",
      "Epoch 00050: loss improved from 1.47001 to 1.46642, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 51/100\n",
      "274/274 [==============================] - 11s 39ms/step - loss: 1.4643 - accuracy: 0.6707 - val_loss: 2.0152 - val_accuracy: 0.5810\n",
      "\n",
      "Epoch 00051: loss improved from 1.46642 to 1.46432, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 52/100\n",
      "274/274 [==============================] - 11s 39ms/step - loss: 1.4573 - accuracy: 0.6729 - val_loss: 1.9972 - val_accuracy: 0.5785\n",
      "\n",
      "Epoch 00052: loss improved from 1.46432 to 1.45730, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 53/100\n",
      "274/274 [==============================] - 11s 39ms/step - loss: 1.4593 - accuracy: 0.6756 - val_loss: 2.0063 - val_accuracy: 0.5776\n",
      "\n",
      "Epoch 00053: loss did not improve from 1.45730\n",
      "Epoch 54/100\n",
      "274/274 [==============================] - 11s 39ms/step - loss: 1.4506 - accuracy: 0.6764 - val_loss: 2.0029 - val_accuracy: 0.5760\n",
      "\n",
      "Epoch 00054: loss improved from 1.45730 to 1.45061, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 55/100\n",
      "274/274 [==============================] - 11s 39ms/step - loss: 1.4483 - accuracy: 0.6735 - val_loss: 1.9894 - val_accuracy: 0.5863\n",
      "\n",
      "Epoch 00055: loss improved from 1.45061 to 1.44826, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 56/100\n",
      "274/274 [==============================] - 11s 39ms/step - loss: 1.4455 - accuracy: 0.6758 - val_loss: 2.0096 - val_accuracy: 0.5767\n",
      "\n",
      "Epoch 00056: loss improved from 1.44826 to 1.44546, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 57/100\n",
      "274/274 [==============================] - 11s 39ms/step - loss: 1.4405 - accuracy: 0.6746 - val_loss: 1.9949 - val_accuracy: 0.5865\n",
      "\n",
      "Epoch 00057: loss improved from 1.44546 to 1.44048, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 58/100\n",
      "274/274 [==============================] - 11s 39ms/step - loss: 1.4313 - accuracy: 0.6802 - val_loss: 1.9851 - val_accuracy: 0.5851\n",
      "\n",
      "Epoch 00058: loss improved from 1.44048 to 1.43131, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 59/100\n",
      "274/274 [==============================] - 11s 39ms/step - loss: 1.4363 - accuracy: 0.6767 - val_loss: 1.9954 - val_accuracy: 0.5801\n",
      "\n",
      "Epoch 00059: loss did not improve from 1.43131\n",
      "Epoch 60/100\n",
      "274/274 [==============================] - 11s 39ms/step - loss: 1.4300 - accuracy: 0.6781 - val_loss: 1.9939 - val_accuracy: 0.5840\n",
      "\n",
      "Epoch 00060: loss improved from 1.43131 to 1.43001, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 61/100\n",
      "274/274 [==============================] - 11s 39ms/step - loss: 1.4129 - accuracy: 0.6835 - val_loss: 1.9877 - val_accuracy: 0.5886\n",
      "\n",
      "Epoch 00061: loss improved from 1.43001 to 1.41292, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 62/100\n",
      "274/274 [==============================] - 11s 39ms/step - loss: 1.4161 - accuracy: 0.6827 - val_loss: 1.9943 - val_accuracy: 0.5863\n",
      "\n",
      "Epoch 00062: loss did not improve from 1.41292\n",
      "Epoch 63/100\n",
      "274/274 [==============================] - 11s 39ms/step - loss: 1.4154 - accuracy: 0.6835 - val_loss: 1.9940 - val_accuracy: 0.5838\n",
      "\n",
      "Epoch 00063: loss did not improve from 1.41292\n",
      "Epoch 64/100\n",
      "274/274 [==============================] - 11s 39ms/step - loss: 1.4122 - accuracy: 0.6829 - val_loss: 2.0228 - val_accuracy: 0.5803\n",
      "\n",
      "Epoch 00064: loss improved from 1.41292 to 1.41216, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 65/100\n",
      "274/274 [==============================] - 11s 39ms/step - loss: 1.4190 - accuracy: 0.6818 - val_loss: 2.0037 - val_accuracy: 0.5810\n",
      "\n",
      "Epoch 00065: loss did not improve from 1.41216\n",
      "Epoch 66/100\n",
      "274/274 [==============================] - 11s 39ms/step - loss: 1.4087 - accuracy: 0.6854 - val_loss: 1.9843 - val_accuracy: 0.5861\n",
      "\n",
      "Epoch 00066: loss improved from 1.41216 to 1.40870, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 67/100\n",
      "274/274 [==============================] - 11s 39ms/step - loss: 1.4089 - accuracy: 0.6857 - val_loss: 1.9920 - val_accuracy: 0.5826\n",
      "\n",
      "Epoch 00067: loss did not improve from 1.40870\n",
      "Epoch 68/100\n",
      "274/274 [==============================] - 11s 39ms/step - loss: 1.3993 - accuracy: 0.6867 - val_loss: 2.0027 - val_accuracy: 0.5851\n",
      "\n",
      "Epoch 00068: loss improved from 1.40870 to 1.39928, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 69/100\n",
      "274/274 [==============================] - 11s 39ms/step - loss: 1.4038 - accuracy: 0.6821 - val_loss: 1.9934 - val_accuracy: 0.5854\n",
      "\n",
      "Epoch 00069: loss did not improve from 1.39928\n",
      "Epoch 70/100\n",
      "274/274 [==============================] - 11s 39ms/step - loss: 1.3863 - accuracy: 0.6890 - val_loss: 1.9966 - val_accuracy: 0.5849\n",
      "\n",
      "Epoch 00070: loss improved from 1.39928 to 1.38635, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 71/100\n",
      "274/274 [==============================] - 11s 39ms/step - loss: 1.3934 - accuracy: 0.6871 - val_loss: 1.9967 - val_accuracy: 0.5863\n",
      "\n",
      "Epoch 00071: loss did not improve from 1.38635\n",
      "Epoch 72/100\n",
      "274/274 [==============================] - 11s 39ms/step - loss: 1.3917 - accuracy: 0.6911 - val_loss: 2.0036 - val_accuracy: 0.5874\n",
      "\n",
      "Epoch 00072: loss did not improve from 1.38635\n",
      "Epoch 73/100\n",
      "274/274 [==============================] - 11s 39ms/step - loss: 1.3880 - accuracy: 0.6870 - val_loss: 2.0010 - val_accuracy: 0.5863\n",
      "\n",
      "Epoch 00073: loss did not improve from 1.38635\n",
      "Epoch 74/100\n",
      "274/274 [==============================] - 11s 39ms/step - loss: 1.3849 - accuracy: 0.6883 - val_loss: 2.0030 - val_accuracy: 0.5842\n",
      "\n",
      "Epoch 00074: loss improved from 1.38635 to 1.38489, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 75/100\n",
      "274/274 [==============================] - 11s 39ms/step - loss: 1.3863 - accuracy: 0.6888 - val_loss: 2.0197 - val_accuracy: 0.5810\n",
      "\n",
      "Epoch 00075: loss did not improve from 1.38489\n",
      "Epoch 76/100\n",
      "274/274 [==============================] - 11s 39ms/step - loss: 1.3732 - accuracy: 0.6903 - val_loss: 1.9982 - val_accuracy: 0.5922\n",
      "\n",
      "Epoch 00076: loss improved from 1.38489 to 1.37320, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 77/100\n",
      "274/274 [==============================] - 11s 39ms/step - loss: 1.3790 - accuracy: 0.6903 - val_loss: 2.0144 - val_accuracy: 0.5831\n",
      "\n",
      "Epoch 00077: loss did not improve from 1.37320\n",
      "Epoch 78/100\n",
      "274/274 [==============================] - 11s 41ms/step - loss: 1.3719 - accuracy: 0.6915 - val_loss: 2.0202 - val_accuracy: 0.5833\n",
      "\n",
      "Epoch 00078: loss improved from 1.37320 to 1.37190, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 79/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "274/274 [==============================] - 11s 41ms/step - loss: 1.3766 - accuracy: 0.6893 - val_loss: 2.0052 - val_accuracy: 0.5861\n",
      "\n",
      "Epoch 00079: loss did not improve from 1.37190\n",
      "Epoch 80/100\n",
      "274/274 [==============================] - 11s 42ms/step - loss: 1.3705 - accuracy: 0.6914 - val_loss: 1.9968 - val_accuracy: 0.5904\n",
      "\n",
      "Epoch 00080: loss improved from 1.37190 to 1.37054, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 81/100\n",
      "274/274 [==============================] - 11s 41ms/step - loss: 1.3682 - accuracy: 0.6917 - val_loss: 2.0057 - val_accuracy: 0.5877\n",
      "\n",
      "Epoch 00081: loss improved from 1.37054 to 1.36823, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 82/100\n",
      "274/274 [==============================] - 11s 41ms/step - loss: 1.3637 - accuracy: 0.6930 - val_loss: 1.9876 - val_accuracy: 0.5895\n",
      "\n",
      "Epoch 00082: loss improved from 1.36823 to 1.36367, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 83/100\n",
      "274/274 [==============================] - 11s 41ms/step - loss: 1.3558 - accuracy: 0.6960 - val_loss: 2.0222 - val_accuracy: 0.5815\n",
      "\n",
      "Epoch 00083: loss improved from 1.36367 to 1.35583, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 84/100\n",
      "274/274 [==============================] - 11s 41ms/step - loss: 1.3534 - accuracy: 0.6951 - val_loss: 2.0080 - val_accuracy: 0.5856\n",
      "\n",
      "Epoch 00084: loss improved from 1.35583 to 1.35341, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 85/100\n",
      "274/274 [==============================] - 11s 41ms/step - loss: 1.3525 - accuracy: 0.6941 - val_loss: 2.0033 - val_accuracy: 0.5877\n",
      "\n",
      "Epoch 00085: loss improved from 1.35341 to 1.35250, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 86/100\n",
      "274/274 [==============================] - 11s 41ms/step - loss: 1.3607 - accuracy: 0.6962 - val_loss: 2.0165 - val_accuracy: 0.5838\n",
      "\n",
      "Epoch 00086: loss did not improve from 1.35250\n",
      "Epoch 87/100\n",
      "274/274 [==============================] - 11s 41ms/step - loss: 1.3561 - accuracy: 0.6954 - val_loss: 1.9968 - val_accuracy: 0.5906\n",
      "\n",
      "Epoch 00087: loss did not improve from 1.35250\n",
      "Epoch 88/100\n",
      "274/274 [==============================] - 11s 41ms/step - loss: 1.3517 - accuracy: 0.6966 - val_loss: 2.0040 - val_accuracy: 0.5865\n",
      "\n",
      "Epoch 00088: loss improved from 1.35250 to 1.35165, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 89/100\n",
      "274/274 [==============================] - 11s 41ms/step - loss: 1.3540 - accuracy: 0.6948 - val_loss: 1.9920 - val_accuracy: 0.5931\n",
      "\n",
      "Epoch 00089: loss did not improve from 1.35165\n",
      "Epoch 90/100\n",
      "274/274 [==============================] - 11s 41ms/step - loss: 1.3402 - accuracy: 0.6965 - val_loss: 1.9954 - val_accuracy: 0.5838\n",
      "\n",
      "Epoch 00090: loss improved from 1.35165 to 1.34016, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 91/100\n",
      "274/274 [==============================] - 11s 41ms/step - loss: 1.3398 - accuracy: 0.6989 - val_loss: 1.9971 - val_accuracy: 0.5899\n",
      "\n",
      "Epoch 00091: loss improved from 1.34016 to 1.33979, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 92/100\n",
      "274/274 [==============================] - 11s 41ms/step - loss: 1.3453 - accuracy: 0.6973 - val_loss: 1.9894 - val_accuracy: 0.5874\n",
      "\n",
      "Epoch 00092: loss did not improve from 1.33979\n",
      "Epoch 93/100\n",
      "274/274 [==============================] - 11s 41ms/step - loss: 1.3396 - accuracy: 0.6990 - val_loss: 1.9829 - val_accuracy: 0.5913\n",
      "\n",
      "Epoch 00093: loss improved from 1.33979 to 1.33958, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 94/100\n",
      "274/274 [==============================] - 11s 41ms/step - loss: 1.3264 - accuracy: 0.7036 - val_loss: 2.0305 - val_accuracy: 0.5877\n",
      "\n",
      "Epoch 00094: loss improved from 1.33958 to 1.32641, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 95/100\n",
      "274/274 [==============================] - 11s 41ms/step - loss: 1.3330 - accuracy: 0.6973 - val_loss: 2.0266 - val_accuracy: 0.5858\n",
      "\n",
      "Epoch 00095: loss did not improve from 1.32641\n",
      "Epoch 96/100\n",
      "274/274 [==============================] - 11s 41ms/step - loss: 1.3309 - accuracy: 0.6983 - val_loss: 1.9906 - val_accuracy: 0.5927\n",
      "\n",
      "Epoch 00096: loss did not improve from 1.32641\n",
      "Epoch 97/100\n",
      "274/274 [==============================] - 11s 41ms/step - loss: 1.3297 - accuracy: 0.7007 - val_loss: 2.0143 - val_accuracy: 0.5835\n",
      "\n",
      "Epoch 00097: loss did not improve from 1.32641\n",
      "Epoch 98/100\n",
      "274/274 [==============================] - 11s 42ms/step - loss: 1.3289 - accuracy: 0.7013 - val_loss: 2.0164 - val_accuracy: 0.5819\n",
      "\n",
      "Epoch 00098: loss did not improve from 1.32641\n",
      "Epoch 99/100\n",
      "274/274 [==============================] - 11s 41ms/step - loss: 1.3288 - accuracy: 0.7013 - val_loss: 2.0209 - val_accuracy: 0.5849\n",
      "\n",
      "Epoch 00099: loss did not improve from 1.32641\n",
      "Epoch 100/100\n",
      "274/274 [==============================] - 11s 41ms/step - loss: 1.3252 - accuracy: 0.7009 - val_loss: 2.0006 - val_accuracy: 0.5904\n",
      "\n",
      "Epoch 00100: loss improved from 1.32641 to 1.32518, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 1/100\n",
      "274/274 [==============================] - 25s 82ms/step - loss: 2.6238 - accuracy: 0.4863 - val_loss: 2.4832 - val_accuracy: 0.4885\n",
      "\n",
      "Epoch 00001: loss improved from inf to 2.62376, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 2/100\n",
      "274/274 [==============================] - 22s 80ms/step - loss: 2.2043 - accuracy: 0.5132 - val_loss: 2.3727 - val_accuracy: 0.5083\n",
      "\n",
      "Epoch 00002: loss improved from 2.62376 to 2.20434, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 3/100\n",
      "274/274 [==============================] - 22s 81ms/step - loss: 2.0780 - accuracy: 0.5304 - val_loss: 2.3148 - val_accuracy: 0.5042\n",
      "\n",
      "Epoch 00003: loss improved from 2.20434 to 2.07795, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 4/100\n",
      "274/274 [==============================] - 22s 80ms/step - loss: 1.9934 - accuracy: 0.5483 - val_loss: 2.2319 - val_accuracy: 0.5259\n",
      "\n",
      "Epoch 00004: loss improved from 2.07795 to 1.99341, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 5/100\n",
      "274/274 [==============================] - 22s 80ms/step - loss: 1.9275 - accuracy: 0.5622 - val_loss: 2.1909 - val_accuracy: 0.5303\n",
      "\n",
      "Epoch 00005: loss improved from 1.99341 to 1.92753, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 6/100\n",
      "274/274 [==============================] - 22s 80ms/step - loss: 1.8774 - accuracy: 0.5750 - val_loss: 2.1500 - val_accuracy: 0.5371\n",
      "\n",
      "Epoch 00006: loss improved from 1.92753 to 1.87744, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 7/100\n",
      "274/274 [==============================] - 22s 81ms/step - loss: 1.8473 - accuracy: 0.5814 - val_loss: 2.1163 - val_accuracy: 0.5477\n",
      "\n",
      "Epoch 00007: loss improved from 1.87744 to 1.84726, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 8/100\n",
      "274/274 [==============================] - 22s 81ms/step - loss: 1.8133 - accuracy: 0.5881 - val_loss: 2.1175 - val_accuracy: 0.5408\n",
      "\n",
      "Epoch 00008: loss improved from 1.84726 to 1.81333, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 9/100\n",
      "274/274 [==============================] - 22s 81ms/step - loss: 1.7838 - accuracy: 0.5961 - val_loss: 2.0948 - val_accuracy: 0.5557\n",
      "\n",
      "Epoch 00009: loss improved from 1.81333 to 1.78380, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 10/100\n",
      "274/274 [==============================] - 22s 80ms/step - loss: 1.7586 - accuracy: 0.6030 - val_loss: 2.0698 - val_accuracy: 0.5650\n",
      "\n",
      "Epoch 00010: loss improved from 1.78380 to 1.75865, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 11/100\n",
      "274/274 [==============================] - 22s 80ms/step - loss: 1.7310 - accuracy: 0.6113 - val_loss: 2.0720 - val_accuracy: 0.5637\n",
      "\n",
      "Epoch 00011: loss improved from 1.75865 to 1.73104, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 12/100\n",
      "274/274 [==============================] - 22s 80ms/step - loss: 1.7160 - accuracy: 0.6123 - val_loss: 2.0482 - val_accuracy: 0.5595\n",
      "\n",
      "Epoch 00012: loss improved from 1.73104 to 1.71601, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 13/100\n",
      "274/274 [==============================] - 22s 80ms/step - loss: 1.6881 - accuracy: 0.6183 - val_loss: 2.0634 - val_accuracy: 0.5589\n",
      "\n",
      "Epoch 00013: loss improved from 1.71601 to 1.68811, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 14/100\n",
      "274/274 [==============================] - 22s 81ms/step - loss: 1.6804 - accuracy: 0.6222 - val_loss: 2.0325 - val_accuracy: 0.5673\n",
      "\n",
      "Epoch 00014: loss improved from 1.68811 to 1.68040, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 15/100\n",
      "274/274 [==============================] - 23s 85ms/step - loss: 1.6588 - accuracy: 0.6244 - val_loss: 2.0208 - val_accuracy: 0.5662\n",
      "\n",
      "Epoch 00015: loss improved from 1.68040 to 1.65883, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 16/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 44/274 [===>..........................] - ETA: 18s - loss: 1.6120 - accuracy: 0.6307"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-4020ff4d3db4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m                                 save_best_only=True, mode='min')\n\u001b[0;32m      8\u001b[0m     \u001b[0mearly_stopping\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mEarlyStopping\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmonitor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'loss'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpatience\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m30\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'min'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m     model.fit(X, y, epochs=epochs, batch_size=batch_size, \n\u001b[0m\u001b[0;32m     10\u001b[0m             validation_split=0.2, callbacks=[early_stopping, cp_callback])\n\u001b[0;32m     11\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'models/model_{i}.h5'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\jy\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1182\u001b[0m                 _r=1):\n\u001b[0;32m   1183\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1184\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1185\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1186\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\jy\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    883\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    884\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 885\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    886\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    887\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\jy\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    915\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    916\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 917\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    918\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    919\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\jy\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3037\u001b[0m       (graph_function,\n\u001b[0;32m   3038\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m-> 3039\u001b[1;33m     return graph_function._call_flat(\n\u001b[0m\u001b[0;32m   3040\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0;32m   3041\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\jy\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1961\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1962\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1963\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1964\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1965\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32mc:\\users\\jy\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    589\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    590\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 591\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    592\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    593\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\jy\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 위의 모델들 학습하면서 stacking\n",
    "for i in range(5):\n",
    "    model = getattr(Models, f'define_model_{i}')()\n",
    "    checkpoint_path = \"checkpoint/cp.ckpt\"\n",
    "    cp_callback = ModelCheckpoint(filepath=checkpoint_path, monitor='loss', \n",
    "                                verbose=1, save_weights_only=True, \n",
    "                                save_best_only=True, mode='min')\n",
    "    early_stopping = EarlyStopping(monitor='loss', patience=5, mode='min')\n",
    "    model.fit(X, y, epochs=epochs, batch_size=batch_size, \n",
    "            validation_split=0.2, callbacks=[early_stopping, cp_callback])\n",
    "    model.save(f'models/211008_model_{i}.h5')\n",
    "    tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "executionInfo": {
     "elapsed": 5606,
     "status": "ok",
     "timestamp": 1633579387323,
     "user": {
      "displayName": "꾸꾸",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "14922489440020274566"
     },
     "user_tz": -540
    },
    "id": "-Sqxkt_QkEUa"
   },
   "outputs": [],
   "source": [
    "# 저장한 모델 불러오기\n",
    "for i in range(5): # 모델 갯수\n",
    "    globals()[f'model{i}'] = load_model(f'models/211008_model_{i}.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "executionInfo": {
     "elapsed": 208,
     "status": "ok",
     "timestamp": 1633579707189,
     "user": {
      "displayName": "꾸꾸",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "14922489440020274566"
     },
     "user_tz": -540
    },
    "id": "t4TQvwEz73Kg"
   },
   "outputs": [],
   "source": [
    "model0._name = 'Client0'\n",
    "model1._name = 'Client1'\n",
    "model2._name = 'Client2'\n",
    "model3._name = 'Client3'\n",
    "model4._name = 'Client4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "zMyFk1x-kEYe"
   },
   "outputs": [],
   "source": [
    "inputs = Input(shape=(n_steps, n_length, n_features))\n",
    "\n",
    "merge = concatenate([model0(inputs), model1(inputs), model2(inputs), model3(inputs), model4(inputs)])\n",
    "hidden = Dense(10, activation='relu')(merge)\n",
    "output = Dense(61, activation='softmax')(hidden)\n",
    "model = tf.keras.models.Model(inputs=inputs, outputs=output)\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1119943,
     "status": "ok",
     "timestamp": 1633580845256,
     "user": {
      "displayName": "꾸꾸",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "14922489440020274566"
     },
     "user_tz": -540
    },
    "id": "JyJBKsFxkEbn",
    "outputId": "70882a38-e090-41e8-f0ba-f582c9502eaa",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "335/335 [==============================] - 120s 329ms/step - loss: 2.9083 - accuracy: 0.4686 - val_loss: 2.9914 - val_accuracy: 0.4863\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 2.99139, saving model to checkpoint\\cp.ckpt\n",
      "Epoch 2/100\n",
      "335/335 [==============================] - 106s 316ms/step - loss: 2.0825 - accuracy: 0.5330 - val_loss: 3.1542 - val_accuracy: 0.4521\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 2.99139\n",
      "Epoch 3/100\n",
      "335/335 [==============================] - 105s 314ms/step - loss: 1.8759 - accuracy: 0.5718 - val_loss: 3.3613 - val_accuracy: 0.4292\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 2.99139\n",
      "Epoch 4/100\n",
      "335/335 [==============================] - 101s 302ms/step - loss: 1.7181 - accuracy: 0.6002 - val_loss: 3.4827 - val_accuracy: 0.4087\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 2.99139\n",
      "Epoch 5/100\n",
      "335/335 [==============================] - 102s 304ms/step - loss: 1.6138 - accuracy: 0.6256 - val_loss: 3.5465 - val_accuracy: 0.4018\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 2.99139\n",
      "Epoch 6/100\n",
      "335/335 [==============================] - 100s 300ms/step - loss: 1.5272 - accuracy: 0.6425 - val_loss: 3.6935 - val_accuracy: 0.3973\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 2.99139\n",
      "Epoch 7/100\n",
      "335/335 [==============================] - 104s 312ms/step - loss: 1.4801 - accuracy: 0.6495 - val_loss: 3.7022 - val_accuracy: 0.3950\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 2.99139\n",
      "Epoch 8/100\n",
      "335/335 [==============================] - 99s 296ms/step - loss: 1.4324 - accuracy: 0.6611 - val_loss: 3.6701 - val_accuracy: 0.3881\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 2.99139\n",
      "Epoch 9/100\n",
      "335/335 [==============================] - 100s 299ms/step - loss: 1.4031 - accuracy: 0.6653 - val_loss: 3.7699 - val_accuracy: 0.3744\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 2.99139\n",
      "Epoch 10/100\n",
      "335/335 [==============================] - 99s 296ms/step - loss: 1.3589 - accuracy: 0.6753 - val_loss: 3.7781 - val_accuracy: 0.3699\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 2.99139\n",
      "Epoch 11/100\n",
      "335/335 [==============================] - 99s 296ms/step - loss: 1.3477 - accuracy: 0.6789 - val_loss: 3.7964 - val_accuracy: 0.3858\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 2.99139\n",
      "Epoch 12/100\n",
      "335/335 [==============================] - 100s 297ms/step - loss: 1.3225 - accuracy: 0.6838 - val_loss: 3.8525 - val_accuracy: 0.3699\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 2.99139\n",
      "Epoch 13/100\n",
      "335/335 [==============================] - 99s 295ms/step - loss: 1.2882 - accuracy: 0.6901 - val_loss: 3.9803 - val_accuracy: 0.3493\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 2.99139\n",
      "Epoch 14/100\n",
      "335/335 [==============================] - 99s 296ms/step - loss: 1.2785 - accuracy: 0.6931 - val_loss: 3.9621 - val_accuracy: 0.3630\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 2.99139\n",
      "Epoch 15/100\n",
      "335/335 [==============================] - 99s 296ms/step - loss: 1.2629 - accuracy: 0.6951 - val_loss: 3.9361 - val_accuracy: 0.3630\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 2.99139\n",
      "Epoch 16/100\n",
      "335/335 [==============================] - 99s 296ms/step - loss: 1.2391 - accuracy: 0.7033 - val_loss: 3.8965 - val_accuracy: 0.3790\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 2.99139\n",
      "Epoch 17/100\n",
      "335/335 [==============================] - 100s 298ms/step - loss: 1.2367 - accuracy: 0.7016 - val_loss: 3.9545 - val_accuracy: 0.3950\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 2.99139\n",
      "Epoch 18/100\n",
      "335/335 [==============================] - 105s 314ms/step - loss: 1.2311 - accuracy: 0.7020 - val_loss: 4.0342 - val_accuracy: 0.3721\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 2.99139\n",
      "Epoch 19/100\n",
      "335/335 [==============================] - 100s 299ms/step - loss: 1.2091 - accuracy: 0.7070 - val_loss: 4.0744 - val_accuracy: 0.3584\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 2.99139\n",
      "Epoch 20/100\n",
      "335/335 [==============================] - 104s 310ms/step - loss: 1.1998 - accuracy: 0.7097 - val_loss: 3.9820 - val_accuracy: 0.4018\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 2.99139\n",
      "Epoch 21/100\n",
      "335/335 [==============================] - 104s 310ms/step - loss: 1.1902 - accuracy: 0.7097 - val_loss: 3.9209 - val_accuracy: 0.3813\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 2.99139\n",
      "Epoch 22/100\n",
      "335/335 [==============================] - 100s 299ms/step - loss: 1.1651 - accuracy: 0.7136 - val_loss: 3.9342 - val_accuracy: 0.3744\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 2.99139\n",
      "Epoch 23/100\n",
      "335/335 [==============================] - 106s 316ms/step - loss: 1.1729 - accuracy: 0.7136 - val_loss: 4.0580 - val_accuracy: 0.3767\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 2.99139\n",
      "Epoch 24/100\n",
      "335/335 [==============================] - 106s 316ms/step - loss: 1.1596 - accuracy: 0.7158 - val_loss: 3.9458 - val_accuracy: 0.3676\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 2.99139\n",
      "Epoch 25/100\n",
      "335/335 [==============================] - 104s 310ms/step - loss: 1.1455 - accuracy: 0.7149 - val_loss: 4.1309 - val_accuracy: 0.3493\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 2.99139\n",
      "Epoch 26/100\n",
      "335/335 [==============================] - 102s 305ms/step - loss: 1.1489 - accuracy: 0.7175 - val_loss: 4.0011 - val_accuracy: 0.3767\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 2.99139\n",
      "Epoch 27/100\n",
      "335/335 [==============================] - 105s 312ms/step - loss: 1.1376 - accuracy: 0.7187 - val_loss: 4.0153 - val_accuracy: 0.3790\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 2.99139\n",
      "Epoch 28/100\n",
      "335/335 [==============================] - 102s 305ms/step - loss: 1.1176 - accuracy: 0.7220 - val_loss: 4.1936 - val_accuracy: 0.3607\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 2.99139\n",
      "Epoch 29/100\n",
      "335/335 [==============================] - 100s 298ms/step - loss: 1.1298 - accuracy: 0.7205 - val_loss: 4.1160 - val_accuracy: 0.3699\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 2.99139\n",
      "Epoch 30/100\n",
      "335/335 [==============================] - 100s 297ms/step - loss: 1.1228 - accuracy: 0.7220 - val_loss: 3.9811 - val_accuracy: 0.3813\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 2.99139\n",
      "Epoch 31/100\n",
      "335/335 [==============================] - 103s 306ms/step - loss: 1.1049 - accuracy: 0.7228 - val_loss: 4.0917 - val_accuracy: 0.3858\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 2.99139\n",
      "Epoch 32/100\n",
      "335/335 [==============================] - 100s 298ms/step - loss: 1.0935 - accuracy: 0.7244 - val_loss: 4.1885 - val_accuracy: 0.3881\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 2.99139\n",
      "Epoch 33/100\n",
      "335/335 [==============================] - 100s 300ms/step - loss: 1.0929 - accuracy: 0.7260 - val_loss: 4.1295 - val_accuracy: 0.3607\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 2.99139\n",
      "Epoch 34/100\n",
      "335/335 [==============================] - 102s 303ms/step - loss: 1.0898 - accuracy: 0.7264 - val_loss: 4.2415 - val_accuracy: 0.3881\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 2.99139\n",
      "Epoch 35/100\n",
      "335/335 [==============================] - 114s 342ms/step - loss: 1.0739 - accuracy: 0.7320 - val_loss: 4.2028 - val_accuracy: 0.3676\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 2.99139\n",
      "Epoch 36/100\n",
      "335/335 [==============================] - 126s 375ms/step - loss: 1.0572 - accuracy: 0.7327 - val_loss: 4.3007 - val_accuracy: 0.3539\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 2.99139\n",
      "Epoch 37/100\n",
      "335/335 [==============================] - 115s 344ms/step - loss: 1.0654 - accuracy: 0.7329 - val_loss: 4.1360 - val_accuracy: 0.3607\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 2.99139\n",
      "Epoch 38/100\n",
      "335/335 [==============================] - 104s 309ms/step - loss: 1.0607 - accuracy: 0.7328 - val_loss: 4.2262 - val_accuracy: 0.3858\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 2.99139\n",
      "Epoch 39/100\n",
      "335/335 [==============================] - 107s 320ms/step - loss: 1.0745 - accuracy: 0.7286 - val_loss: 4.2088 - val_accuracy: 0.3767\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 2.99139\n",
      "Epoch 40/100\n",
      "335/335 [==============================] - 100s 297ms/step - loss: 1.0509 - accuracy: 0.7355 - val_loss: 4.2496 - val_accuracy: 0.3767\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 2.99139\n",
      "Epoch 41/100\n",
      "335/335 [==============================] - 103s 308ms/step - loss: 1.0310 - accuracy: 0.7392 - val_loss: 4.2507 - val_accuracy: 0.3744\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 2.99139\n",
      "Epoch 42/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "335/335 [==============================] - 103s 309ms/step - loss: 1.0285 - accuracy: 0.7382 - val_loss: 4.3462 - val_accuracy: 0.3767\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 2.99139\n",
      "Epoch 43/100\n",
      "335/335 [==============================] - 110s 328ms/step - loss: 1.0396 - accuracy: 0.7374 - val_loss: 4.3618 - val_accuracy: 0.3516\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 2.99139\n",
      "Epoch 44/100\n",
      "335/335 [==============================] - 108s 321ms/step - loss: 1.0354 - accuracy: 0.7377 - val_loss: 4.3094 - val_accuracy: 0.3767\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 2.99139\n",
      "Epoch 45/100\n",
      "335/335 [==============================] - 100s 299ms/step - loss: 1.0262 - accuracy: 0.7399 - val_loss: 4.3382 - val_accuracy: 0.3676\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 2.99139\n",
      "Epoch 46/100\n",
      "335/335 [==============================] - 106s 316ms/step - loss: 1.0213 - accuracy: 0.7377 - val_loss: 4.2336 - val_accuracy: 0.3447\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 2.99139\n",
      "Epoch 47/100\n",
      "335/335 [==============================] - 103s 306ms/step - loss: 1.0324 - accuracy: 0.7367 - val_loss: 4.2502 - val_accuracy: 0.3493\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 2.99139\n",
      "Epoch 48/100\n",
      "335/335 [==============================] - 99s 296ms/step - loss: 1.0100 - accuracy: 0.7408 - val_loss: 4.3884 - val_accuracy: 0.3584\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 2.99139\n",
      "Epoch 49/100\n",
      "335/335 [==============================] - 100s 299ms/step - loss: 1.0152 - accuracy: 0.7431 - val_loss: 4.3701 - val_accuracy: 0.3356\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 2.99139\n",
      "Epoch 50/100\n",
      "335/335 [==============================] - 99s 297ms/step - loss: 1.0012 - accuracy: 0.7452 - val_loss: 4.1534 - val_accuracy: 0.3630\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 2.99139\n",
      "Epoch 51/100\n",
      "335/335 [==============================] - 102s 304ms/step - loss: 0.9999 - accuracy: 0.7418 - val_loss: 4.4434 - val_accuracy: 0.3699\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 2.99139\n",
      "Epoch 52/100\n",
      "335/335 [==============================] - 100s 299ms/step - loss: 0.9814 - accuracy: 0.7468 - val_loss: 4.4970 - val_accuracy: 0.3356\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 2.99139\n",
      "Epoch 53/100\n",
      "335/335 [==============================] - 100s 298ms/step - loss: 0.9931 - accuracy: 0.7424 - val_loss: 4.3896 - val_accuracy: 0.3470\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 2.99139\n",
      "Epoch 54/100\n",
      "335/335 [==============================] - 104s 310ms/step - loss: 1.0022 - accuracy: 0.7418 - val_loss: 4.3984 - val_accuracy: 0.3470\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 2.99139\n",
      "Epoch 55/100\n",
      "335/335 [==============================] - 102s 304ms/step - loss: 0.9856 - accuracy: 0.7463 - val_loss: 4.2387 - val_accuracy: 0.3539\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 2.99139\n",
      "Epoch 56/100\n",
      "335/335 [==============================] - 103s 307ms/step - loss: 0.9744 - accuracy: 0.7467 - val_loss: 4.4317 - val_accuracy: 0.3562\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 2.99139\n",
      "Epoch 57/100\n",
      "335/335 [==============================] - 102s 304ms/step - loss: 0.9988 - accuracy: 0.7433 - val_loss: 4.3558 - val_accuracy: 0.3493\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 2.99139\n",
      "Epoch 58/100\n",
      "335/335 [==============================] - 101s 302ms/step - loss: 0.9699 - accuracy: 0.7478 - val_loss: 4.4300 - val_accuracy: 0.3470\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 2.99139\n",
      "Epoch 59/100\n",
      "335/335 [==============================] - 103s 308ms/step - loss: 0.9765 - accuracy: 0.7478 - val_loss: 4.3391 - val_accuracy: 0.3539\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 2.99139\n",
      "Epoch 60/100\n",
      "335/335 [==============================] - 100s 298ms/step - loss: 0.9735 - accuracy: 0.7486 - val_loss: 4.3602 - val_accuracy: 0.3539\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 2.99139\n",
      "Epoch 61/100\n",
      "335/335 [==============================] - 99s 296ms/step - loss: 0.9639 - accuracy: 0.7492 - val_loss: 4.2711 - val_accuracy: 0.3721\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 2.99139\n",
      "Epoch 62/100\n",
      "335/335 [==============================] - 99s 297ms/step - loss: 0.9767 - accuracy: 0.7472 - val_loss: 4.3867 - val_accuracy: 0.3447\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 2.99139\n",
      "Epoch 63/100\n",
      "335/335 [==============================] - 104s 310ms/step - loss: 0.9577 - accuracy: 0.7519 - val_loss: 4.3705 - val_accuracy: 0.3584\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 2.99139\n",
      "Epoch 64/100\n",
      "335/335 [==============================] - 103s 308ms/step - loss: 0.9538 - accuracy: 0.7549 - val_loss: 4.3377 - val_accuracy: 0.3653\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 2.99139\n",
      "Epoch 65/100\n",
      "335/335 [==============================] - 101s 303ms/step - loss: 0.9521 - accuracy: 0.7516 - val_loss: 4.5208 - val_accuracy: 0.3402\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 2.99139\n",
      "Epoch 66/100\n",
      "335/335 [==============================] - 105s 313ms/step - loss: 0.9454 - accuracy: 0.7525 - val_loss: 4.3955 - val_accuracy: 0.3288\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 2.99139\n",
      "Epoch 67/100\n",
      "335/335 [==============================] - 101s 301ms/step - loss: 0.9336 - accuracy: 0.7574 - val_loss: 4.4765 - val_accuracy: 0.3447\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 2.99139\n",
      "Epoch 68/100\n",
      "335/335 [==============================] - 98s 293ms/step - loss: 0.9417 - accuracy: 0.7552 - val_loss: 4.4366 - val_accuracy: 0.3447\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 2.99139\n",
      "Epoch 69/100\n",
      "335/335 [==============================] - 98s 293ms/step - loss: 0.9334 - accuracy: 0.7576 - val_loss: 4.3877 - val_accuracy: 0.3699\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 2.99139\n",
      "Epoch 70/100\n",
      "335/335 [==============================] - 101s 301ms/step - loss: 0.9415 - accuracy: 0.7558 - val_loss: 4.4663 - val_accuracy: 0.3516\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 2.99139\n",
      "Epoch 71/100\n",
      "335/335 [==============================] - 102s 306ms/step - loss: 0.9417 - accuracy: 0.7547 - val_loss: 4.4301 - val_accuracy: 0.3425\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 2.99139\n",
      "Epoch 72/100\n",
      "335/335 [==============================] - 107s 318ms/step - loss: 0.9504 - accuracy: 0.7551 - val_loss: 4.5462 - val_accuracy: 0.3196\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 2.99139\n",
      "Epoch 73/100\n",
      "335/335 [==============================] - 106s 317ms/step - loss: 0.9299 - accuracy: 0.7565 - val_loss: 4.4592 - val_accuracy: 0.3539\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 2.99139\n",
      "Epoch 74/100\n",
      "335/335 [==============================] - 99s 296ms/step - loss: 0.9138 - accuracy: 0.7591 - val_loss: 4.5438 - val_accuracy: 0.3447\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 2.99139\n",
      "Epoch 75/100\n",
      "335/335 [==============================] - 102s 304ms/step - loss: 0.9268 - accuracy: 0.7599 - val_loss: 4.5748 - val_accuracy: 0.3447\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 2.99139\n",
      "Epoch 76/100\n",
      "335/335 [==============================] - 101s 301ms/step - loss: 0.9258 - accuracy: 0.7578 - val_loss: 4.4889 - val_accuracy: 0.3516\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 2.99139\n",
      "Epoch 77/100\n",
      "335/335 [==============================] - 100s 297ms/step - loss: 0.9186 - accuracy: 0.7579 - val_loss: 4.4771 - val_accuracy: 0.3470\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 2.99139\n",
      "Epoch 78/100\n",
      "335/335 [==============================] - 103s 307ms/step - loss: 0.9211 - accuracy: 0.7579 - val_loss: 4.5432 - val_accuracy: 0.3356\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 2.99139\n",
      "Epoch 79/100\n",
      "335/335 [==============================] - 103s 307ms/step - loss: 0.9271 - accuracy: 0.7591 - val_loss: 4.5162 - val_accuracy: 0.3311\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 2.99139\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x168b4a33c70>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint_path = \"checkpoint/cp.ckpt\"\n",
    "cp_callback = ModelCheckpoint(filepath=checkpoint_path, monitor='val_loss', verbose=1, save_weights_only=True, save_best_only=True, mode='min')\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='loss', patience=5, mode='min')\n",
    "model.fit(X, y, epochs=epochs, batch_size=batch_size, validation_split=0.02, callbacks=[early_stopping, cp_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import StratifiedKFold\n",
    "# from sklearn.metrics import accuracy_score\n",
    "\n",
    "# stfold = StratifiedKFold(n_splits=3, shuffle=True)\n",
    "# idx_iter = 0 \n",
    "# skf_accuracy=[]\n",
    "\n",
    "# for train_idx, valid_idx in stfold.split(X, y_train_total) : \n",
    "#     Y_train, Y_valid = tf.gather(y, train_idx), tf.gather(y, valid_idx)\n",
    "#     X_train, X_valid = tf.gather(X, train_idx), tf.gather(X, valid_idx)\n",
    "\n",
    "#     checkpoint_path = \"checkpoint/cp(211008).ckpt\"\n",
    "#     cp_callback = ModelCheckpoint(filepath=checkpoint_path, monitor='val_loss', verbose=1, save_weights_only=True, save_best_only=True, mode='min')\n",
    "\n",
    "#     early_stopping = EarlyStopping(monitor='loss', patience=5, mode='min')\n",
    "#     model.fit(X_train, Y_train, epochs=epochs, batch_size=batch_size, callbacks=[early_stopping, cp_callback])\n",
    "#     pred = model.predict(X_valid)\n",
    "\n",
    "#     # 반복 시 마다 정확도 측정 -> 수정해야함; \n",
    "#     idx_iter += 1 \n",
    "#     y_pred = (pred > 0.5) \n",
    "#     accuracy = np.round(accuracy_score(Y_valid, y_pred), 4)\n",
    "#     train_size = X_train.shape[0]\n",
    "#     test_size = X_valid.shape[0]\n",
    "\n",
    "#     print(\"\\n##### 교차 검증: {}, 정확도: {}  #####\" .format(idx_iter, accuracy))\n",
    "#     print('학습 레이블 데이터 분포:\\n ', Y_train.shape[0])\n",
    "#     print('검증 레이블 데이터 분포:\\n ', Y_valid.shape[0], '\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5960,
     "status": "ok",
     "timestamp": 1633580859933,
     "user": {
      "displayName": "꾸꾸",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "14922489440020274566"
     },
     "user_tz": -540
    },
    "id": "rUDiw-fA05uf",
    "outputId": "93c67665-d3d6-454b-b6b2-76ffe2e993e6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(782, 61)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction = model.predict(test_X)\n",
    "prediction.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 444
    },
    "executionInfo": {
     "elapsed": 566,
     "status": "ok",
     "timestamp": 1633580868360,
     "user": {
      "displayName": "꾸꾸",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "14922489440020274566"
     },
     "user_tz": -540
    },
    "id": "fP8wkIVHL79U",
    "outputId": "9d31623d-73fb-4eb5-dd30-0514970b48e5"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3125</td>\n",
       "      <td>8.188165e-07</td>\n",
       "      <td>3.252405e-09</td>\n",
       "      <td>5.289134e-12</td>\n",
       "      <td>5.288130e-10</td>\n",
       "      <td>1.057025e-04</td>\n",
       "      <td>6.336675e-06</td>\n",
       "      <td>1.272024e-08</td>\n",
       "      <td>1.353531e-08</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>...</td>\n",
       "      <td>3.615741e-08</td>\n",
       "      <td>4.092537e-06</td>\n",
       "      <td>9.319634e-09</td>\n",
       "      <td>1.288084e-05</td>\n",
       "      <td>8.179205e-11</td>\n",
       "      <td>4.108106e-05</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.000998</td>\n",
       "      <td>1.578432e-04</td>\n",
       "      <td>2.457487e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3126</td>\n",
       "      <td>3.557848e-03</td>\n",
       "      <td>3.452285e-05</td>\n",
       "      <td>1.907644e-03</td>\n",
       "      <td>8.422525e-03</td>\n",
       "      <td>8.233026e-04</td>\n",
       "      <td>7.096452e-04</td>\n",
       "      <td>1.453176e-03</td>\n",
       "      <td>3.240900e-04</td>\n",
       "      <td>0.002677</td>\n",
       "      <td>...</td>\n",
       "      <td>3.404642e-04</td>\n",
       "      <td>4.795172e-05</td>\n",
       "      <td>1.079065e-03</td>\n",
       "      <td>1.729587e-03</td>\n",
       "      <td>3.814084e-03</td>\n",
       "      <td>4.433006e-04</td>\n",
       "      <td>0.000325</td>\n",
       "      <td>0.000772</td>\n",
       "      <td>9.722515e-05</td>\n",
       "      <td>2.036020e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3127</td>\n",
       "      <td>7.310430e-03</td>\n",
       "      <td>3.260876e-02</td>\n",
       "      <td>2.663807e-04</td>\n",
       "      <td>1.955045e-05</td>\n",
       "      <td>4.687956e-07</td>\n",
       "      <td>1.706130e-05</td>\n",
       "      <td>6.450887e-04</td>\n",
       "      <td>1.084616e-02</td>\n",
       "      <td>0.025576</td>\n",
       "      <td>...</td>\n",
       "      <td>7.561062e-05</td>\n",
       "      <td>9.240519e-05</td>\n",
       "      <td>5.300564e-06</td>\n",
       "      <td>7.785617e-03</td>\n",
       "      <td>2.296529e-04</td>\n",
       "      <td>6.304176e-04</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>9.044350e-05</td>\n",
       "      <td>1.898947e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3128</td>\n",
       "      <td>2.403304e-03</td>\n",
       "      <td>2.892588e-06</td>\n",
       "      <td>2.312218e-05</td>\n",
       "      <td>5.341680e-05</td>\n",
       "      <td>3.259653e-05</td>\n",
       "      <td>1.905677e-06</td>\n",
       "      <td>1.216230e-04</td>\n",
       "      <td>3.120205e-05</td>\n",
       "      <td>0.002048</td>\n",
       "      <td>...</td>\n",
       "      <td>1.952361e-06</td>\n",
       "      <td>4.380901e-06</td>\n",
       "      <td>2.154401e-06</td>\n",
       "      <td>4.251190e-05</td>\n",
       "      <td>1.214165e-05</td>\n",
       "      <td>2.761259e-06</td>\n",
       "      <td>0.000412</td>\n",
       "      <td>0.000030</td>\n",
       "      <td>1.425031e-05</td>\n",
       "      <td>1.701997e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3129</td>\n",
       "      <td>8.270038e-05</td>\n",
       "      <td>7.647411e-09</td>\n",
       "      <td>7.342957e-07</td>\n",
       "      <td>5.336374e-06</td>\n",
       "      <td>5.802468e-05</td>\n",
       "      <td>6.494856e-07</td>\n",
       "      <td>1.975171e-05</td>\n",
       "      <td>4.428545e-07</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>...</td>\n",
       "      <td>3.906394e-08</td>\n",
       "      <td>9.341128e-09</td>\n",
       "      <td>8.720875e-07</td>\n",
       "      <td>5.643861e-07</td>\n",
       "      <td>8.725259e-07</td>\n",
       "      <td>2.958231e-07</td>\n",
       "      <td>0.000267</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>8.937378e-07</td>\n",
       "      <td>4.076185e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>777</th>\n",
       "      <td>3902</td>\n",
       "      <td>5.334413e-04</td>\n",
       "      <td>2.537272e-07</td>\n",
       "      <td>1.540227e-05</td>\n",
       "      <td>1.291522e-04</td>\n",
       "      <td>1.784978e-03</td>\n",
       "      <td>3.722269e-05</td>\n",
       "      <td>6.304502e-05</td>\n",
       "      <td>1.378330e-05</td>\n",
       "      <td>0.000097</td>\n",
       "      <td>...</td>\n",
       "      <td>1.185205e-06</td>\n",
       "      <td>3.891688e-07</td>\n",
       "      <td>1.386265e-05</td>\n",
       "      <td>4.249470e-06</td>\n",
       "      <td>1.846914e-05</td>\n",
       "      <td>6.107186e-06</td>\n",
       "      <td>0.000760</td>\n",
       "      <td>0.000095</td>\n",
       "      <td>1.536776e-05</td>\n",
       "      <td>2.605067e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>778</th>\n",
       "      <td>3903</td>\n",
       "      <td>1.417753e-03</td>\n",
       "      <td>9.522214e-06</td>\n",
       "      <td>9.579218e-05</td>\n",
       "      <td>2.781164e-04</td>\n",
       "      <td>1.445989e-04</td>\n",
       "      <td>3.117869e-05</td>\n",
       "      <td>8.242012e-04</td>\n",
       "      <td>3.272770e-05</td>\n",
       "      <td>0.002510</td>\n",
       "      <td>...</td>\n",
       "      <td>1.726760e-05</td>\n",
       "      <td>4.702084e-06</td>\n",
       "      <td>5.571641e-05</td>\n",
       "      <td>1.088487e-04</td>\n",
       "      <td>1.235258e-04</td>\n",
       "      <td>3.478106e-05</td>\n",
       "      <td>0.000856</td>\n",
       "      <td>0.000138</td>\n",
       "      <td>7.609236e-05</td>\n",
       "      <td>7.287843e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>779</th>\n",
       "      <td>3904</td>\n",
       "      <td>1.166258e-03</td>\n",
       "      <td>1.391959e-06</td>\n",
       "      <td>4.337814e-05</td>\n",
       "      <td>1.262150e-04</td>\n",
       "      <td>7.601050e-05</td>\n",
       "      <td>7.895438e-06</td>\n",
       "      <td>2.302951e-04</td>\n",
       "      <td>2.008697e-05</td>\n",
       "      <td>0.000473</td>\n",
       "      <td>...</td>\n",
       "      <td>3.253240e-06</td>\n",
       "      <td>1.608644e-06</td>\n",
       "      <td>1.338978e-05</td>\n",
       "      <td>1.240644e-04</td>\n",
       "      <td>4.352060e-05</td>\n",
       "      <td>1.083684e-05</td>\n",
       "      <td>0.000348</td>\n",
       "      <td>0.000095</td>\n",
       "      <td>9.161315e-06</td>\n",
       "      <td>7.376492e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>780</th>\n",
       "      <td>3905</td>\n",
       "      <td>2.303998e-05</td>\n",
       "      <td>6.097020e-03</td>\n",
       "      <td>1.234970e-04</td>\n",
       "      <td>6.617053e-05</td>\n",
       "      <td>2.639443e-06</td>\n",
       "      <td>1.714626e-06</td>\n",
       "      <td>3.114889e-02</td>\n",
       "      <td>1.622851e-06</td>\n",
       "      <td>0.001601</td>\n",
       "      <td>...</td>\n",
       "      <td>2.446040e-06</td>\n",
       "      <td>7.999105e-06</td>\n",
       "      <td>1.727888e-06</td>\n",
       "      <td>1.590365e-03</td>\n",
       "      <td>3.393491e-04</td>\n",
       "      <td>7.269366e-04</td>\n",
       "      <td>0.000080</td>\n",
       "      <td>0.000049</td>\n",
       "      <td>3.950317e-03</td>\n",
       "      <td>2.099279e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>781</th>\n",
       "      <td>3906</td>\n",
       "      <td>1.809927e-03</td>\n",
       "      <td>2.801878e-06</td>\n",
       "      <td>1.061059e-04</td>\n",
       "      <td>7.443944e-04</td>\n",
       "      <td>2.720203e-03</td>\n",
       "      <td>2.994046e-04</td>\n",
       "      <td>5.842203e-04</td>\n",
       "      <td>3.076495e-04</td>\n",
       "      <td>0.000654</td>\n",
       "      <td>...</td>\n",
       "      <td>2.121607e-04</td>\n",
       "      <td>1.571333e-05</td>\n",
       "      <td>7.258910e-04</td>\n",
       "      <td>2.635619e-05</td>\n",
       "      <td>2.207332e-04</td>\n",
       "      <td>1.112305e-04</td>\n",
       "      <td>0.002361</td>\n",
       "      <td>0.000784</td>\n",
       "      <td>1.228427e-04</td>\n",
       "      <td>2.185416e-03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>782 rows × 62 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       id             0             1             2             3  \\\n",
       "0    3125  8.188165e-07  3.252405e-09  5.289134e-12  5.288130e-10   \n",
       "1    3126  3.557848e-03  3.452285e-05  1.907644e-03  8.422525e-03   \n",
       "2    3127  7.310430e-03  3.260876e-02  2.663807e-04  1.955045e-05   \n",
       "3    3128  2.403304e-03  2.892588e-06  2.312218e-05  5.341680e-05   \n",
       "4    3129  8.270038e-05  7.647411e-09  7.342957e-07  5.336374e-06   \n",
       "..    ...           ...           ...           ...           ...   \n",
       "777  3902  5.334413e-04  2.537272e-07  1.540227e-05  1.291522e-04   \n",
       "778  3903  1.417753e-03  9.522214e-06  9.579218e-05  2.781164e-04   \n",
       "779  3904  1.166258e-03  1.391959e-06  4.337814e-05  1.262150e-04   \n",
       "780  3905  2.303998e-05  6.097020e-03  1.234970e-04  6.617053e-05   \n",
       "781  3906  1.809927e-03  2.801878e-06  1.061059e-04  7.443944e-04   \n",
       "\n",
       "                4             5             6             7         8  ...  \\\n",
       "0    1.057025e-04  6.336675e-06  1.272024e-08  1.353531e-08  0.000027  ...   \n",
       "1    8.233026e-04  7.096452e-04  1.453176e-03  3.240900e-04  0.002677  ...   \n",
       "2    4.687956e-07  1.706130e-05  6.450887e-04  1.084616e-02  0.025576  ...   \n",
       "3    3.259653e-05  1.905677e-06  1.216230e-04  3.120205e-05  0.002048  ...   \n",
       "4    5.802468e-05  6.494856e-07  1.975171e-05  4.428545e-07  0.000017  ...   \n",
       "..            ...           ...           ...           ...       ...  ...   \n",
       "777  1.784978e-03  3.722269e-05  6.304502e-05  1.378330e-05  0.000097  ...   \n",
       "778  1.445989e-04  3.117869e-05  8.242012e-04  3.272770e-05  0.002510  ...   \n",
       "779  7.601050e-05  7.895438e-06  2.302951e-04  2.008697e-05  0.000473  ...   \n",
       "780  2.639443e-06  1.714626e-06  3.114889e-02  1.622851e-06  0.001601  ...   \n",
       "781  2.720203e-03  2.994046e-04  5.842203e-04  3.076495e-04  0.000654  ...   \n",
       "\n",
       "               51            52            53            54            55  \\\n",
       "0    3.615741e-08  4.092537e-06  9.319634e-09  1.288084e-05  8.179205e-11   \n",
       "1    3.404642e-04  4.795172e-05  1.079065e-03  1.729587e-03  3.814084e-03   \n",
       "2    7.561062e-05  9.240519e-05  5.300564e-06  7.785617e-03  2.296529e-04   \n",
       "3    1.952361e-06  4.380901e-06  2.154401e-06  4.251190e-05  1.214165e-05   \n",
       "4    3.906394e-08  9.341128e-09  8.720875e-07  5.643861e-07  8.725259e-07   \n",
       "..            ...           ...           ...           ...           ...   \n",
       "777  1.185205e-06  3.891688e-07  1.386265e-05  4.249470e-06  1.846914e-05   \n",
       "778  1.726760e-05  4.702084e-06  5.571641e-05  1.088487e-04  1.235258e-04   \n",
       "779  3.253240e-06  1.608644e-06  1.338978e-05  1.240644e-04  4.352060e-05   \n",
       "780  2.446040e-06  7.999105e-06  1.727888e-06  1.590365e-03  3.393491e-04   \n",
       "781  2.121607e-04  1.571333e-05  7.258910e-04  2.635619e-05  2.207332e-04   \n",
       "\n",
       "               56        57        58            59            60  \n",
       "0    4.108106e-05  0.000020  0.000998  1.578432e-04  2.457487e-07  \n",
       "1    4.433006e-04  0.000325  0.000772  9.722515e-05  2.036020e-03  \n",
       "2    6.304176e-04  0.000013  0.000013  9.044350e-05  1.898947e-03  \n",
       "3    2.761259e-06  0.000412  0.000030  1.425031e-05  1.701997e-03  \n",
       "4    2.958231e-07  0.000267  0.000012  8.937378e-07  4.076185e-05  \n",
       "..            ...       ...       ...           ...           ...  \n",
       "777  6.107186e-06  0.000760  0.000095  1.536776e-05  2.605067e-04  \n",
       "778  3.478106e-05  0.000856  0.000138  7.609236e-05  7.287843e-04  \n",
       "779  1.083684e-05  0.000348  0.000095  9.161315e-06  7.376492e-04  \n",
       "780  7.269366e-04  0.000080  0.000049  3.950317e-03  2.099279e-05  \n",
       "781  1.112305e-04  0.002361  0.000784  1.228427e-04  2.185416e-03  \n",
       "\n",
       "[782 rows x 62 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "executionInfo": {
     "elapsed": 214,
     "status": "ok",
     "timestamp": 1633580870115,
     "user": {
      "displayName": "꾸꾸",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "14922489440020274566"
     },
     "user_tz": -540
    },
    "id": "ngJyjpIBL972"
   },
   "outputs": [],
   "source": [
    "submission.iloc[:,1:]=prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "executionInfo": {
     "elapsed": 236,
     "status": "ok",
     "timestamp": 1633580945729,
     "user": {
      "displayName": "꾸꾸",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "14922489440020274566"
     },
     "user_tz": -540
    },
    "id": "Y1ir4C2oMBFS"
   },
   "outputs": [],
   "source": [
    "submission.to_csv('cnn_LSTM_stacked5_fold3(jy).csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 444
    },
    "executionInfo": {
     "elapsed": 223,
     "status": "ok",
     "timestamp": 1633580871532,
     "user": {
      "displayName": "꾸꾸",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "14922489440020274566"
     },
     "user_tz": -540
    },
    "id": "ABb6IgKAL_9N",
    "outputId": "105a563f-f73b-4de1-e4f8-b296cec4c0c8"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3125</td>\n",
       "      <td>1.818085e-07</td>\n",
       "      <td>2.990748e-10</td>\n",
       "      <td>4.487960e-13</td>\n",
       "      <td>1.291852e-10</td>\n",
       "      <td>1.653824e-04</td>\n",
       "      <td>3.122892e-06</td>\n",
       "      <td>3.212281e-09</td>\n",
       "      <td>4.089149e-09</td>\n",
       "      <td>3.953727e-06</td>\n",
       "      <td>...</td>\n",
       "      <td>5.920189e-09</td>\n",
       "      <td>1.194939e-06</td>\n",
       "      <td>2.049685e-09</td>\n",
       "      <td>2.950898e-06</td>\n",
       "      <td>1.409117e-11</td>\n",
       "      <td>2.571565e-05</td>\n",
       "      <td>1.052109e-05</td>\n",
       "      <td>0.000882</td>\n",
       "      <td>7.647593e-05</td>\n",
       "      <td>4.605368e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3126</td>\n",
       "      <td>1.035188e-04</td>\n",
       "      <td>7.174468e-08</td>\n",
       "      <td>2.586844e-06</td>\n",
       "      <td>3.508122e-05</td>\n",
       "      <td>1.124479e-04</td>\n",
       "      <td>9.138392e-06</td>\n",
       "      <td>8.007053e-05</td>\n",
       "      <td>3.063066e-06</td>\n",
       "      <td>3.752326e-05</td>\n",
       "      <td>...</td>\n",
       "      <td>3.524654e-07</td>\n",
       "      <td>1.798253e-08</td>\n",
       "      <td>9.352498e-06</td>\n",
       "      <td>3.732722e-06</td>\n",
       "      <td>1.238638e-05</td>\n",
       "      <td>7.568388e-06</td>\n",
       "      <td>1.090419e-04</td>\n",
       "      <td>0.000057</td>\n",
       "      <td>3.633829e-06</td>\n",
       "      <td>1.975011e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3127</td>\n",
       "      <td>5.698949e-04</td>\n",
       "      <td>1.300783e-02</td>\n",
       "      <td>1.049216e-05</td>\n",
       "      <td>1.284879e-07</td>\n",
       "      <td>2.514458e-09</td>\n",
       "      <td>1.802775e-07</td>\n",
       "      <td>9.249253e-05</td>\n",
       "      <td>1.102775e-03</td>\n",
       "      <td>7.089174e-03</td>\n",
       "      <td>...</td>\n",
       "      <td>2.359332e-05</td>\n",
       "      <td>4.424048e-05</td>\n",
       "      <td>1.849813e-07</td>\n",
       "      <td>1.850916e-03</td>\n",
       "      <td>6.893796e-06</td>\n",
       "      <td>8.602461e-05</td>\n",
       "      <td>8.844395e-07</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>1.894044e-05</td>\n",
       "      <td>3.203505e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3128</td>\n",
       "      <td>1.129604e-04</td>\n",
       "      <td>8.796709e-09</td>\n",
       "      <td>2.209129e-07</td>\n",
       "      <td>1.394959e-06</td>\n",
       "      <td>3.753279e-06</td>\n",
       "      <td>4.502023e-08</td>\n",
       "      <td>8.851490e-06</td>\n",
       "      <td>4.006568e-07</td>\n",
       "      <td>4.572582e-05</td>\n",
       "      <td>...</td>\n",
       "      <td>5.797814e-09</td>\n",
       "      <td>2.277752e-09</td>\n",
       "      <td>7.398341e-08</td>\n",
       "      <td>1.867475e-07</td>\n",
       "      <td>2.243160e-07</td>\n",
       "      <td>4.317151e-08</td>\n",
       "      <td>7.804685e-05</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>2.850201e-07</td>\n",
       "      <td>1.608517e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3129</td>\n",
       "      <td>1.273341e-05</td>\n",
       "      <td>2.004103e-10</td>\n",
       "      <td>4.232902e-08</td>\n",
       "      <td>7.597974e-07</td>\n",
       "      <td>9.845483e-06</td>\n",
       "      <td>6.312181e-08</td>\n",
       "      <td>3.018983e-06</td>\n",
       "      <td>5.344403e-08</td>\n",
       "      <td>9.868612e-07</td>\n",
       "      <td>...</td>\n",
       "      <td>7.965164e-10</td>\n",
       "      <td>4.721470e-11</td>\n",
       "      <td>9.768743e-08</td>\n",
       "      <td>2.629502e-08</td>\n",
       "      <td>1.063932e-07</td>\n",
       "      <td>2.587393e-08</td>\n",
       "      <td>3.513558e-05</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>3.781655e-08</td>\n",
       "      <td>1.622565e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>777</th>\n",
       "      <td>3902</td>\n",
       "      <td>1.589479e-04</td>\n",
       "      <td>1.404485e-08</td>\n",
       "      <td>1.107691e-06</td>\n",
       "      <td>1.604071e-05</td>\n",
       "      <td>3.846888e-04</td>\n",
       "      <td>9.459447e-07</td>\n",
       "      <td>2.214505e-05</td>\n",
       "      <td>1.306076e-06</td>\n",
       "      <td>1.472531e-05</td>\n",
       "      <td>...</td>\n",
       "      <td>2.601518e-08</td>\n",
       "      <td>1.491754e-08</td>\n",
       "      <td>6.096317e-07</td>\n",
       "      <td>3.859403e-07</td>\n",
       "      <td>1.141888e-06</td>\n",
       "      <td>3.284736e-07</td>\n",
       "      <td>6.095179e-04</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>2.337227e-06</td>\n",
       "      <td>6.067682e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>778</th>\n",
       "      <td>3903</td>\n",
       "      <td>9.217057e-05</td>\n",
       "      <td>4.155473e-08</td>\n",
       "      <td>6.853861e-07</td>\n",
       "      <td>6.811353e-06</td>\n",
       "      <td>5.491576e-05</td>\n",
       "      <td>1.486162e-06</td>\n",
       "      <td>3.743223e-05</td>\n",
       "      <td>1.219919e-06</td>\n",
       "      <td>5.136179e-05</td>\n",
       "      <td>...</td>\n",
       "      <td>5.491746e-08</td>\n",
       "      <td>5.318538e-09</td>\n",
       "      <td>1.334689e-06</td>\n",
       "      <td>3.455058e-07</td>\n",
       "      <td>1.717482e-06</td>\n",
       "      <td>7.994167e-07</td>\n",
       "      <td>2.084754e-04</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>2.866668e-06</td>\n",
       "      <td>1.306722e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>779</th>\n",
       "      <td>3904</td>\n",
       "      <td>4.075159e-05</td>\n",
       "      <td>1.473930e-09</td>\n",
       "      <td>1.562473e-07</td>\n",
       "      <td>1.337599e-06</td>\n",
       "      <td>2.428704e-06</td>\n",
       "      <td>3.349579e-08</td>\n",
       "      <td>7.848435e-06</td>\n",
       "      <td>1.075496e-07</td>\n",
       "      <td>1.061142e-05</td>\n",
       "      <td>...</td>\n",
       "      <td>5.234783e-09</td>\n",
       "      <td>6.082884e-10</td>\n",
       "      <td>1.357391e-07</td>\n",
       "      <td>1.431384e-07</td>\n",
       "      <td>2.059154e-07</td>\n",
       "      <td>3.035527e-08</td>\n",
       "      <td>4.723554e-05</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>8.771500e-08</td>\n",
       "      <td>8.799493e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>780</th>\n",
       "      <td>3905</td>\n",
       "      <td>2.302760e-04</td>\n",
       "      <td>2.713558e-02</td>\n",
       "      <td>2.443792e-04</td>\n",
       "      <td>2.005777e-04</td>\n",
       "      <td>3.298060e-05</td>\n",
       "      <td>6.894526e-05</td>\n",
       "      <td>3.003283e-02</td>\n",
       "      <td>1.486704e-04</td>\n",
       "      <td>1.839368e-02</td>\n",
       "      <td>...</td>\n",
       "      <td>4.510919e-04</td>\n",
       "      <td>1.025270e-03</td>\n",
       "      <td>4.981594e-05</td>\n",
       "      <td>9.963953e-03</td>\n",
       "      <td>1.301768e-03</td>\n",
       "      <td>1.893748e-02</td>\n",
       "      <td>2.438040e-04</td>\n",
       "      <td>0.001290</td>\n",
       "      <td>3.344771e-02</td>\n",
       "      <td>3.274780e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>781</th>\n",
       "      <td>3906</td>\n",
       "      <td>5.853642e-04</td>\n",
       "      <td>8.491147e-07</td>\n",
       "      <td>3.989881e-06</td>\n",
       "      <td>3.588315e-05</td>\n",
       "      <td>5.485517e-04</td>\n",
       "      <td>2.673314e-05</td>\n",
       "      <td>2.201237e-04</td>\n",
       "      <td>3.335669e-05</td>\n",
       "      <td>3.784164e-04</td>\n",
       "      <td>...</td>\n",
       "      <td>1.518714e-06</td>\n",
       "      <td>2.407207e-07</td>\n",
       "      <td>1.836816e-05</td>\n",
       "      <td>5.232524e-06</td>\n",
       "      <td>1.429993e-05</td>\n",
       "      <td>2.135463e-05</td>\n",
       "      <td>1.299932e-03</td>\n",
       "      <td>0.000145</td>\n",
       "      <td>4.551334e-05</td>\n",
       "      <td>8.002464e-05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>782 rows × 62 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       id             0             1             2             3  \\\n",
       "0    3125  1.818085e-07  2.990748e-10  4.487960e-13  1.291852e-10   \n",
       "1    3126  1.035188e-04  7.174468e-08  2.586844e-06  3.508122e-05   \n",
       "2    3127  5.698949e-04  1.300783e-02  1.049216e-05  1.284879e-07   \n",
       "3    3128  1.129604e-04  8.796709e-09  2.209129e-07  1.394959e-06   \n",
       "4    3129  1.273341e-05  2.004103e-10  4.232902e-08  7.597974e-07   \n",
       "..    ...           ...           ...           ...           ...   \n",
       "777  3902  1.589479e-04  1.404485e-08  1.107691e-06  1.604071e-05   \n",
       "778  3903  9.217057e-05  4.155473e-08  6.853861e-07  6.811353e-06   \n",
       "779  3904  4.075159e-05  1.473930e-09  1.562473e-07  1.337599e-06   \n",
       "780  3905  2.302760e-04  2.713558e-02  2.443792e-04  2.005777e-04   \n",
       "781  3906  5.853642e-04  8.491147e-07  3.989881e-06  3.588315e-05   \n",
       "\n",
       "                4             5             6             7             8  \\\n",
       "0    1.653824e-04  3.122892e-06  3.212281e-09  4.089149e-09  3.953727e-06   \n",
       "1    1.124479e-04  9.138392e-06  8.007053e-05  3.063066e-06  3.752326e-05   \n",
       "2    2.514458e-09  1.802775e-07  9.249253e-05  1.102775e-03  7.089174e-03   \n",
       "3    3.753279e-06  4.502023e-08  8.851490e-06  4.006568e-07  4.572582e-05   \n",
       "4    9.845483e-06  6.312181e-08  3.018983e-06  5.344403e-08  9.868612e-07   \n",
       "..            ...           ...           ...           ...           ...   \n",
       "777  3.846888e-04  9.459447e-07  2.214505e-05  1.306076e-06  1.472531e-05   \n",
       "778  5.491576e-05  1.486162e-06  3.743223e-05  1.219919e-06  5.136179e-05   \n",
       "779  2.428704e-06  3.349579e-08  7.848435e-06  1.075496e-07  1.061142e-05   \n",
       "780  3.298060e-05  6.894526e-05  3.003283e-02  1.486704e-04  1.839368e-02   \n",
       "781  5.485517e-04  2.673314e-05  2.201237e-04  3.335669e-05  3.784164e-04   \n",
       "\n",
       "     ...            51            52            53            54  \\\n",
       "0    ...  5.920189e-09  1.194939e-06  2.049685e-09  2.950898e-06   \n",
       "1    ...  3.524654e-07  1.798253e-08  9.352498e-06  3.732722e-06   \n",
       "2    ...  2.359332e-05  4.424048e-05  1.849813e-07  1.850916e-03   \n",
       "3    ...  5.797814e-09  2.277752e-09  7.398341e-08  1.867475e-07   \n",
       "4    ...  7.965164e-10  4.721470e-11  9.768743e-08  2.629502e-08   \n",
       "..   ...           ...           ...           ...           ...   \n",
       "777  ...  2.601518e-08  1.491754e-08  6.096317e-07  3.859403e-07   \n",
       "778  ...  5.491746e-08  5.318538e-09  1.334689e-06  3.455058e-07   \n",
       "779  ...  5.234783e-09  6.082884e-10  1.357391e-07  1.431384e-07   \n",
       "780  ...  4.510919e-04  1.025270e-03  4.981594e-05  9.963953e-03   \n",
       "781  ...  1.518714e-06  2.407207e-07  1.836816e-05  5.232524e-06   \n",
       "\n",
       "               55            56            57        58            59  \\\n",
       "0    1.409117e-11  2.571565e-05  1.052109e-05  0.000882  7.647593e-05   \n",
       "1    1.238638e-05  7.568388e-06  1.090419e-04  0.000057  3.633829e-06   \n",
       "2    6.893796e-06  8.602461e-05  8.844395e-07  0.000001  1.894044e-05   \n",
       "3    2.243160e-07  4.317151e-08  7.804685e-05  0.000002  2.850201e-07   \n",
       "4    1.063932e-07  2.587393e-08  3.513558e-05  0.000002  3.781655e-08   \n",
       "..            ...           ...           ...       ...           ...   \n",
       "777  1.141888e-06  3.284736e-07  6.095179e-04  0.000026  2.337227e-06   \n",
       "778  1.717482e-06  7.994167e-07  2.084754e-04  0.000011  2.866668e-06   \n",
       "779  2.059154e-07  3.035527e-08  4.723554e-05  0.000002  8.771500e-08   \n",
       "780  1.301768e-03  1.893748e-02  2.438040e-04  0.001290  3.344771e-02   \n",
       "781  1.429993e-05  2.135463e-05  1.299932e-03  0.000145  4.551334e-05   \n",
       "\n",
       "               60  \n",
       "0    4.605368e-08  \n",
       "1    1.975011e-05  \n",
       "2    3.203505e-04  \n",
       "3    1.608517e-05  \n",
       "4    1.622565e-06  \n",
       "..            ...  \n",
       "777  6.067682e-05  \n",
       "778  1.306722e-05  \n",
       "779  8.799493e-06  \n",
       "780  3.274780e-04  \n",
       "781  8.002464e-05  \n",
       "\n",
       "[782 rows x 62 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def result_pred(sub1, sub2) :\n",
    "    subpre1 = []\n",
    "    subpre2 = []\n",
    "    corcount = 0\n",
    "    \n",
    "    for i in range(len(sub1)) :\n",
    "        subpre1.append(sub1.iloc[i,1:].idxmax())\n",
    "        subpre2.append(sub2.iloc[i,1:].idxmax())\n",
    "\n",
    "    subpre1 = pd.DataFrame(subpre1, columns = ['label'])\n",
    "    subpre1.head()\n",
    "    \n",
    "    subpre2 = pd.DataFrame(subpre2, columns = ['label'])\n",
    "    subpre2.head()\n",
    "    \n",
    "    print(\"파일 1 운동중 라벨 수 :\", len(subpre1[subpre1['label'] != '26']), \"\\n파일 2 운동중 라벨 수 :\", len(subpre2[subpre2['label'] != '26']))\n",
    "    for i in range(len(subpre1)) :\n",
    "        if (subpre1['label'][i] == subpre2['label'][i]) : \n",
    "            corcount += 1\n",
    "    print(\"예측 결과 일치 개수 :\", corcount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "파일 1 운동중 라벨 수 : 780 \n",
      "파일 2 운동중 라벨 수 : 380\n",
      "예측 결과 일치 개수 : 1\n"
     ]
    }
   ],
   "source": [
    "sub1 = pd.read_csv('cnn_LSTM_stacked5_fold3(jy).csv')\n",
    "sub2 = pd.read_csv('cnn_LSTM_stacked_5(jy).csv')\n",
    "\n",
    "result_pred(sub1, sub2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub2"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "cnn1d_lstm_stacking.ipynb",
   "provenance": []
  },
  "hide_input": false,
  "interpreter": {
   "hash": "172d357f1c92d4c08eada0d83cc0b4d7a3e15628b28e34b7092f9013b5b73d18"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
